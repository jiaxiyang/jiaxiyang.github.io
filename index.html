<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0-rc2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jiaxiyang.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="深度学习&#x2F;自动驾驶&#x2F;C++&#x2F;性能优化">
<meta property="og:type" content="website">
<meta property="og:title" content="Xiyang">
<meta property="og:url" content="https://jiaxiyang.github.io/index.html">
<meta property="og:site_name" content="Xiyang">
<meta property="og:description" content="深度学习&#x2F;自动驾驶&#x2F;C++&#x2F;性能优化">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="贾夕阳">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://jiaxiyang.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Xiyang</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WGS6S6YFJ6"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-WGS6S6YFJ6');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Xiyang</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Think twice, code once!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">170</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">44</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">55</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/jiaxiyang" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2024/01/11/blas/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/11/blas/" class="post-title-link" itemprop="url">blas</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-01-11 16:31:34 / 修改时间：16:55:43" itemprop="dateCreated datePublished" datetime="2024-01-11T16:31:34+08:00">2024-01-11</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2024/01/11/blas/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/01/11/blas/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>862</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="basic"><a href="#basic" class="headerlink" title="basic"></a>basic</h2><ol>
<li>BLAS 是 Basic Linear Algebra Subprograms 的缩写,即基本线性代数子程序,它是一系列线性代数运算函数的标准说明和接口规范。通常情况下,BLAS 函数库会为矩阵和向量运算提供高效、经过优化的实现,这些函数被广泛使用于科学计算、机器学习、数据分析等领域需要大量数值计算的场景中。常见的 BLAS 函数标准说明有:<ul>
<li>BLAS level 1:向量-向量运算</li>
<li>BLAS level 2:矩阵-向量运算</li>
<li>BLAS level 3:矩阵-矩阵运算</li>
</ul>
</li>
<li><code>GEMM(General Matrix-Matrix Multiplicatio)</code> 是通用矩阵乘法,表示 <code>C = αAB + β*C</code>。它计算两个矩阵的乘积,是最常见的数值密集型运算之一。</li>
<li><code>GEMV(General Matrix-Vector Multiplication)</code>是矩阵向量乘法,表示<code>y = αAx + β*y</code>。它计算矩阵和向量的乘积得到一个向量。 αβ 是标量，A 是矩阵，xy 是向量</li>
<li><a target="_blank" rel="noopener" href="https://github.com/flame/how-to-optimize-gemm">how-to-optimize-gemm</a></li>
</ol>
<h2 id="NVIDIA-cutlass"><a href="#NVIDIA-cutlass" class="headerlink" title="NVIDIA&#x2F;cutlass"></a><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cutlass">NVIDIA&#x2F;cutlass</a></h2><ol>
<li>CUDA Templates for Linear Algebra Subroutines and Solvers</li>
<li>CUTLASS 和 cuBLAS 都是与 NVIDIA GPUs 相关的库，专门用于高效地执行线性代数运算</li>
<li>大矩阵 GEMM 运算 CuTlass 可以显著提速,是目前 GPU 上最快的 GEMM 库。</li>
<li>它允许开发者使用模板元编程自定义和优化矩阵乘法（GEMM）等线性代数运算，更加灵活。</li>
<li>cuBLAS 提供了一个简单、标准的 BLAS 接口，易于使用，而 CUTLASS 提供了更多的定制性和灵活性，但需要更深入的理解和控制。</li>
</ol>
<h2 id="cuBLAS"><a href="#cuBLAS" class="headerlink" title="cuBLAS"></a><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cublas">cuBLAS</a></h2><ol>
<li>CUDA Basic Linear Algebra Subprograms</li>
<li>cuBLAS（CUDA Basic Linear Algebra Subprograms）是由 NVIDIA 提供的官方库，它是经典 BLAS（Basic Linear Algebra Subprograms）库的 CUDA 实现。</li>
</ol>
<h2 id="OpenBLAS"><a href="#OpenBLAS" class="headerlink" title="OpenBLAS"></a><a target="_blank" rel="noopener" href="https://github.com/OpenMathLib/OpenBLAS">OpenBLAS</a></h2><h2 id="blis"><a href="#blis" class="headerlink" title="blis"></a><a target="_blank" rel="noopener" href="https://github.com/flame/blis">blis</a></h2><h2 id="hipBLAS"><a href="#hipBLAS" class="headerlink" title="hipBLAS"></a><a target="_blank" rel="noopener" href="https://github.com/ROCm/hipBLAS">hipBLAS</a></h2><h2 id="Intel-oneMKL"><a href="#Intel-oneMKL" class="headerlink" title="Intel oneMKL"></a><a target="_blank" rel="noopener" href="https://github.com/oneapi-src/oneMKL">Intel oneMKL</a></h2><h2 id="CLBlast"><a href="#CLBlast" class="headerlink" title="CLBlast"></a><a target="_blank" rel="noopener" href="https://github.com/CNugteren/CLBlast">CLBlast</a></h2>
      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2024/01/10/llama-cpp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/10/llama-cpp/" class="post-title-link" itemprop="url">llama.cpp</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-10 17:07:30" itemprop="dateCreated datePublished" datetime="2024-01-10T17:07:30+08:00">2024-01-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-11 11:03:22" itemprop="dateModified" datetime="2024-01-11T11:03:22+08:00">2024-01-11</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2024/01/10/llama-cpp/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/01/10/llama-cpp/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="run-on-cpu"><a href="#run-on-cpu" class="headerlink" title="run on cpu"></a>run on cpu</h2><ol>
<li>build</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/ggerganov/llama.cpp</span><br><span class="line"><span class="built_in">cd</span> llama.cpp</span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">cmake --build . --config Release -j16</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>convert llama2 model</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## llama repo下下载了7b模型</span></span><br><span class="line">python convert.py ../llama/llama-2-7b/</span><br><span class="line"></span><br><span class="line"><span class="comment">## q4_0量化</span></span><br><span class="line">./build/bin/quantize ../llama/llama-2-7b/ggml-model-f16.gguf ../llama/llama-2-7b/ggml-model-q4_0.gguf q4_0</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>run</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./build/bin/main -m ../llama/llama-2-7b/ggml-model-f16.gguf -p <span class="string">&quot;Building a website can be done in 10 simple steps:\nStep 1:&quot;</span> -n 40 -e</span><br></pre></td></tr></table></figure>

<p>4.result</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">llama_print_timings:        load time =    2123.21 ms</span><br><span class="line">llama_print_timings:      sample time =      22.01 ms /    40 runs   (    0.55 ms per token,  1817.19 tokens per second)</span><br><span class="line">llama_print_timings: prompt eval time =     820.50 ms /    19 tokens (   43.18 ms per token,    23.16 tokens per second)</span><br><span class="line">llama_print_timings:        eval time =   15164.51 ms /    39 runs   (  388.83 ms per token,     2.57 tokens per second)</span><br><span class="line">llama_print_timings:       total time =   16023.55 ms</span><br></pre></td></tr></table></figure>

<h2 id="run-on-cpu-with-mpi-on"><a href="#run-on-cpu-with-mpi-on" class="headerlink" title="run on cpu with mpi on"></a>run on cpu with mpi on</h2><ol>
<li>build</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install libopenmpi-dev</span><br><span class="line">cmake -S . -B build -DLLAMA_MPI=ON</span><br><span class="line">cd build</span><br><span class="line">cmake --build . --config Release -j16</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>result</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">llama_print_timings:        load time =    2092.53 ms</span><br><span class="line">llama_print_timings:      sample time =      20.81 ms /    40 runs   (    0.52 ms per token,  1922.15 tokens per second)</span><br><span class="line">llama_print_timings: prompt eval time =     668.81 ms /    19 tokens (   35.20 ms per token,    28.41 tokens per second)</span><br><span class="line">llama_print_timings:        eval time =   10150.64 ms /    39 runs   (  260.27 ms per token,     3.84 tokens per second)</span><br><span class="line">llama_print_timings:       total time =   10855.62 ms</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># run with mulit core</span></span></span><br><span class="line">mpirun -np 8 ./build/bin/main -m ../llama/llama-2-7b/ggml-model-f16.gguf -p &quot;Building a website can be done in 10 simple steps:\nStep 1:&quot; -n 40 -e</span><br></pre></td></tr></table></figure>

<h2 id="openBlas"><a href="#openBlas" class="headerlink" title="openBlas"></a>openBlas</h2><ol>
<li>build</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd build</span><br><span class="line">cmake .. -DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS</span><br><span class="line">cmake --build . --config Release -j16</span><br></pre></td></tr></table></figure>

<ol>
<li>result</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">llama_print_timings:        load time =    2008.93 ms</span><br><span class="line">llama_print_timings:      sample time =      50.88 ms /   100 runs   (    0.51 ms per token,  1965.37 tokens per second)</span><br><span class="line">llama_print_timings: prompt <span class="built_in">eval</span> time =     647.12 ms /    19 tokens (   34.06 ms per token,    29.36 tokens per second)</span><br><span class="line">llama_print_timings:        <span class="built_in">eval</span> time =   25045.01 ms /    99 runs   (  252.98 ms per token,     3.95 tokens per second)</span><br><span class="line">llama_print_timings:       total time =   25779.49 ms</span><br></pre></td></tr></table></figure>

<h2 id="cublas"><a href="#cublas" class="headerlink" title="cublas"></a>cublas</h2><ol>
<li>build</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_VISIBLE_DEVICES=0,1</span><br><span class="line">export PATH=/usr/local/cuda/bin/:$&#123;PATH&#125;</span><br><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">cmake .. -DLLAMA_CUBLAS=ON</span><br><span class="line">cmake --build . --config Release -j16</span><br></pre></td></tr></table></figure>

<ol>
<li>result</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">llama_print_timings:        load time =    2225.07 ms</span><br><span class="line">llama_print_timings:      sample time =      21.19 ms /    40 runs   (    0.53 ms per token,  1887.33 tokens per second)</span><br><span class="line">llama_print_timings: prompt eval time =     814.74 ms /    19 tokens (   42.88 ms per token,    23.32 tokens per second)</span><br><span class="line">llama_print_timings:        eval time =   10324.64 ms /    39 runs   (  264.73 ms per token,     3.78 tokens per second)</span><br><span class="line">llama_print_timings:       total time =   11176.41 ms</span><br></pre></td></tr></table></figure>

<ol>
<li>q4_0 result</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">llama_print_timings:        load time =    1097.19 ms</span><br><span class="line">llama_print_timings:      sample time =      22.74 ms /    40 runs   (    0.57 ms per token,  1759.25 tokens per second)</span><br><span class="line">llama_print_timings: prompt eval time =     780.84 ms /    19 tokens (   41.10 ms per token,    24.33 tokens per second)</span><br><span class="line">llama_print_timings:        eval time =    6715.37 ms /    39 runs   (  172.19 ms per token,     5.81 tokens per second)</span><br><span class="line">llama_print_timings:       total time =    7536.04 ms</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2024/01/10/model-compression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/10/model-compression/" class="post-title-link" itemprop="url">model-compression</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-01-10 16:27:54 / 修改时间：16:36:12" itemprop="dateCreated datePublished" datetime="2024-01-10T16:27:54+08:00">2024-01-10</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2024/01/10/model-compression/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/01/10/model-compression/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>132</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="quantization-量化"><a href="#quantization-量化" class="headerlink" title="quantization 量化"></a>quantization 量化</h2><h2 id="pruning-剪枝"><a href="#pruning-剪枝" class="headerlink" title="pruning 剪枝"></a>pruning 剪枝</h2><h3 id="稀疏化"><a href="#稀疏化" class="headerlink" title="稀疏化"></a>稀疏化</h3><ol>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013010889/article/details/53305595">scipy csr_matrix 和 csc_matrix 函数详解</a></li>
</ol>
<h2 id="knowledge-distillation-蒸馏"><a href="#knowledge-distillation-蒸馏" class="headerlink" title="knowledge distillation 蒸馏"></a>knowledge distillation 蒸馏</h2><h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://xailient.com/blog/4-popular-model-compression-techniques-explained/">4-popular-model-compression-techniques-explained</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2024/01/04/huggingface/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/04/huggingface/" class="post-title-link" itemprop="url">huggingface</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-04 11:22:30" itemprop="dateCreated datePublished" datetime="2024-01-04T11:22:30+08:00">2024-01-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-08 17:58:42" itemprop="dateModified" datetime="2024-01-08T17:58:42+08:00">2024-01-08</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2024/01/04/huggingface/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/01/04/huggingface/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="pipeline"><a href="#pipeline" class="headerlink" title="pipeline"></a><a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/main_classes/pipelines">pipeline</a></h2><ol>
<li>The pipelines are a great and easy way to use models for inference.</li>
<li>llama2</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use a pipeline as a high-level helper</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line">pipe = pipeline(<span class="string">&quot;text-generation&quot;</span>, model=<span class="string">&quot;./Llama-2-7b-hf&quot;</span>)</span><br><span class="line">pipe(<span class="string">&quot;how are you&quot;</span>)</span><br><span class="line"><span class="comment"># 查看帮助</span></span><br><span class="line"><span class="built_in">help</span>(pipeline)</span><br><span class="line"><span class="built_in">help</span>(pipe)</span><br></pre></td></tr></table></figure>

<h2 id="查看模型信息"><a href="#查看模型信息" class="headerlink" title="查看模型信息"></a>查看模型信息</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/saratbhargava/ai-blog-resources/blob/main/LLM/Llama_2_param_count.ipynb">基础信息</a></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load model directly</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line"></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;./Llama-2-7b-hf&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="keyword">from</span> prettytable <span class="keyword">import</span> PrettyTable</span><br><span class="line"></span><br><span class="line">table = PrettyTable([<span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Shape&#x27;</span>, <span class="string">&#x27;Param&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    param_count = param.numel()</span><br><span class="line">    table.add_row([name, param.shape, param_count])</span><br><span class="line"><span class="built_in">print</span>(table)</span><br><span class="line">num_parameters = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters())</span><br><span class="line"><span class="built_in">print</span>(num_parameters)</span><br></pre></td></tr></table></figure>

<h2 id="models"><a href="#models" class="headerlink" title="models"></a><a target="_blank" rel="noopener" href="https://huggingface.co/models">models</a></h2><ol>
<li>repo 包含<ul>
<li>config.json 每个架构一个 config.json <a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/main/model_doc/llama2#transformers.LlamaConfig">llama config</a></li>
</ul>
</li>
</ol>
<h2 id="模型文件类型"><a href="#模型文件类型" class="headerlink" title="模型文件类型"></a><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/620641385/answer/3230090109">模型文件类型</a></h2><ol>
<li>支持 bin 或 safetensors 文件</li>
<li>safetensors 是谷歌开发的一种 TensorFlow Lite 模型文件格式，用于在移动设备上运行模型</li>
<li>bin 文件自存储模型的参数，不包含</li>
<li>pytorch 两种方式<ul>
<li>保存整个模型：保存整个模型的结构（代码）、参数 <code>torch.save(model, &#39;model.pth&#39;)</code></li>
<li>保存模型参数：仅保存模型的参数，而不保存模型的结构（代码）。<code>torch.save(model.state_dict(), &#39;model_params.pth&#39;</code></li>
</ul>
</li>
<li>有些模型保存未 gguf 格式，需要专门推理引擎才能使用</li>
<li><a target="_blank" rel="noopener" href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md">gguf doc</a></li>
<li>gguf：It is a successor file format to GGML, GGMF and GGJT, and is designed to be unambiguous by containing all the information needed to load a model. It is also designed to be extensible, so that new features can be added to GGML without breaking compatibility with older models.</li>
<li>The .bin files that are used by llama.cpp allow users to easily share models in a single file. Except they had one big problem: lack of flexibility. You could not add additional information about the model.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/ggerganov/llama.cpp/discussions/2948">hugging face models to gguf</a></li>
</ol>
<h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/v4.36.1/zh/index">transformers 中文文档</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/blog/zh/llama2">blog</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/blog/zh/llama2">Llama 2 来袭 - 在 Hugging Face 上玩转它</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2024/01/01/tensorrt-llm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/01/tensorrt-llm/" class="post-title-link" itemprop="url">tensorrt-llm</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-01 20:33:30" itemprop="dateCreated datePublished" datetime="2024-01-01T20:33:30+08:00">2024-01-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-11 10:32:22" itemprop="dateModified" datetime="2024-01-11T10:32:22+08:00">2024-01-11</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2024/01/01/tensorrt-llm/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/01/01/tensorrt-llm/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="base"><a href="#base" class="headerlink" title="base"></a>base</h2><ol>
<li>大模型优化方法：tensorrt + plugins, 耗时的算子用专有库进行替换，如矩阵乘用 cutlass</li>
<li>TensorRT-LLM wraps TensorRT’s deep learning compiler—which includes optimized kernels from FasterTransformer, pre- and post-processing, and multi-GPU and multi-node communication—in a simple open-source Python API for defining, optimizing, and executing LLMs for inference in production.</li>
<li><a target="_blank" rel="noopener" href="https://nvidia.github.io/TensorRT-LLM/gpt_runtime.html#generation">generation</a></li>
<li><a target="_blank" rel="noopener" href="https://nvidia.github.io/TensorRT-LLM/batch_manager.html#gptmanager-design">gptmanager</a></li>
<li>TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines.</li>
<li><a target="_blank" rel="noopener" href="https://nvidia.github.io/TensorRT-LLM/">doc</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT-LLM/tree/main?tab=readme-ov-file#key-features">key-features 可学习如何优化</a></li>
</ol>
<h2 id="deubg"><a href="#deubg" class="headerlink" title="deubg"></a>deubg</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT-LLM/blob/6cc5e177ff2fb60b1aab3b03fa0534b5181cf0f1/cpp/tensorrt_llm/common/logger.cpp#L32">TLLM_LOG_LEVEL&#x3D;TRACE</a></li>
<li>打开 trace， 跟踪代码执行</li>
</ol>
<h2 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h2><ol>
<li><a target="_blank" rel="noopener" href="https://hub.docker.com/search?q=tensorrt_llm">docker hubs</a></li>
</ol>
<h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2><ol>
<li>使用 docker <a target="_blank" rel="noopener" href="https://hub.docker.com/r/baseten/tensorrt_llm-release">baseten&#x2F;tensorrt_llm-release</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT-LLM/blob/v0.7.1/docs/source/installation.md#fetch-the-sources">fetch-the-sources</a> in docker</li>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT-LLM/blob/v0.7.1/docs/source/installation.md#build-tensorrt-llm">build-tensorrt-llm</a></li>
<li>可能需要先卸载 <code>pip uninstall tensorrt_llm</code>， 重新安装</li>
</ol>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="ccdv-cnn-dailymail"><a href="#ccdv-cnn-dailymail" class="headerlink" title="ccdv&#x2F;cnn_dailymail"></a><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/ccdv/cnn_dailymail">ccdv&#x2F;cnn_dailymail</a></h3><ol>
<li>gitee 镜像版本不太好使</li>
<li>下载之后传到服务器</li>
<li><a target="_blank" rel="noopener" href="https://github.com/abisee/cnn-dailymail/tree/master/url_lists">clone txt</a></li>
<li>修改 summarize.py；从本地 load 数据集</li>
<li><code>dataset = load_dataset(&quot;/mnt/data-2/home/xiyang.jia/TensorRT-LLM/examples/bloom/cnn_dailymail/cnn_dailymail.py&quot;, &quot;3.0.0&quot;)</code> 从本地加载数据集</li>
</ol>
<h2 id="vscode-setting"><a href="#vscode-setting" class="headerlink" title="vscode setting"></a>vscode setting</h2><ol>
<li>env settings</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;PYDEVD_WARN_EVALUATION_TIMEOUT&quot;</span><span class="punctuation">:</span> <span class="string">&quot;500&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;OPAL_PREFIX&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/opt/hpcx/ompi&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<ol>
<li>launch.json</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Python: tensorrt&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="comment">// &quot;program&quot;: &quot;$&#123;workspaceFolder&#125;/examples/summarize.py&quot;,</span></span><br><span class="line">      <span class="comment">// &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;/examples/bloom/&quot;,</span></span><br><span class="line">      <span class="comment">// &quot;program&quot;: &quot;../summarize.py&quot;,</span></span><br><span class="line">      <span class="comment">// &quot;args&quot;: [</span></span><br><span class="line">      <span class="comment">//     &quot;--test_trt_llm&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;--hf_model_dir&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;./bloom/560M/&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;--data_type&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;fp16&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;--engine_dir&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;./bloom/560M/trt_engines/fp16/1-gpu/&quot;</span></span><br><span class="line">      <span class="comment">// ],</span></span><br><span class="line">      <span class="comment">// run llama test</span></span><br><span class="line">      <span class="attr">&quot;cwd&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;/examples/llama/&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;../run.py&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;--max_output_len=50&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;--tokenizer_dir&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;/mnt/data-2/home/xiyang.jia/Llama-2-7b-hf&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;--engine_dir=./tmp/llama/7B/trt_engines/fp16/1-gpu/&quot;</span></span><br><span class="line">      <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="comment">// build llama test</span></span><br><span class="line">      <span class="comment">// &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;/examples/llama/&quot;,</span></span><br><span class="line">      <span class="comment">// &quot;program&quot;: &quot;./build.py&quot;,</span></span><br><span class="line">      <span class="comment">// &quot;args&quot;: [</span></span><br><span class="line">      <span class="comment">//     &quot;--model_dir&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;/mnt/data-2/home/xiyang.jia/Llama-2-7b-hf&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;--dtype&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;float16&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;--remove_input_padding&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;--use_gpt_attention_plugin&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;float16&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;--enable_context_fmha&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;--use_gemm_plugin&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;float16&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;--output_dir&quot;,</span></span><br><span class="line">      <span class="comment">//     &quot;./tmp/llama/7B/trt_engines/fp16/test/&quot;</span></span><br><span class="line">      <span class="comment">// ],</span></span><br><span class="line">      <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;PYDEVD_WARN_EVALUATION_TIMEOUT&quot;</span><span class="punctuation">:</span> <span class="string">&quot;500&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;OPAL_PREFIX&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/opt/hpcx/ompi&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6,7&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;TLLM_LOG_LEVEL&quot;</span><span class="punctuation">:</span> <span class="string">&quot;DEBUG&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;console&quot;</span><span class="punctuation">:</span> <span class="string">&quot;integratedTerminal&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;justMyCode&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h2 id="examples"><a href="#examples" class="headerlink" title="examples"></a>examples</h2><ol>
<li><code>build.py</code> 每个 example 独占，用于构建模型和编译成 engine 模型; 需要模型配置：权重等</li>
<li>In addition, there are two shared files in the parent folder examples for inference and evaluation:<ul>
<li><code>run.py</code> to run the inference on an input text;</li>
<li><code>summarize.py</code> to summarize the articles in the cnn_dailymail dataset.</li>
</ul>
</li>
<li>需要 hf model; 例:llama-7B-hf; hf 是 Huggingface 对原始 llama-7B 模型的打包版本,</li>
<li>TensorRT-LLM LLaMA builds TensorRT engine(s) from HF checkpoint. If no checkpoint directory is specified, TensorRT-LLM will build engine(s) with dummy weights. 如果不设置 <code>--model_dir</code>, 使用随机权重</li>
<li>llama sample 运行时需要 config.json, <code>--tokenizer_dir</code>指定</li>
<li><a target="_blank" rel="noopener" href="https://gitee.com/hf-models/Llama-2-7b-hf">gitee.com&#x2F;hf-models&#x2F;Llama-2-7b-hf</a> gitee 下载要快很多 <code>git lfs clone https://gitee.com/hf-models/Llama-2-7b-hf</code></li>
<li>run 的时候加参数<code>--temperature=0.6 --top_k=10</code>可生成不一样内容</li>
<li><code>/usr/local/tensorrt/bin/trtexec --loadEngine=tmp/llama/7B/trt_engines/fp16/1-gpu/llama_float16_tp1_rank0.engine</code>会出错，未解决</li>
<li><a target="_blank" rel="noopener" href="https://github.com/hpcaitech/SwiftInfer?tab=readme-ov-file">tensorrt llm llama</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/12/30/gpt/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/12/30/gpt/" class="post-title-link" itemprop="url">gpt</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-12-30 21:01:57 / 修改时间：21:02:26" itemprop="dateCreated datePublished" datetime="2023-12-30T21:01:57+08:00">2023-12-30</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/12/30/gpt/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/12/30/gpt/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>26</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/openai/gpt-2">openai&#x2F;gpt-2 开源代码</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/29/">29</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="贾夕阳"
      src="/images/coder2.jpg">
  <p class="site-author-name" itemprop="name">贾夕阳</p>
  <div class="site-description" itemprop="description">深度学习/自动驾驶/C++/性能优化</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">170</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/jiaxiyang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jiaxiyang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



  <div class="links-of-recent-posts motion-element">
    <div class="links-of-recent-posts-title">
      <i class="fa fa-history fa-fw"></i>
      最近文章
    </div>
    <ul class="links-of-recent-posts-list">
        <li class="links-of-recent-posts-item">
          <a href="/2024/01/11/blas/" title="2024&#x2F;01&#x2F;11&#x2F;blas&#x2F;">blas</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2024/01/10/llama-cpp/" title="2024&#x2F;01&#x2F;10&#x2F;llama-cpp&#x2F;">llama.cpp</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2024/01/10/model-compression/" title="2024&#x2F;01&#x2F;10&#x2F;model-compression&#x2F;">model-compression</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2024/01/04/huggingface/" title="2024&#x2F;01&#x2F;04&#x2F;huggingface&#x2F;">huggingface</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2024/01/01/tensorrt-llm/" title="2024&#x2F;01&#x2F;01&#x2F;tensorrt-llm&#x2F;">tensorrt-llm</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">贾夕阳</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">422k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">6:24</span>
</div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("06/26/2020 14:52:10");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_sphere.min.js"></script>


  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : '[object Object]',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://jiaxiyang.github.io/',]
      });
      });
  </script>


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'g32ipLmEye1u5l6wBGRJt03S-gzGzoHsz',
      appKey     : 'zHgLkAICsZUl9Mf8LfdoVigP',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

  

  <script src="/js/activate-power-mode.min.js"></script>
  <script>
    POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);
  </script>





 
</body>
</html>

