<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0-rc2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jiaxiyang.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="深度学习&#x2F;自动驾驶&#x2F;C++&#x2F;性能优化">
<meta property="og:type" content="website">
<meta property="og:title" content="Xiyang">
<meta property="og:url" content="https://jiaxiyang.github.io/page/6/index.html">
<meta property="og:site_name" content="Xiyang">
<meta property="og:description" content="深度学习&#x2F;自动驾驶&#x2F;C++&#x2F;性能优化">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="贾夕阳">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://jiaxiyang.github.io/page/6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Xiyang</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WGS6S6YFJ6"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-WGS6S6YFJ6');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Xiyang</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Think twice, code once!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">171</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">44</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">55</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/jiaxiyang" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/07/11/pandas/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/07/11/pandas/" class="post-title-link" itemprop="url">pandas</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-07-11 12:39:24 / 修改时间：12:39:58" itemprop="dateCreated datePublished" datetime="2023-07-11T12:39:24+08:00">2023-07-11</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/07/11/pandas/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/07/11/pandas/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>18</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="describe"><a href="#describe" class="headerlink" title="describe"></a><a target="_blank" rel="noopener" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html">describe</a></h2><ol>
<li>获取统计信息， 可配置</li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/07/09/data-view/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/07/09/data-view/" class="post-title-link" itemprop="url">data_view</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-07-09 10:30:56" itemprop="dateCreated datePublished" datetime="2023-07-09T10:30:56+08:00">2023-07-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-12-03 17:40:43" itemprop="dateModified" datetime="2023-12-03T17:40:43+08:00">2023-12-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DataView/" itemprop="url" rel="index"><span itemprop="name">DataView</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/07/09/data-view/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/07/09/data-view/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="note"><a href="#note" class="headerlink" title="note"></a>note</h2><ol>
<li>openai 数据分析可视化</li>
<li><a target="_blank" rel="noopener" href="https://github.com/rougier/scientific-visualization-book">科学可视化：Python+Matplotlib</a></li>
</ol>
<h2 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h2><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/572327280?utm_id=0">3σ 准则</a></li>
<li><a target="_blank" rel="noopener" href="https://www.rerun.io/blog#principles-for-a-computer-vision-focused-seeingtool">可视化工具原则</a></li>
<li>使用 rerun 实时或回放监测的数据: 将可视化代码与算法代码分开</li>
<li>两二进制文件比较服务器(转成 float 对比)<ul>
<li>error 画图</li>
<li>三列, 数据 1， 数据 2， error， error 用色阶表示</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://pandas.pydata.org/docs/user_guide/style.html">pandas table 颜色设置（好用）</a>, 类似 excel 表格色阶</li>
<li>excel 中可以套用表格格式来美化表格, 利用好色阶，条件格式, 数据条</li>
<li>将 log 文件拖到浏览器中，生成报告(正则表达式先生成 pandas， 然后生成报告)</li>
<li>csv server</li>
<li><a target="_blank" rel="noopener" href="https://www.51cto.com/article/719697.html">提高数据可视化效果的五个原则</a></li>
<li><a target="_blank" rel="noopener" href="https://techcommunity.microsoft.com/t5/excel-blog/announcing-python-in-excel-combining-the-power-of-python-and-the/ba-p/3893439">excel with python</a></li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2023/07/09/data-view/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/07/05/matplotlib/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/07/05/matplotlib/" class="post-title-link" itemprop="url">matplotlib</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-07-05 10:19:07 / 修改时间：10:20:35" itemprop="dateCreated datePublished" datetime="2023-07-05T10:19:07+08:00">2023-07-05</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/07/05/matplotlib/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/07/05/matplotlib/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>22</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://matplotlib.org/stable/gallery/index.html">examples</a></li>
<li><a target="_blank" rel="noopener" href="https://matplotlib.org/stable/tutorials/introductory/pyplot.html">tutorials</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/06/26/pip/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/26/pip/" class="post-title-link" itemprop="url">pip</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-26 20:31:38" itemprop="dateCreated datePublished" datetime="2023-06-26T20:31:38+08:00">2023-06-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-12-28 16:28:12" itemprop="dateModified" datetime="2023-12-28T16:28:12+08:00">2023-12-28</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/06/26/pip/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/06/26/pip/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>86</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="use"><a href="#use" class="headerlink" title="use"></a>use</h2><ol>
<li>注意 conda 源和 pip 源的区别，并不是共用</li>
<li><code>pip list</code></li>
<li><code>pip install torchtext --upgrade</code></li>
<li><code>pip install torchtext==0.6.0</code></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/06/26/conda/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/26/conda/" class="post-title-link" itemprop="url">conda</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-26 15:08:04" itemprop="dateCreated datePublished" datetime="2023-06-26T15:08:04+08:00">2023-06-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-04 17:23:13" itemprop="dateModified" datetime="2024-01-04T17:23:13+08:00">2024-01-04</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/06/26/conda/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/06/26/conda/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="NOTE"><a href="#NOTE" class="headerlink" title="NOTE"></a>NOTE</h2><ol>
<li>注意 conda 源和 pip 源的区别，并不是共用</li>
<li>gcc 版本有要求</li>
<li><a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/">清华源切换</a></li>
<li><code>unset all_proxy</code> 不能使用代理，可能出现 install 错误 <a target="_blank" rel="noopener" href="https://blog.csdn.net/whatday/article/details/109287343">link</a></li>
<li><code>conda config --append channels conda-forge</code></li>
<li><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh &amp;&amp; sh Miniconda3-latest-Linux-x86_64.sh</code> install</li>
</ol>
<h2 id="basic-use"><a href="#basic-use" class="headerlink" title="basic use"></a>basic use</h2><ol>
<li><code>~/miniconda3/bin/conda init</code></li>
<li><code>conda config --set auto_activate_base false</code> 关闭自启动</li>
<li><code>conda info</code> 查看安装情况</li>
<li><code>conda env list</code> list env</li>
<li><code>conda list</code> list package in env</li>
<li><code>conda create --name ENVNAME</code> create env</li>
<li><code>conda create --name d2l python=3.9 -y</code></li>
<li><code>conda activate ENVNAME</code> activate env</li>
<li><code>conda deactivate</code> deactivate env</li>
<li><code>conda install PKGNAME=3.1.4</code> install lib</li>
<li><code>conda uninstall PKGNAME</code> uninstall lib</li>
<li>导出导入环境</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda list -e &gt; requirements.txt</span><br><span class="line">conda install --<span class="built_in">yes</span> --file requirements.txt</span><br></pre></td></tr></table></figure>

<h2 id="condarc"><a href="#condarc" class="headerlink" title="~&#x2F;.condarc"></a>~&#x2F;.condarc</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">auto_activate_base: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: <span class="literal">true</span></span><br><span class="line">default_channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class="line">custom_channels:</span><br><span class="line">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></table></figure>

<h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html">user-guide&#x2F;install</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.conda.io/en/latest/miniconda.html#linux-installers">miniconda</a> 选择对应 python 版本, install 时可以选路径</li>
<li><a target="_blank" rel="noopener" href="https://docs.conda.io/projects/conda/en/latest/user-guide/configuration/index.html#">user-guide&#x2F;configuration</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/conda/conda/blob/main/docs/source/user-guide/cheatsheets/conda-4.14.pdf">cheatsheets&#x2F;conda-4.14.pdf</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/deadsnakes/docs/blob/main/Building-Deadsnakes-Packages-from-Git.rst">build python from source</a> 编译之后需要前一级目录 <code>sudo dpkg -i *.deb</code></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/06/25/VPN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/25/VPN/" class="post-title-link" itemprop="url">VPN</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-25 11:45:46" itemprop="dateCreated datePublished" datetime="2023-06-25T11:45:46+08:00">2023-06-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-04 18:06:17" itemprop="dateModified" datetime="2024-01-04T18:06:17+08:00">2024-01-04</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/06/25/VPN/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/06/25/VPN/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>411</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="NOTE"><a href="#NOTE" class="headerlink" title="NOTE"></a>NOTE</h2><ol>
<li><code>export all_proxy=&quot;socks5://$&#123;IP&#125;:7890&quot;</code> linux 服务器可以设置 all_proxy 来翻墙， clash 鼠标悬浮 <code>Allow Lan</code> 可以看到对应 IP</li>
<li><code>export http_proxy=&quot;http://10.31.2.35:7890&quot; &amp;&amp; export https_proxy=&quot;https://10.31.2.35:7890&quot;</code> socks5 不起作用时</li>
<li>Proxies 选择 Rule，可以同时连接公司内网和外网，不要选 Global，不能连接内网</li>
</ol>
<h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://agentneo.tech/">agentneo</a> 使用 clash 客户端</li>
<li><a target="_blank" rel="noopener" href="https://solidspoon.xyz/2021/02/17/%E9%85%8D%E7%BD%AEWSL2%E4%BD%BF%E7%94%A8Windows%E4%BB%A3%E7%90%86%E4%B8%8A%E7%BD%91/">WSL 2 配置代理 clash</a> 配置 WSL2 使用 Windows 代理上网 有用</li>
<li><a target="_blank" rel="noopener" href="http://www.debugself.com/2018/01/17/docker_network/">docker build 以及 docker run 时使用 host 网络的方法</a></li>
<li><a target="_blank" rel="noopener" href="https://device.harmonyos.com/cn/docs/documentation/guide/vscode_proxy-0000001074231144">vscode proxy setting</a><ul>
<li>注意本地 proxy 和远程 proxy 都要设置对</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/06/12/onnxruntime/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/12/onnxruntime/" class="post-title-link" itemprop="url">onnxruntime</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-12 14:39:10" itemprop="dateCreated datePublished" datetime="2023-06-12T14:39:10+08:00">2023-06-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-10-19 17:39:03" itemprop="dateModified" datetime="2023-10-19T17:39:03+08:00">2023-10-19</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/06/12/onnxruntime/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/06/12/onnxruntime/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="concept"><a href="#concept" class="headerlink" title="concept"></a>concept</h2><p><img src="https://developer-blogs.nvidia.com/wp-content/uploads/2022/12/image3-2.png" alt="ONNX 运行时高级架构"><br>ONNX Runtime 是一个性能优秀的跨平台推理（inference）引擎，用于 ONNX（Open Neural Network Exchange）模型。它具有灵活的支持和高效的性能，可用于各种硬件设备（包括在边缘设备上）和操作系统。</p>
<p>以下是关于 ONNX Runtime 的一些基本概念：</p>
<ol>
<li><strong>ONNX 模型执行</strong>：ONNX Runtime 提供了执行 ONNX 模型的能力。你可以加载一个 ONNX 模型，然后使用 ONNX Runtime 来进行推理。</li>
<li><strong>硬件优化</strong>：ONNX Runtime 被设计为能够充分利用不同的硬件能力。它支持 CPU，GPU，以及更专用的硬件加速器（如 Microsoft 的 DirectML 和 NVIDIA 的 TensorRT）。</li>
<li><strong>跨平台</strong>：ONNX Runtime 可以在多种操作系统（包括 Windows，Linux，和 Mac OS）上运行，并且支持多种硬件设备，包括在边缘设备上。</li>
<li><strong>语言绑定</strong>：ONNX Runtime 提供了多种语言的 API，包括 C，C++，Python，C#，Java，和 JavaScript，使得开发者可以在他们选择的语言中使用 ONNX Runtime。</li>
<li><strong>会话（Session）</strong>：在 ONNX Runtime 中，一次模型的推理被称为一个会话。你可以创建一个会话，然后通过这个会话来执行模型。</li>
<li><strong>提供者（Providers）</strong>：ONNX Runtime 支持通过不同的“提供者”来执行模型。这些提供者可以是 CPU，CUDA（NVIDIA GPUs），TensorRT（NVIDIA GPUs），DirectML（Windows GPUs），OpenVINO（Intel GPUs）等。<br>通过 ONNX Runtime，开发者可以将 ONNX 模型部署到各种平台和设备上，同时保持良好的性能和灵活性。</li>
</ol>
<h3 id="Providers"><a href="#Providers" class="headerlink" title="Providers"></a><a target="_blank" rel="noopener" href="https://onnxruntime.ai/docs/execution-providers/">Providers</a></h3><p>ONNX Runtime 的”提供者”（Providers）是执行 ONNX 模型运算的后端引擎。每种提供者都是为特定的硬件或者软件平台优化的。使用正确的提供者可以大大提高模型的执行效率。<br>以下是一些主要的 ONNX Runtime 提供者：</p>
<ol>
<li><strong>CPU Execution Provider</strong>: CPU 提供者是 ONNX Runtime 的默认提供者，它在 CPU 上执行模型运算。CPU 提供者在所有系统上都可用，不需要任何额外的依赖。</li>
<li><strong>CUDA Execution Provider</strong>: CUDA 提供者是为 NVIDIA 的 GPU 优化的，它使用 CUDA 和 cuDNN 库来在 GPU 上执行模型运算。使用 CUDA 提供者需要安装 CUDA 和 cuDNN。</li>
<li><strong>TensorRT Execution Provider</strong>: TensorRT 提供者也是为 NVIDIA 的 GPU 优化的，但是它使用 NVIDIA 的 TensorRT 库来执行模型运算。TensorRT 提供者可以提供比 CUDA 提供者更高的性能，但是需要更复杂的设置。</li>
<li><strong>DirectML Execution Provider</strong>: DirectML 提供者是为 Windows 系统上的 GPU 优化的，它使用 Microsoft 的 DirectML 库来执行模型运算。DirectML 提供者可以在任何支持 DirectX 12 的 Windows 系统上使用。</li>
<li><strong>OpenVINO Execution Provider</strong>: OpenVINO 提供者是为 Intel 的硬件优化的，包括 CPU，GPU，VPU，和 FPGA。它使用 Intel 的 OpenVINO 库来执行模型运算。</li>
<li><strong>Nuphar Execution Provider</strong>: Nuphar 是一个为 CPU 优化的 JIT 编译器，主要用于对模型中的循环结构进行优化。</li>
<li><strong>VitisAI Execution Provider</strong>: VitisAI 提供者是为 Xilinx FPGA 硬件优化的，使用了 Xilinx 的 Vitis AI 库。<br>当你创建一个 ONNX Runtime 会话时，你可以指定用于执行模型运算的提供者。如果你没有指定提供者，ONNX Runtime 会使用默认的 CPU 提供者。如果你在一个支持 GPU 的系统上运行 ONNX Runtime，并且你已经安装了相应的依赖，你可以选择使用 CUDA，TensorRT，DirectML，或者 OpenVINO 提供者来提高模型的执行效率。<br>Note: provider 在 onnxruntime repo 里</li>
</ol>
<h2 id="TVM-and-onnxruntime"><a href="#TVM-and-onnxruntime" class="headerlink" title="TVM and onnxruntime"></a>TVM and onnxruntime</h2><p>TVM 是一个开源的机器学习编译器堆栈，它可以将机器学习模型从各种框架（例如 TensorFlow、PyTorch、ONNX、Keras 等）优化编译到各种硬件（例如 CPU、GPU、FPGA、ASIC 等）。<br>ONNX Runtime 是一个用于运行和推理 ONNX 模型的高性能跨平台推理引擎。然而，TVM 的关键优势在于它的自动调度程序和编译器栈，能够生成优化的计算内核，而 ONNX Runtime 的优势在于它对 ONNX 模型的广泛支持以及一系列优化技术。ONNX Runtime 支持多种硬件平台，包括 CPU、GPU 和专用加速器。它可以在不同硬件上运行，无需重新编译模型。<br>TVM 和 ONNX Runtime 的结合可以在两者之间提供一个桥梁，使得开发者可以利用 TVM 的优化能力，同时使用 ONNX Runtime 的灵活性和易用性。<br>ONNX Runtime 和 TVM 结合的一种方式是使用 TVM 作为 ONNX Runtime 的一个执行提供者。TVM 有一个 ONNX 编译器，可以将 ONNX 模型编译成 TVM 模块，然后在 ONNX Runtime 中注册这个模块作为一个提供者，这样 ONNX Runtime 就可以使用 TVM 来执行模型。<br>另一种方式是使用 TVM 来优化 ONNX 模型，然后在 ONNX Runtime 中执行优化后的模型。这种方法的优点是可以使用 TVM 的自动调度程序和编译器栈来优化模型，然后使用 ONNX Runtime 的高效运行时来执行优化后的模型。<br>这两种方法都需要一些设置和配置，并且可能需要修改 ONNX Runtime 或者 TVM 的代码。然而，它们都可以提供更好的性能和更高的灵活性，使得开发者可以更好地利用他们的硬件资源。</p>
<p>TVM 和 ONNX Runtime 都是用于机器学习模型推理的工具，但它们各自有着不同的优势和设计目标。<br><strong>TVM</strong>是一个开源的深度学习编译器和优化器，它的主要目标是提供一种灵活的方式来优化和部署深度学习模型到各种硬件平台，包括 CPU、GPU、FPGA 和 ASIC 等。TVM 的优势在于：</p>
<ol>
<li><strong>硬件无关的优化</strong>：TVM 的自动调度功能可以生成针对特定硬件优化的代码，无论这个硬件是 CPU、GPU 还是其他类型的硬件。</li>
<li><strong>端到端的编译优化</strong>：TVM 包括了从高层图优化到底层代码生成的全流程优化。</li>
<li><strong>支持多种深度学习框架</strong>：TVM 可以接受多种框架的模型，包括 TensorFlow、PyTorch、MXNet、Keras、ONNX 等。<br>而<strong>ONNX Runtime</strong>是一个用于运行和推理 ONNX 模型的跨平台高性能推理引擎，它的主要目标是提供一种高效、灵活且易于使用的方式来部署和执行 ONNX 模型。ONNX Runtime 的优势在于：</li>
<li><strong>广泛的 ONNX 模型支持</strong>：ONNX Runtime 支持 ONNX 模型中的所有运算符和特性。</li>
<li><strong>性能优化</strong>：ONNX Runtime 包含了一系列优化技术，包括图优化、运算符融合、内存优化等，以提高模型的执行性能。</li>
<li><strong>硬件加速</strong>：通过不同的执行提供者（如 CUDA、TensorRT、DirectML 等），ONNX Runtime 可以利用硬件加速器来提高模型的执行速度。<br>两者之间并非完全的竞争关系，它们可以相互结合，例如使用 TVM 作为 ONNX Runtime 的一个执行提供者，使得 ONNX Runtime 能够利用 TVM 的优化能力。</li>
</ol>
<h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2><ol>
<li><code>pip install onnxruntime</code></li>
<li><a target="_blank" rel="noopener" href="https://github.com/microsoft/onnxruntime/releases">c++直接下载编译好的库</a></li>
</ol>
<h2 id="sample"><a href="#sample" class="headerlink" title="sample"></a><a target="_blank" rel="noopener" href="https://github.com/microsoft/onnxruntime-inference-examples/tree/main/c_cxx">sample</a></h2><ol>
<li>测试</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --depth=1 https://github.com/microsoft/onnxruntime-inference-examples.git</span><br><span class="line"><span class="built_in">cd</span> onnxruntime-inference-examples/c_cxx/</span><br><span class="line">make -p build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake -DONNXRUNTIME_ROOTDIR=/xxx/onnxruntime-linux-x64-1.15.1 ..</span><br><span class="line">make -j4</span><br><span class="line">curl https://media.githubusercontent.com/media/onnx/models/main/vision/classification/squeezenet/model/squeezenet1.0-7.onnx --output squeezenet.onnx</span><br><span class="line">./build/model-explorer/model-explorer squeezenet.onnx</span><br></pre></td></tr></table></figure>

<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/microsoft/onnxruntime-inference-examples/blob/main/c_cxx/model-explorer/model-explorer.cpp">c++ sample code</a></li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;onnxruntime_cxx_api.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Load the model and create InferenceSession</span></span><br><span class="line">Ort::Env env;</span><br><span class="line">std::string model_path = <span class="string">&quot;path/to/your/onnx/model&quot;</span>;</span><br><span class="line"><span class="function">Ort::Session <span class="title">session</span><span class="params">(env, model_path, Ort::SessionOptions&#123; <span class="literal">nullptr</span> &#125;)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Load and preprocess the input image to</span></span><br><span class="line"><span class="comment">// inputTensor, inputNames, and outputNames</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment">// Run inference</span></span><br><span class="line">std::vector outputTensors =</span><br><span class="line"> session.<span class="built_in">Run</span>(Ort::RunOptions&#123;<span class="literal">nullptr</span>&#125;,</span><br><span class="line"> 			inputNames.<span class="built_in">data</span>(),</span><br><span class="line">			&amp;inputTensor,</span><br><span class="line">			inputNames.<span class="built_in">size</span>(),</span><br><span class="line">			outputNames.<span class="built_in">data</span>(),</span><br><span class="line">			outputNames.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">float</span>* outputDataPtr = outputTensors[<span class="number">0</span>].<span class="built_in">GetTensorMutableData</span>();</span><br><span class="line">std::cout &lt;&lt; outputDataPtr[<span class="number">0</span>] &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure>

<ol>
<li>sample 解析<ul>
<li>Session 处理各种环境信息，比如模型信息， 环境变量等，同时也进行调度， 不负责管理模型输入输出数据</li>
<li>由 Ort::Value::CreateTensor 申请模型输入输出的内存， 所有权归上层应用</li>
</ul>
</li>
</ol>
<h2 id="模型优化"><a href="#模型优化" class="headerlink" title="模型优化"></a>模型优化</h2><h3 id="sample-1"><a href="#sample-1" class="headerlink" title="sample"></a>sample</h3><h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://onnxruntime.ai/index.html#getStartedTable">支持的平台选择</a></li>
<li><a target="_blank" rel="noopener" href="https://onnxruntime.ai/docs/execution-providers/">onnxruntime.ai</a></li>
<li><a target="_blank" rel="noopener" href="https://onnxruntime.ai/docs/execution-providers/">docs</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/microsoft/onnxruntime/tree/eed02a3f782407e569c29a8a86c58a4d398d0b0e/onnxruntime/core/providers">onnxruntime&#x2F;core&#x2F;providers</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-AI/tree/c55b7565bde608dd65dda94abea154ad7db4d594/examples/vai_library/samples_onnx">vitis ai onnxruntime samples</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/search?q=repo:microsoft/onnxruntime%20USE_VITISAI&type=code">onnxruntime vitis support</a></li>
<li><a target="_blank" rel="noopener" href="https://software-dl.ti.com/jacinto7/esd/processor-sdk-rtos-jacinto7/07_03_00_07/exports/docs/tidl_j7_02_00_00_07/ti_dl/docs/user_guide_html/md_tidl_osr_onnxrt_tidl.html">tda4 onnx runtime</a></li>
<li><a target="_blank" rel="noopener" href="https://onnxruntime.ai/docs/api/c/struct_ort_1_1_session.html">doxygen</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/582974246">推理模型部署(一)：ONNX runtime 实践</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/06/12/Quantization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/12/Quantization/" class="post-title-link" itemprop="url">Quantization</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-12 11:43:36" itemprop="dateCreated datePublished" datetime="2023-06-12T11:43:36+08:00">2023-06-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-12-26 18:11:00" itemprop="dateModified" datetime="2023-12-26T18:11:00+08:00">2023-12-26</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/06/12/Quantization/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/06/12/Quantization/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>277</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="量化（定浮点转换）"><a href="#量化（定浮点转换）" class="headerlink" title="量化（定浮点转换）"></a>量化（定浮点转换）</h2><ol>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/niaolianjiulin/article/details/82764511">https://blog.csdn.net/niaolianjiulin/article/details/82764511</a></li>
<li>NVIDIA’s Turing architecture introduced INT4 precision</li>
<li>不是所有的 nvidia gpu 都支持 4bit 量化， Turing 架构之前的 Pascal、Volta 等架构就不提供对 4-bit 定点数的硬件加速支持。</li>
<li>是的,绝大多数 Nvidia GPU 都原生支持 8-bit 整数(INT8)定点数运算。</li>
<li>如果处理器不支持 4bit 量化； 那么 4bit 量化只能减少内存使用</li>
</ol>
<h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/LXP-Never/p/16822727.html">Pytorch 模型量化</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/06/09/pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/09/pytorch/" class="post-title-link" itemprop="url">pytorch</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-09 15:28:49" itemprop="dateCreated datePublished" datetime="2023-06-09T15:28:49+08:00">2023-06-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-08 16:36:39" itemprop="dateModified" datetime="2024-01-08T16:36:39+08:00">2024-01-08</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/06/09/pytorch/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/06/09/pytorch/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="base"><a href="#base" class="headerlink" title="base"></a>base</h2><ol>
<li>pytorch 导出模型时会显示 ONNX IR, 类似三段式<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/blob/main/torch/onnx/utils.py#L190">Functions to export models into the ONNX IR format.</a></li>
</ul>
</li>
<li>pytorch 模型结构定义之后, 有些算子不一定会使用，导出 onnx 模型时不使用的算子不会导出，应为导出模型进行一次模型推理，在推理的过程中记录所有经过的计算，将这些记录整合成计算图</li>
<li>pytorch 为什么不直接用 numpy?<ul>
<li><code>GPU 支持</code>：PyTorch 设计之初就考虑到了与 GPU 的兼容性，允许其在 GPU 上直接执行张量运算，大大加快了深度学习模型的训练和推理速度。相比之下，NumPy 主要是为 CPU 设计的，不支持 GPU 或其他类型的加速硬件。</li>
<li><code>自动微分</code>：PyTorch 提供了自动微分功能，这对于深度学习至关重要。通过它的 <code>autograd</code> 系统，PyTorch 能够自动计算模型参数的梯度，这对于训练神经网络来说是必需的。NumPy 没有内置这样的功能。</li>
<li><code>深度学习特定的操作</code>：PyTorch 提供了许多专为深度学习设计的操作和函数，如卷积、池化等，这些在 NumPy 中不是直接可用的。</li>
<li><code>动态计算图</code>：PyTorch 使用动态计算图（也称为即时执行），这意味着计算图在运行时动态构建，从而提供了更灵活的编程模式，特别是对于复杂的模型和动态输入。而 NumPy 没有这样的概念。</li>
<li><code>可扩展性和生态系统</code>：虽然 NumPy 在科学计算方面非常强大，但 PyTorch 提供了更适合于大规模、复杂的深度学习模型和应用的工具和库。</li>
</ul>
</li>
<li>在使用动态图（Dynamic Graph）框架（如 PyTorch 或 TensorFlow 的 Eager Execution 模式）进行单步调试时，并不是每一步操作都会完全重新构建整个计算图。相反，每一步操作通常对应计算图的一部分，这个部分在执行时被动态创建和执行。在单步调试时，整个模型的计算图不会在每一步都被重新构建。只有实际执行的操作会被动态添加到图中。</li>
<li>在使用动态图框架（如 PyTorch 或 TensorFlow 的 Eager Execution 模式）进行单步调试时，整个模型的计算图并不会在每一步都被重新构建。动态图的特点是在运行时动态构建和执行计算图的一部分，而非整个图。这种方法与静态图框架（如 TensorFlow 的传统模式）形成对比，后者在执行任何计算前需要先构建完整的计算图并对其进行优化。</li>
<li>循环：<ul>
<li>不固定：动态图</li>
<li>固定：可以被展开，构成静态图</li>
</ul>
</li>
<li><code>torch==1.11.0+cu113</code></li>
<li><code>pip install torch==1.11.0+cu113 --extra-index-url https://download.pytorch.org/whl/cu113</code></li>
<li><code>pip freeze | grep torch</code>: 查看库版本</li>
<li><code>pip show torch</code>: 查看库版本</li>
<li><code>python3 -c &quot;import torch; print(torch.__version__)&quot;</code></li>
<li>pytorch tensor to binary file: <code>tensor.cpu().numpy().astype(np.float32).tofile(&quot;test.bin&quot;)</code>; c++ read binary file</li>
<li>tensor 中取单个元素会降维；例如从二维 tensor 取单行或者单列结果会变为一维 tensor</li>
<li><code>help(torch.ones)</code> 显示函数 help</li>
<li><code>print(dir(torch.distributions))</code> 显示 torch 的 distributions</li>
</ol>
<h2 id="基础运算"><a href="#基础运算" class="headerlink" title="基础运算"></a><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html">基础运算</a></h2><ol>
<li><a target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_preliminaries/ndarray.html">d2l ndarray</a></li>
<li><code>x = torch.arange(10)</code> tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</li>
<li><code>x = torch.arange(10.0)</code> tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])</li>
<li><code>type(x)</code> 打印 x 类型</li>
<li><code>torch.randn(2)</code> tensor([ 0.6872, -0.3433]); 返回一个填充随机正态分布的张量(mean&#x3D;0, std&#x3D;1)。即,生成的值大概符合平均数为 0,标准差为 1 的正态分布。</li>
<li><code>X = torch.rand(2,20)</code> 返回一个填充随机均匀分布的张量,即在[0,1)区间内均匀随机。</li>
<li><code>x = x.reshape(2, 5)</code></li>
<li><code>x.shape</code> torch.Size([2, 5])</li>
<li><code>a = torch.tensor(3.4); a.shape</code> torch.Size([]) 标量</li>
<li><code>a = torch.tensor([3.4]);a.shape</code> torch.Size([1]) 向量</li>
<li><code>x.numel()</code> 10; element number</li>
<li><code>len(x)</code> 2; len()为 python 内置函数， 用于 tensor 时是指 tesnor 的维度（dimension）</li>
<li><code>torch.ones(2, 4)</code></li>
<li><code>torch.zeros(2, 4)</code></li>
<li><code>X.reshape(-1)</code> 展平为一维</li>
<li>tensor 基本运算</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1.0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>])  <span class="comment"># 1.0 mean float</span></span><br><span class="line">y = torch.tensor([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">x + y, x - y, x * y, x / y, x ** y  <span class="comment"># **运算符是求幂运算</span></span><br></pre></td></tr></table></figure>

<ol>
<li>tensor 矩阵运算</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X = torch.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">Y = torch.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">X.t() <span class="comment"># 转置</span></span><br><span class="line">X @ Y <span class="comment"># 矩阵乘</span></span><br><span class="line">torch.matmul(X, Y) <span class="comment"># 矩阵乘</span></span><br><span class="line">X * Y <span class="comment"># 元素分别相乘</span></span><br><span class="line">X + <span class="number">5</span> <span class="comment"># 广播：分别加5</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li><code>torch.exp(x)</code> tensor 求指数</li>
<li>concat and condition</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X = torch.arange(<span class="number">12</span>, dtype=torch.float32).reshape((<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">Y = torch.tensor([[<span class="number">2.0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line">torch.cat((X, Y), dim=<span class="number">0</span>), torch.cat((X, Y), dim=<span class="number">1</span>)  <span class="comment"># dim=0按行拼接， dim=1按列拼接， 0代表最里面一个维度</span></span><br><span class="line">X == Y <span class="comment"># shape: torch.Size([3, 4])</span></span><br><span class="line">X &lt; Y</span><br><span class="line">X &gt; Y</span><br><span class="line">X.<span class="built_in">sum</span>() <span class="comment"># 求和</span></span><br><span class="line">X.mean() <span class="comment"># 求均值</span></span><br></pre></td></tr></table></figure>

<ol>
<li>索引和切片</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X[-<span class="number">1</span>] <span class="comment"># 取最后一个元素</span></span><br><span class="line">X[<span class="number">1</span>:<span class="number">3</span>] <span class="comment"># 取第二个和第三个元素，不包含X[3]</span></span><br><span class="line">X[<span class="number">1</span>,<span class="number">2</span>] = <span class="number">9</span> <span class="comment"># 赋值</span></span><br><span class="line">X[<span class="number">0</span>:<span class="number">2</span>, :] = <span class="number">12</span> <span class="comment"># 前两行赋值为12</span></span><br></pre></td></tr></table></figure>

<ol>
<li>节省内存</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">before = <span class="built_in">id</span>(Y)</span><br><span class="line">Y = Y + X</span><br><span class="line"><span class="built_in">id</span>(Y) == before <span class="comment"># False</span></span><br><span class="line"></span><br><span class="line">Z = torch.zeros_like(Y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;id(Z):&#x27;</span>, <span class="built_in">id</span>(Z))</span><br><span class="line">Z[:] = X + Y</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;id(Z):&#x27;</span>, <span class="built_in">id</span>(Z))</span><br><span class="line"></span><br><span class="line">before = <span class="built_in">id</span>(X)</span><br><span class="line">X += Y</span><br><span class="line"><span class="built_in">id</span>(X) == before <span class="comment"># True</span></span><br></pre></td></tr></table></figure>

<ol>
<li>和 numpy 转换</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">A = X.numpy()</span><br><span class="line">B = torch.tensor(A)</span><br><span class="line"><span class="built_in">type</span>(A), <span class="built_in">type</span>(B)</span><br><span class="line"></span><br><span class="line">a = torch.tensor([<span class="number">3.5</span>])</span><br><span class="line">a, a.item(), <span class="built_in">float</span>(a), <span class="built_in">int</span>(a) <span class="comment"># (tensor([3.5000]), 3.5, 3.5, 3)</span></span><br></pre></td></tr></table></figure>

<ol>
<li>type 转换 <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html">type</a></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = torch.arange(<span class="number">12</span>).reshape(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">X.dtype <span class="comment"># torch.int64</span></span><br><span class="line">X.to(torch.float32)</span><br><span class="line">torch.tensor([<span class="number">1.2</span>]).<span class="built_in">type</span>() <span class="comment"># torch.FloatTensor</span></span><br><span class="line">torch.tensor([<span class="number">1.2</span>]).dtype <span class="comment"># torch.float32</span></span><br></pre></td></tr></table></figure>

<ol>
<li>cpu cuda</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">X.cpu()</span><br><span class="line">X.cuda() <span class="comment"># 默认cuda:0</span></span><br><span class="line">X.to(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">X.to(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">Y = X.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># PyTorch的GPU端对tensor数据类型的支持是有限的,很多运算只实现了float/double类型的GPU支持。</span></span><br><span class="line">X = torch.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>).cuda().to(torch.float32)</span><br><span class="line">Y = torch.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>).cuda().to(torch.float32)</span><br><span class="line">torch.matmul(X, Y)</span><br><span class="line">X @ Y</span><br></pre></td></tr></table></figure>

<h2 id="torchscript"><a href="#torchscript" class="headerlink" title="torchscript"></a><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/2010575">torchscript</a></h2><ol>
<li>TorchScript 是 PyTorch 模型推理部署的中间表示，可以在高性能环境 libtorch（C ++）中直接加载，实现模型推理，而无需 Pytorch 训练框架依赖。torch.jit 是 torchscript Python 语言包支持，支持 pytorch 模型快速，高效，无缝对接到 libtorch 运行时，实现高效推理。</li>
<li>torchscript 主要包含权重和计算过程(IR; 类似.text; 各种函数，有一个入口)</li>
<li>trace 指的是进行一次模型推理，在推理的过程中记录所有经过的计算，将这些记录整合成计算图<ul>
<li>for 循环被展开</li>
</ul>
</li>
<li>script 会直接解析网络定义的 python 代码，生成抽象语法树 AST，因此这种方法可以解决一些 trace 无法解决的问题，比如对 branch&#x2F;loop 等数据流控制语句的建图。<ul>
<li>for 循环编程子图</li>
</ul>
</li>
</ol>
<h2 id="model"><a href="#model" class="headerlink" title="model"></a>model</h2><ol>
<li>定义模型时可以直接初始化参数，也可以后期加载<ul>
<li><code>self.lin1.weight = nn.Parameter(torch.arange(-4.0, 5.0).view(3, 3))</code></li>
</ul>
</li>
<li>basic</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line">model = nn.Sequential(nn.Linear(<span class="number">20</span>, <span class="number">256</span>), nn.ReLU(), nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line">X = torch.rand(<span class="number">2</span>, <span class="number">20</span>)</span><br><span class="line">model(X)</span><br><span class="line"><span class="built_in">help</span>(model) <span class="comment">#可以看帮助</span></span><br><span class="line"></span><br><span class="line">output = x</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;输入:&#x27;</span>, output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看每层输出</span></span><br><span class="line"><span class="keyword">for</span> name, layer <span class="keyword">in</span> model.named_children():</span><br><span class="line">    output = layer(output)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;层:&#x27;</span>, name, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;输出:&#x27;</span>, output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看每层参数</span></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Name: <span class="subst">&#123;name&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Size: <span class="subst">&#123;param.size()&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;param.data&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<ol>
<li>model parmas</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load model directly</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line"></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;./Llama-2-7b-hf&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="keyword">from</span> prettytable <span class="keyword">import</span> PrettyTable</span><br><span class="line"></span><br><span class="line">table = PrettyTable([<span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Shape&#x27;</span>, <span class="string">&#x27;Param&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    param_count = param.numel()</span><br><span class="line">    table.add_row([name, param.shape, param_count])</span><br><span class="line"><span class="built_in">print</span>(table)</span><br><span class="line"></span><br><span class="line">num_parameters = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters())</span><br><span class="line"><span class="built_in">print</span>(num_parameters)</span><br></pre></td></tr></table></figure>

<ol>
<li>pytorch model to onnx(导出为 batch 1 时需要设置输入数据第一维度为 1,)</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">import</span> torch.onnx <span class="keyword">as</span> onnx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载预训练模型</span></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个输入张量作为示例; 注意数据和模型要么都在cuda，要么都在cpu</span></span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>).cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置模型为推理模式</span></span><br><span class="line">model.<span class="built_in">eval</span>() <span class="comment"># 只影响</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将模型和输入张量转换为ONNX格式</span></span><br><span class="line">onnx_path = <span class="string">&quot;model.onnx&quot;</span></span><br><span class="line">onnx.export(model, input_data, onnx_path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型已成功转换为ONNX格式并保存在:&quot;</span>, onnx_path)</span><br></pre></td></tr></table></figure>

<h2 id="model-info"><a href="#model-info" class="headerlink" title="model info"></a>model info</h2><ol>
<li>需要 model.eval()； 不会打印 dropout 层</li>
<li><a target="_blank" rel="noopener" href="https://github.com/TylerYep/torchinfo">torchinfo</a></li>
<li><code>summary(model, [(1, 1, 32000), (1,1,32000), (1, 1, 32000), (1,1,32000)], dtypes=[torch.long, torch.long, torch.long, torch.long])</code></li>
</ol>
<h2 id="tools"><a href="#tools" class="headerlink" title="tools"></a>tools</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/pytorch/captum">captum</a> Model interpretability and understanding for PyTorch</li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html">tensorboard_tutorial</a></li>
</ol>
<h2 id="samples"><a href="#samples" class="headerlink" title="samples"></a>samples</h2><ol start="2">
<li>量化模型</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html">tutorials</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/index.html">docs</a></li>
<li><a target="_blank" rel="noopener" href="https://yiyibooks.cn/yiyibooks/pytorch_131/index.html">中文</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2023/06/08/colab/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/08/colab/" class="post-title-link" itemprop="url">colab</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-08 17:16:31" itemprop="dateCreated datePublished" datetime="2023-06-08T17:16:31+08:00">2023-06-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-06-20 15:37:37" itemprop="dateModified" datetime="2023-06-20T15:37:37+08:00">2023-06-20</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/06/08/colab/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/06/08/colab/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>23</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="link"><a href="#link" class="headerlink" title="link"></a>link</h2><ol>
<li><a target="_blank" rel="noopener" href="https://colab.research.google.com/notebooks/snippets/importing_libraries.ipynb">importing_libraries</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="贾夕阳"
      src="/images/coder2.jpg">
  <p class="site-author-name" itemprop="name">贾夕阳</p>
  <div class="site-description" itemprop="description">深度学习/自动驾驶/C++/性能优化</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">171</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/jiaxiyang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jiaxiyang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



  <div class="links-of-recent-posts motion-element">
    <div class="links-of-recent-posts-title">
      <i class="fa fa-history fa-fw"></i>
      最近文章
    </div>
    <ul class="links-of-recent-posts-list">
        <li class="links-of-recent-posts-item">
          <a href="/2024/01/14/Efficient-LLM/" title="2024&#x2F;01&#x2F;14&#x2F;Efficient-LLM&#x2F;">Efficient-LLM</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2024/01/11/blas/" title="2024&#x2F;01&#x2F;11&#x2F;blas&#x2F;">blas</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2024/01/10/llama-cpp/" title="2024&#x2F;01&#x2F;10&#x2F;llama-cpp&#x2F;">llama.cpp</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2024/01/10/model-compression/" title="2024&#x2F;01&#x2F;10&#x2F;model-compression&#x2F;">model-compression</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2024/01/04/huggingface/" title="2024&#x2F;01&#x2F;04&#x2F;huggingface&#x2F;">huggingface</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">贾夕阳</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">435k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">6:36</span>
</div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("06/26/2020 14:52:10");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_sphere.min.js"></script>


  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : '[object Object]',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://jiaxiyang.github.io/page/6/',]
      });
      });
  </script>


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'g32ipLmEye1u5l6wBGRJt03S-gzGzoHsz',
      appKey     : 'zHgLkAICsZUl9Mf8LfdoVigP',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

  

  <script src="/js/activate-power-mode.min.js"></script>
  <script>
    POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);
  </script>





 
</body>
</html>

