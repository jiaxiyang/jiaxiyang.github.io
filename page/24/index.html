<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0-rc2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jiaxiyang.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="深度学习&#x2F;自动驾驶&#x2F;C++&#x2F;性能优化">
<meta property="og:type" content="website">
<meta property="og:title" content="Xiyang">
<meta property="og:url" content="https://jiaxiyang.github.io/page/24/index.html">
<meta property="og:site_name" content="Xiyang">
<meta property="og:description" content="深度学习&#x2F;自动驾驶&#x2F;C++&#x2F;性能优化">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="贾夕阳">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://jiaxiyang.github.io/page/24/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Xiyang</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WGS6S6YFJ6"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-WGS6S6YFJ6');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Xiyang</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Think twice, code once!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">196</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">44</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">55</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/jiaxiyang" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2022/03/18/samba/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/18/samba/" class="post-title-link" itemprop="url">samba</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-18 01:43:12" itemprop="dateCreated datePublished" datetime="2022-03-18T01:43:12+08:00">2022-03-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-09-28 13:13:37" itemprop="dateModified" datetime="2023-09-28T13:13:37+08:00">2023-09-28</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/03/18/samba/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/03/18/samba/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>481</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install samba</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="config"><a href="#config" class="headerlink" title="config"></a>config</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/samba/smb.conf</span><br><span class="line"></span><br><span class="line">[share]</span><br><span class="line">     path = /home/jiaxiyang/share</span><br><span class="line">     available = <span class="built_in">yes</span></span><br><span class="line">     valid <span class="built_in">users</span> = jiaxiyang</span><br><span class="line">     <span class="built_in">read</span> only = no</span><br><span class="line">     browsable = <span class="built_in">yes</span></span><br><span class="line">     public = <span class="built_in">yes</span></span><br><span class="line">     writable = <span class="built_in">yes</span></span><br></pre></td></tr></table></figure>

<h2 id="add-user"><a href="#add-user" class="headerlink" title="add user"></a>add user</h2><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo smbpasswd -<span class="selector-tag">a</span> jiaxiyang</span><br></pre></td></tr></table></figure>

<h2 id="restart"><a href="#restart" class="headerlink" title="restart"></a>restart</h2><h3 id="ubuntu"><a href="#ubuntu" class="headerlink" title="ubuntu"></a>ubuntu</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="regexp">/etc/i</span>nit.d/samba restart</span><br><span class="line">sudo <span class="regexp">/etc/i</span>nit.d/smbd restart</span><br></pre></td></tr></table></figure>

<h3 id="centos"><a href="#centos" class="headerlink" title="centos"></a>centos</h3><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="params">system</span>ctl start smb.service</span><br><span class="line">sudo <span class="params">system</span>ctl restart smb</span><br></pre></td></tr></table></figure>

<h2 id="link"><a href="#link" class="headerlink" title="link"></a>link</h2><h3 id="ubuntu-1"><a href="#ubuntu-1" class="headerlink" title="ubuntu"></a>ubuntu</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mount.cifs <span class="regexp">//</span><span class="number">10.10</span>.<span class="number">0.61</span><span class="regexp">/jiaxiyang/</span> samba_16 -o user=jiaxiyang</span><br></pre></td></tr></table></figure>

<h3 id="windows"><a href="#windows" class="headerlink" title="windows"></a>windows</h3><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">映射网络驱动器</span><br><span class="line">\\ipaddr\share</span><br><span class="line"><span class="symbol">NOTE: </span>share is [share] in smb.conf</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2022/03/10/Cuda/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/10/Cuda/" class="post-title-link" itemprop="url">Cuda</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-10 02:17:38" itemprop="dateCreated datePublished" datetime="2022-03-10T02:17:38+08:00">2022-03-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-05-16 15:09:36" itemprop="dateModified" datetime="2025-05-16T15:09:36+08:00">2025-05-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Program/" itemprop="url" rel="index"><span itemprop="name">Program</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Program/Cuda/" itemprop="url" rel="index"><span itemprop="name">Cuda</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/03/10/Cuda/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/03/10/Cuda/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>31k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>28 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="install"><a href="#install" class="headerlink" title="install"></a><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=22.04&target_type=deb_network">install</a></h2><ol>
<li>command</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb</span><br><span class="line">sudo dpkg -i cuda-keyring_1.1-1_all.deb</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get -y install cuda-toolkit-12-x</span><br><span class="line">sudo apt-get install -y nvidia-open</span><br></pre></td></tr></table></figure>

<h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><ol>
<li>Scale Up 侧重加速单节点&#x2F;单集群内部的极限性能，Scale Out 侧重扩展系统整体的处理能力。</li>
<li>Scale-Up 专注于在有限范围内挖掘单节点的极致性能，适用于需要低延迟、高带宽的高强度计算；Scale-Out 则致力于通过增减节点来适应更大规模的任务，适用于任务可分布、对弹性和扩展性要求高的应用场景。</li>
<li>1维用int, 多维度用dim3</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int numBlocks = 1;</span><br><span class="line">dim3 threadsPerBlock(N, N);</span><br><span class="line">MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);</span><br></pre></td></tr></table></figure>

<ol>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration">Execution Configuration</a><ul>
<li>&lt;&lt;&lt; &gt;&gt;&gt; 叫做 kernel launch configuration（核函数启动配置）, launch参数：&lt;&lt;&lt;gridDim, blockDim, sharedMemSize, stream&gt;&gt;&gt;  CUDA核函数运行参数</li>
<li>&lt;&lt;&lt; Dg, Db, Ns, S &gt;&gt;&gt;</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#built-in-variables">built-in-variables</a><ul>
<li>gridDim</li>
<li>blockIdx</li>
<li>blockDim</li>
<li>threadIdx</li>
<li>warpSize</li>
</ul>
</li>
<li>在 CUDA 编程中，CTA（Cooperative Thread Array） 是 线程块（Thread Block） 的另一种称呼。</li>
<li>Block and Tile<ul>
<li>Block (线程块) 是CUDA线程层次结构中的一部分，位于网格（grid） 之下。它是CUDA中的一个基本执行单元，由多个线程（thread） 组成，每个线程在一个SM（Streaming Multiprocessor）上执行。</li>
<li>Tile（数据分片） 通常是手动优化时的计算划分方式，用于块状处理数据（类似分块矩阵计算）。它不属于CUDA的核心执行模型，而是开发者用来优化CUDA程序时的概念。</li>
<li>Block是线程的概念，Tile是数据划分的概念; Tile数据并不等于Block处理的数据，如矩阵运算是，A矩阵划分为Tile: bm x bk, Block对应的C数据为bm x bn; Block也可能处理多个tile的数据</li>
</ul>
</li>
<li>block swizzle:<ul>
<li>runtime按idx线性调度：0, 1, 2….</li>
<li>用户自己将idx映射到要处理的block</li>
</ul>
</li>
<li><code>CUDA_LAUNCH_BLOCKING=1</code> 有错误立即停下来，效率会差一点，主要用于调试</li>
<li><a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/cuda/detail/KernelUtils.h">kernel utils</a> 简化写 kernel 流程</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/480719273">手动释放显存</a></li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">apt-get install psmisc</span><br><span class="line">fuser -v /dev/nvidia*</span><br><span class="line">kill -9 ***(PID)</span><br><span class="line">killall python</span><br></pre></td></tr></table></figure>

<ol>
<li>fp32, tf32, fp16, bf16, fp8<br><img src="https://i.ibb.co/vdTGHkJ/txy-EFVOs5-P.png" alt="data type"></li>
<li>NVIDIA GPU 的缓存行（cache line）大小一般是 128 字节。</li>
<li>cache line 又分为 4 个 sectors, 1 个 sector 32B</li>
<li>sector 是 global memory 访问的最小单位，32 个线程一起运行，最少访问 32B</li>
<li>gridDim 划分的是数据，blockDim 划分的是线程：例如: sgemm 分块矩阵乘</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">N=M=<span class="number">1024</span>;</span><br><span class="line">BN=BM=<span class="number">128</span>, TN=TB=<span class="number">8</span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">blockDim</span><span class="params">(BN / TN, BM / TM)</span></span>;  <span class="comment">// block 按线程分为 16x16 thread,threadDim=(16, 16) 每个线程处理8x8数据; x维度是列，y维度是行;</span></span><br><span class="line"><span class="function">dim3 <span class="title">gridDim</span><span class="params">((N + BN - <span class="number">1</span>) / BN, (M + BM - <span class="number">1</span>) / BM)</span></span>; <span class="comment">// grid 按数据分为 8x8 block, blockDim=(8, 8)</span></span><br></pre></td></tr></table></figure>

<ol>
<li><code>GPU通过计算而不是深度缓存层次结构来隐藏访存延迟</code><ul>
<li>当数据访存的时候，就让 warp stall，而后再选一个 warp 进行计算，通过这种方式交错开计算和访存，让访存单元一直忙碌，带宽打满。计算延迟的时候也会让 warp stall</li>
</ul>
</li>
<li>并发的 warp 切换没有开销，因为每个 warp 都分配了硬件资源<ul>
<li>不需要上下文切换</li>
<li>以空间换时间</li>
</ul>
</li>
<li>假如 GPU 有 108 个 SM。每个 SM 可以并行处理多个线程块，具体取决于所使用的内核；为了获得最佳并行化，隐式 GEMM 应包含 108 个图块的整数倍。</li>
<li>gpu sram 带宽为什么比主存大很多：<ul>
<li>并行，多个 SM 访问 shared memory， 如有 80 个 sm，每个 sm4 个 partition， 每个 shared memory 有 32 个 bank， 等效位宽为：<code>80*4*32*8 = 81920</code>, hbm 位宽为 8192， 带宽为 1.5TB&#x2F;s, sram 为 19TB&#x2F;s</li>
<li>shared memory 带宽：<code>2(?) * freq * 32(banks) * 8/8 *4(sm partion) * 80(sm num)</code></li>
</ul>
</li>
<li><code>kernel融合主要是使用sram来减少对显存的访问，注意不是device和host数据搬移</code> 也会减少调度开销</li>
<li>kernel 在编译的时候需要明确 block grid size 吗？不需要， 这些参数通常在运行时通过 CUDA 内核启动语法指定，这提供了更高的灵活性和动态调整的可能性。</li>
<li>nvcc 在翻译单元的顶部隐式包含了 cuda_runtime.h 。</li>
<li>核函数 K（kernel function）就是指 K(x, y) &#x3D; ，其中 x 和 y 是 n 维的输入值，f(·) 是从 n 维到 m 维的映射（通常而言，m&gt;&gt;n）。是 x 和 y 的内积（inner product），严格来说 应该叫欧式空间的标准内积，也就是很多人常说的点积（dot product）。</li>
<li><code>sudo update-alternatives --display cuda</code>显示系统 cuda 版本</li>
<li><code>export PATH=/usr/local/cuda/bin/:$&#123;PATH&#125;</code>找不到 nvcc 可能需要 export PATH</li>
<li>在 CUDA 中，你会以类似于 C&#x2F;C++函数的形式来表达想要在 GPU 上运行的计算，这个函数被称为 kernel。</li>
<li>GPU 函数耗时统计不能只记录一次的，GPU 可能做一些准备工作，教训： nppiResize_8u_C3R 不管大小第一次运行耗时都很大 The cuda context is lazily initialized</li>
<li><code>autotuning</code> 搜索 kernel grid 划分参数(结果不变)，找性能最优</li>
<li>L1 和 shared memory 共享一块存储 可动态分配比例; 可用比例见<a target="_blank" rel="noopener" href="https://www.nvidia.com/content/PDF/nvidia-ampere-ga-102-gpu-architecture-whitepaper-v2.pdf">link</a><ul>
<li>多用 shared memory 就多分点给 shared memory 多用寄存器就多分点给 L1 cache</li>
</ul>
</li>
<li>warp 调度:延时隐藏 只执行 warp 一部分 当 warp 需要等待时 先执行其他 warp</li>
<li>shared memory 和 register 是 SM 中的稀缺资源.</li>
<li>warp 执行类似 simd</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/2023.3/ProfilingGuide/index.html#metrics-hw-model">Hardware Model</a><ul>
<li>对 sm 介绍比较好</li>
<li>Each SM is partitioned into four processing blocks, called SM sub partitions.</li>
<li>一个 SM 又可以由若干个 SMP（SM Partition）组成</li>
<li>A warp is allocated to a sub partition and resides on the sub partition from launch to completion. warp 被分配给子分区，并且从启动到完成都驻留在子分区上。</li>
</ul>
</li>
<li><code>FMA (Fused Multiply Add)</code>: z&#x3D;a*x+y …z,x,y are vectors or scalars</li>
<li><code>4FMA (Quad FMA)</code>: z&#x3D;A*x+z …A is a FP32 matrix; x,z are vectors</li>
<li><code>WMMA: Warp-level Matrix Mulitply and Accumulate (Tensor Core)</code>: Z&#x3D;AB+C …A,B are FP16 matrices; Z,C are FP32</li>
<li>global memory -&gt; shared memory 时，计算每个线程需要搬移的数据量。假如每个线程要搬移 A，B 矩阵为 4 个 single float point, 4x4 &#x3D; 16B<ul>
<li>A_tile（128,8): 256 个线程， 每个线程搬移 4 个数，每行由 2 个线程处理， 假如线程一维索引为 tid； 行 m &#x3D; tid &#x2F; 2 &#x3D; tid &gt;&gt; 1; 列 k &#x3D; (tid % 2) x 4 &#x3D; (tid &amp; 1) &lt;&lt; 2</li>
<li>B_tile（8,128): 256 个线程， 每个线程搬移 4 个数，每行由 32 个线程处理， 假如线程一维索引为 tid； 行 k &#x3D; tid &#x2F; 32 &#x3D; tid &gt;&gt; 5; 列 n &#x3D; (tid % 32) x 4 &#x3D; (tid &amp; 31) &lt;&lt; 2</li>
</ul>
</li>
<li>load&#x2F;store 关键点在行列索引(分别计算各 tile 维度的 m, n, k)， 通过行列可以找到起始地址。<code>#define OFFSET(row, col, ld) ((row) * (ld) + (col))</code></li>
<li>load&#x2F;store memory 的时候先通过行列坐标找到 global 起始点，然后再算偏移，用宏定义来访问矩阵，先找最外层的 tile，再找里层的 tile。</li>
<li>sgemm 分块 A 矩阵 global 到 shared load 时，shared memory 需要列优先排列，一次 load 四个数都寄存器，然后再分别赋值给列。</li>
<li>shred memory double buffering: 在 for 循环里只用 sync 一次<ul>
<li>load tile[0] 到 buffer[0]; sync</li>
<li>for: load tile[i]; compute tile[i-1]; sync</li>
<li>comute tile[-1]; sync</li>
</ul>
</li>
<li>wave 的概念：wave 表示 GPU 上同时执行的 thread block。例如一个 kernel 中 thread block 为 256 线程，每个线程使用了 128 个寄存器，那么在 GV100 上每个 SM 可同时执行 2 个 thread block，GV100 共 80 个 SM，一个 wave 就是 160 个 thread block。</li>
<li>cuda 遵循 IEEE 754 standard for binary floating-point representation； 由于融合和乘加， 其结果与分别乘加结果略有不同 <a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#ieee-754-compliance">ieee-754-compliance</a><ul>
<li>One of the key differences is the fused multiply-add (FMA) instruction, which combines multiply-add operations into a single instruction execution. <code>Its result will often differ slightly from results obtained by doing the two operations separately.</code></li>
</ul>
</li>
<li>每个浮点算术运算都涉及一定量的舍入。因此，算术运算的执行顺序很重要。如果 A、B 和 C 是浮点值，则 (A+B)+C 不能保证等于 A+(B+C)</li>
<li>我们可以将 CUDA 内核编写为许多短 <code>__device__</code> 函数的集合，而不是一个大型的整体 <code>__global__</code> 函数；每个设备功能可以在将它们连接在一起之前进行独立测试。</li>
<li>如果大多数函数都定义为 <code>__host__ __device__</code> 而不仅仅是 <code>__device__</code> 函数，那么这些函数就可以在 CPU 和 GPU 上进行测试，</li>
<li><code>local memory</code>之所以如此命名，是因为它的作用域是线程本地的，而不是因为它的物理位置。事实上，本地存储器位于片外。因此，访问本地内存与访问全局内存一样昂贵。换句话说，名称中的“本地”一词并不意味着访问速度更快。本地内存仅用于保存自动变量。当 nvcc 编译器确定没有足够的寄存器空间来保存变量时，就会执行此操作。可能放置在本地内存中的自动变量是大型结构或数组，它们会消耗太多寄存器空间，并且编译器确定可以动态索引的数组。</li>
<li><code>constent memory</code></li>
<li><code>The NVIDIA Management Library (NVML)</code> is a C-based interface that provides direct access to the queries and commands exposed via nvidia-smi intended as a platform for building 3rd-party system management applications.</li>
<li>可以通过 CUDA_VISIBLE_DEVICES 环境变量重新排列已安装的 CUDA 设备的集合; <code>CUDA_VISIBLE_DEVICES=0,2,1,3</code></li>
<li>Starting with CUDA 11.0, devices of compute capability 8.0 and above have the capability to influence persistence of data in the L2 cache, potentially providing higher bandwidth and lower latency accesses to global memory.</li>
<li>从 Hopper 开始，CUTLASS 3.0 将 Warp Specialization 的概念纳入了内核设计的一部分。线程块被划分为两组 warp，生产者 warp 组和消费者 warp 组。生产者 warp 组使用新的张量内存加速器（TMA）将数据从全局内存加载到共享内存缓冲区中。<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cutlass/blob/main/media/docs/efficient_gemm.md#warp-specialization">link</a></li>
<li>TMA 可以异步一次 load 大块数据到 shared memory， ampere 一次最多只能 load 128 bit 数据(指令限制)</li>
<li>想象 shared memory 和 register 是二维的, bank 不冲突<ul>
<li>shared memory: <code>smem[n][32]</code></li>
<li>register: <code>re[n][4]</code></li>
</ul>
</li>
<li>虽然 block 可以划分为二维 thread, 但调度时按一维调度，每 32 个一个 warp</li>
<li>laneID 是 warp 内第几个线程 threadIdx.x %32</li>
<li>WarpID &#x3D; threadIdx.x &#x2F;32</li>
<li>常量内存位于显存中 片上有缓存 类似于 shared memeory warp 内多个线程读同一个地址最快，不同地址要串行</li>
<li>常量内存对于 kernel 是只读的 对于主机可读写</li>
<li>constant 由主机代码准备 kernel 中直接用</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__constant__ <span class="type">float</span> coef[<span class="number">100</span>];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">setup_coef_constant</span><span class="params">(<span class="type">void</span>)</span></span>&#123;</span><br><span class="line">    <span class="built_in">cudaMemorycpyToSymbol</span>(coef, h_coef, size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>kernel 第三个参数是动态共享内存的大小</li>
</ol>
<h2 id="TMA"><a href="#TMA" class="headerlink" title="TMA"></a><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-data-copies-using-the-tensor-memory-accelerator-tma">TMA</a></h2><ol>
<li>The primary goal of TMA is to provide an efficient data transfer mechanism from global memory to shared memory for multi-dimensional arrays. TMA 的主要目标是为多维数组提供一种从全局内存到共享内存的高效数据传输机制。</li>
<li>TMA 根据tensor_map和coord等信息产生ptr，用于搬数</li>
<li>批量异步复制操作的源和目标地址可以位于共享或全局内存中。这些操作可以将数据从全局内存读取到共享内存，将数据从共享内存写入全局内存，还可以从共享内存复制到同一集群中另一个块的分布式共享内存 。此外，在cluster中时，可以将批量异步操作指定为多播(multicast)。在这种情况下，数据可以从全局内存传输到cluster内多个块的共享内存。</li>
<li>mbarrier（内存屏障）是 CUDA 12 引入的新机制，用于 跨线程块（CTA） 进行同步，主要用于 生产者-消费者（producer-consumer）模式的通信。<ul>
<li>可以多个SM</li>
<li>支持多个线程块（CTA）之间的同步，比 __syncthreads() 更强大。</li>
<li>允许 生产者线程（Producer） 和 消费者线程（Consumer） 在不同的 CTA 中进行数据交换和同步。</li>
</ul>
</li>
<li>Bulk Async Group 是 CUDA 12.2 引入的 批量任务管理机制，允许在 SM（流式多处理器） 内进行任务分配，同时异步调度多个 warp 或 CTA 执行任务.</li>
</ol>
<ul>
<li>单个SM内部</li>
</ul>
<ol>
<li>tensor_map创建完在host memory上 <a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-data-copies-using-the-tensor-memory-accelerator-tma:~:text=Host%2Dto%2Ddevice%20transfer.">link</a><ul>
<li>tensor_map中的tensor_ptr需要指向device global memory上</li>
</ul>
</li>
</ol>
<h2 id="driver"><a href="#driver" class="headerlink" title="driver"></a><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-driver-api/index.html">driver</a></h2><h2 id="runtime"><a href="#runtime" class="headerlink" title="runtime"></a>runtime</h2><h2 id="cuda-graph"><a href="#cuda-graph" class="headerlink" title="cuda graph"></a>cuda graph</h2><ol>
<li>减少 Launch 开销</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/cuda-graphs/">cuda-graphs blog</a></li>
<li>trtexec 有参数指定</li>
</ol>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><ol>
<li>想办法喂饱硬件, 好好调教它，让它努力打工, 工作饱和，不能偷懒</li>
<li>分析计算部件停顿的原因。</li>
<li>主要由下列因素决定：<ul>
<li>算力(peak)</li>
<li>带宽(peak)</li>
<li>指令和访存延迟</li>
</ul>
</li>
<li>性能 roofline bound 是满流水线时分析，一直忙; 指令和访存延迟会使得处理器空闲</li>
<li>一直忙条件：<code>warp 数量 = 延迟 x 吞吐</code>, 如：延迟 20 cycle; SM 吞吐为 64 fma 每 cycle；SM warp 数量为： 20 x 64 &#x2F; 32 &#x3D; 40</li>
<li>Use peak performance metrics to guide optimization</li>
<li>Optimize your algorithm, then unroll loops</li>
<li>Use template parameters to generate optimal code</li>
<li>bandwidth(带宽)和 throughput(吞吐)区别：<ul>
<li>bandwitdh: 理论最大吞吐</li>
<li>throughput: 实际吞吐</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/GTC/PDF/1083_Wang.pdf">Fundamental Optimizations in CUDA</a></li>
<li>kernels are too small -&gt; kernel launch bound; gpu is idle in many time, reason:kernels are too small <a target="_blank" rel="noopener" href="https://github.com/jiaxiyang/CUDA-PPT/blob/main/GTC2020/s21417-faster-transformer.pdf">link</a><ul>
<li>a simple solution: using tensorflow XLA to fuse kernel automaticlly</li>
</ul>
</li>
<li>在 CUDA 编程中，<code>谓词替换</code>通常指的是一种编程技巧，它通过使用谓词（即条件表达式）来代替显式的分支语句（如 if-else 或 switch 语句）。这种技巧可以帮助<code>减少线程发散</code>，从而提高在 GPU 上的并行执行效率。使用条件运算符（如? :）或逻辑运算符（如&amp;&amp;和||）来替换 if-else 语句。这样可以保证所有线程执行相同数量的指令，尽管这些指令的实际作用可能因条件而异。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">__global__ void traditionalBranch(int *data, int value, int threshold) &#123;</span><br><span class="line">    int index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    if (data[index] &gt; threshold) &#123;</span><br><span class="line">        data[index] = value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ void predicateReplacement(int *data, int value, int threshold) &#123;</span><br><span class="line">    int index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    data[index] = (data[index] &gt; threshold) * value + !(data[index] &gt; threshold) * data[index];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>cache locality 表示程序对缓存中数据的访问 locality 和重用情况。如果同一个 warp 中的线程迭代访问同一缓存线(cache line)上的数据(比如遍历一个数组),那么可以最大化利用 cache,称之为良好的 cache locality。</li>
</ol>
<h3 id="papers"><a href="#papers" class="headerlink" title="papers"></a>papers</h3><ol>
<li><a target="_blank" rel="noopener" href="http://impact.crhc.illinois.edu/shared/papers/optimization2008.pdf">Optimization Principles and Application Performance Evaluation</a></li>
</ol>
<h3 id="cuda-performance-guidelines"><a href="#cuda-performance-guidelines" class="headerlink" title="cuda performance-guidelines"></a><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#performance-guidelines">cuda performance-guidelines</a></h3><ol>
<li><code>整体优化策略</code> Overall Performance Optimization Strategies；Performance optimization revolves around four basic strategies:<ul>
<li>Maximize parallel execution to achieve maximum utilization; 最大化并行执行以达到最大利用率；</li>
<li>Optimize memory usage to achieve maximum memory throughput; 优化存储使用，实现最大存储吞吐量；</li>
<li>Optimize instruction usage to achieve maximum instruction throughput; 优化指令使用，实现最大指令吞吐量；</li>
<li>Minimize memory thrashing. 最大限度地减少内存抖动。(减少内存申请释放频率)</li>
</ul>
</li>
<li>Which strategies will yield the best performance gain for a particular portion of an application depends on the performance limiters for that portion;根据情况使用哪种策略，比如 reduction 时受 memory bound，因此我们应该争取峰值带宽</li>
<li>compute-bound 需要争取达到最大算力，memory bound 需要争取达到最大带宽</li>
</ol>
<h3 id="优化技术"><a href="#优化技术" class="headerlink" title="优化技术"></a>优化技术</h3><ol>
<li>memory coalescing<ul>
<li>让连续的线程访问连续的内存地址。这样就有合并机会，多个线程间会合并访存，可能并不是 32 个线程都合并, 比如一个线程访问 4 个 32bit float 数据，8 个线程可合并，8 x 4 x 32 &#x2F; 8 &#x3D; 128Bx</li>
<li>不连续的时候每个数据都需要load一次，合并了之后能减少load次数，完全合并后需要n&#x2F;32次，32个线程的数据一次load进来(不考虑cache的情况)</li>
</ul>
</li>
<li>swizzle</li>
<li>bank conflict</li>
<li>分支优化<ul>
<li>谓词替换</li>
<li>分支预测</li>
<li>循环展开</li>
</ul>
</li>
</ol>
<h3 id="访存优化"><a href="#访存优化" class="headerlink" title="访存优化"></a>访存优化</h3><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/600489819">漫谈高性能计算与性能优化：访存</a></li>
<li>访存优化是第一性原理</li>
<li>当我们在说访存优化的时候，我们具体需要做些什么。总的来说，就是三板斧。<ul>
<li>减少数据搬运<ul>
<li>如何减少数据搬运，最主要的手段就是分块，或者说 tiling。</li>
<li>要尽可能地保证数据连续访问，其中最主要的一个原因就是提高 cache 命中率，从而避免不必要的数据搬运</li>
</ul>
</li>
<li>减少数据访存延时(数据搬运确定)<ul>
<li>减少 bank 冲突</li>
<li>pipeline (double buffer, 预取)</li>
<li>就是切分更多的块，启动更多的 warp 来掩盖访存延时。</li>
</ul>
</li>
<li>保证负载均衡。<ul>
<li>关于负载均衡的话题，主要是在 sparse 里面谈的比较多</li>
</ul>
</li>
</ul>
</li>
<li>如果发现实际带宽比较差，数据搬运效率比较低，这个时候就要去思考，是不是可以有办法，通过分块的一些技巧来减少数据搬运。如果数据搬运不能够再减少了的话，是否可以通过一些方式来提高数据的搬运效率，比如向量化访存、合并访问来提高对 DRAM 的访存性能、避免 bank 冲突来提高对 shared memory 的访存性能、调整分块大小来让更多的 warp 跑起来从而减少访存的延时，如果不是 SIMT 架构，就需要精细地设计各级访存的 pipeline，让访存操作尽可能地 pingpong 起来，从而让访存流水尽可能地连续起来不要被打断。理论大概是这样，但是每一个问题都有着不同的处理方式，每一个问题可能都是不同的瓶颈。总之就是万变不离其宗，准确地评估每一级存储的访存效率然后尽可能地提高每一级的访存效率，尽可能地把访存流水打满，不要有空跑。</li>
<li>其实所谓“加速”或者“性能优化”的本质就是让软件充分利用计算硬件，提升利用率，从而逼近理论性能上限。从这个角度，“通用方法”就是：<code>分析计算部件停顿的原因-选择合理的计算模型减少数据依赖和对流水线的破坏(能兼顾缓解访存墙更好)-通过专用硬件或者结构优化消除剩下的瓶颈，然后不断迭代上述过程，直至各方面因素达到平衡</code>。</li>
<li>cuda gemm 为什么是三级分块，不是四级或者两级。因为 NV 的 GPU 内存结构是三级的，global mem-&gt;shared mem，shared mem-&gt;register。</li>
</ol>
<h3 id="reduction-优化"><a href="#reduction-优化" class="headerlink" title="reduction 优化"></a>reduction 优化</h3><ol>
<li>(great)<a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf">Optimizing Parallel Reduction in CUDA</a><ul>
<li>Memory coalescing</li>
<li>Divergent branching</li>
<li>Bank conflicts</li>
<li>Latency hiding</li>
</ul>
</li>
<li><code>What is Our Optimization Goal?</code> 先确定最大目标 We should strive to reach GPU peak performance Choose the right metric:<ul>
<li>GFLOP&#x2F;s: for compute-bound kernels</li>
<li>Bandwidth: for memory-bound kernels</li>
</ul>
</li>
<li>通过不断迭代优化，从而达到硬件最优性能。</li>
<li>Reductions have very low arithmetic intensity; Therefore we should strive for <code>peak bandwidth</code></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/426978026">中文解析</a></li>
</ol>
<h3 id="elementwise-优化"><a href="#elementwise-优化" class="headerlink" title="elementwise 优化"></a>elementwise 优化</h3><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/488601925">elementwise 优化</a></li>
</ol>
<h2 id="NVCC"><a href="#NVCC" class="headerlink" title="NVCC"></a>NVCC</h2><ol>
<li>交叉编译时用本地 nvcc 就行，不存在 x86 和 aarch64 区别</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">NVIDIA CUDA Compiler Driver NVCC</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#supported-input-file-suffixes">编译过程中各类型文件作用说明</a></li>
<li><a target="_blank" rel="noopener" href="https://www.linmao.dev/joy/1165/">CUDA 编译过程</a></li>
</ol>
<h2 id="PTX-Parallel-Thread-Execution"><a href="#PTX-Parallel-Thread-Execution" class="headerlink" title="PTX(Parallel Thread Execution)"></a>PTX(Parallel Thread Execution)</h2><ol>
<li>a low-level parallel thread execution virtual machine and instruction set architecture (ISA)</li>
<li>PTX 是上承 GPU 编程语言 CUDA C++，下启 GPU 硬件 SASS 指令，可以借助 NVRTC 实现运行时优化，某些层面上来说可以称之为 GPU 设备无关代码，因此 PTX 可以理解为<code>CUDA IR</code></li>
<li>PTX 独立于特定 GPU 架构,可以重用相同的代码适用于不同的 GPU 架构,相当于前端</li>
<li>使用虚拟架构生成 PTX 中间文件，虚拟框架由<code>compute_</code>开头。虚拟架构通常是从大的 GPU 代上控制的，真实框架必须大于等于虚拟框架，真实框架对应真正运行的 GPU，即编译阶段就确定要运行的 GPU 是什么。真实框架由<code>sm_</code>开头。</li>
<li><code>nvcc -ptx program.cu -o _program.ptx -arch=sm_86</code></li>
<li><code>cat program.ptx | cu++filt &gt; program_demangle.ptx</code> demangle ptx</li>
</ol>
<h2 id="SASS-Shader-Assembly"><a href="#SASS-Shader-Assembly" class="headerlink" title="SASS(Shader-Assembly)"></a>SASS(Shader-Assembly)</h2><ol>
<li>真正的机器汇编，由 cubin 文件经过 cuobjdump 工具转换而来。目前没有官方的 sass to cubin 的工具。</li>
<li>cuobjdump 可以用来分析 cubin 文件和 host 文件。而 nvdisasm 只能用来分析 cubin 文件，但是可以得到更多的输出信息。我用的比较多的是 nvdisasm。用来看代码的控制流图。</li>
<li>只有官方反汇编器，没有官方汇编器</li>
<li>generate</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ptxas -arch=sm_86 mma_gemm_demangle.ptx -o mma_gemm.cubin</span><br><span class="line">cuobjdump -sass mma_gemm.cubin &gt; mma_gemm.sass</span><br></pre></td></tr></table></figure>

<h2 id="sync"><a href="#sync" class="headerlink" title="sync"></a>sync</h2><ol>
<li><code>block level</code>: <code>__syncthreads()</code></li>
<li><code>grid level</code>: <code>__threadfence()</code></li>
<li><code>stream level</code>: <code>cudaStreamSynchronize(cudaStream_t stream)</code><ul>
<li>这个函数会阻塞 CPU 线程，直到特定的 CUDA stream 中的所有操作完成。</li>
</ul>
</li>
<li><code>device level</code>: <code>cudaDeviceSynchronize()</code></li>
</ol>
<h3 id="event-sync"><a href="#event-sync" class="headerlink" title="event sync"></a>event sync</h3><ol>
<li>CUDA 事件（CUDA Event）是 CUDA 编程中用于时间测量和流同步的一种机制。</li>
<li>Event 是 stream 相关的一个重要概念，其用来标记 strean 执行过程的某个特定的点。</li>
<li>Cuda api 提供了相关函数来插入 event 到 stream 中和查询该 event 是否完成（或者叫满足条件？）。只有当该 event 标记的 stream 位置的所有操作都被执行完毕，该 event 才算完成。关联到默认 stream 上的 event 则对所有的 stream 有效。</li>
<li>Events 标记了 stream 执行过程中的一个点，我们就可以检查正在执行的 stream 中的操作是否到达该点，</li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_24990189/article/details/89602618">使用 event 测量性能</a><ul>
<li>cudaEventSynchronize</li>
</ul>
</li>
<li>CUDA Events 是 NVIDIA 的 CUDA（Compute Unified Device Architecture）编程模型中的一个特性，用于在 GPU 上进行高精度的计时操作。<code>它们允许开发者在异步任务和内核（kernel）执行中精确地测量时间，帮助分析和优化 CUDA 应用程序的性能</code></li>
<li>主要功能<ul>
<li><code>时间测量</code>：CUDA Events 可以用于测量 CUDA kernel 执行时间，或数据传输操作的持续时间。这对于性能分析和调优非常有用。</li>
<li><code>同步操作</code>：CUDA Events 可以作为同步点，确保在某些操作完成后再执行下一步。例如，可以等待一个 event 完成后再启动另一个 kernel。</li>
</ul>
</li>
</ol>
<h3 id="stream-sync"><a href="#stream-sync" class="headerlink" title="stream sync"></a>stream sync</h3><h2 id="bank-conflict"><a href="#bank-conflict" class="headerlink" title="bank conflict"></a>bank conflict</h2><ol>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/a/3842483/23011500">概念</a></li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Bank    |      1      |      2      |      3      |     ...     |      16     |</span><br><span class="line">Address |  0  1  2  3 |  4  5  6  7 |  8  9 10 11 |     ...     | 60 61 62 63 |</span><br><span class="line">Address | 64 65 66 67 | 68 69 70 71 | 72 73 74 75 |     ...     |     ...     |</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<ol>
<li>Each bank has a bandwidth of 32 bits per clock cycle</li>
<li>shared memory 一次不冲突只能读 32x4B， 看一次读取的数据量，多于 32x4B 需要读取多次 n&#x2F;(32x4)，只要在 n&#x2F;(32x4) 次内读完就是最高效的。</li>
<li>使用 float4 类型访存，用向量化的 LDG.128 和 STG.128 指令一次读 4 个元素，以减少访存指令数， 提高计算访存比</li>
<li>thread tile 时如果 TM 是 8，一个 warp 需要读 32*8 个 TM 的数(shared memory 上)，至少需要 8 次(如果有 32 个 bank)<ul>
<li>如果一个线程一次处理 8 个连续的数，一个 warp 一次只有 4 个线程不 bank 冲突，<ul>
<li>如果一个线程 1 次读 1 个数，一个 warp 一次只读 4 个数， 需要 64 次读完，</li>
<li>如果一个线程一次读 4 个数，一个 warp 一次读 16 个数， 需要读 16 次，</li>
<li>如果一个线程一次读 8 个数，一个 warp 一次读 32 个数，需要读 8 次（最优），但不存在一次读 8 个数的指令。</li>
</ul>
</li>
<li>如果一个线程一次操作 4 个连续的数(处理两个在空间上属于同一 bank 的数)， 那么一个 warp 一次有 8 个线程 bank 不冲突， 一次操作 4*8 个数， 需要 8 次能读完。与 bank 不冲突等效。</li>
</ul>
</li>
<li>这种情况也可以看作是：shared memory 基本单元为 16byte，总 bank 数为 8，冲突与否的分析不在是 32 线程，而变成 4 个 phase 中的不同线程。如果采用 64bit 的访问形式，则相应的基本单元可以看作是 8byte，总 bank 数目为 16，冲突与否的条件变成两个 phase 内的线程是否冲突。</li>
<li>4x32 or 8x16 or 16x8 (16B, 8bank)</li>
</ol>
<h2 id="关键字"><a href="#关键字" class="headerlink" title="关键字"></a>关键字</h2><ol>
<li><code>__restrict__</code> 用于限定指针,表示该指针是唯一访问目标内存的途径。可以避免出现不同指针引用同一内存区域的情况,编译器可以更自由地进行优化。这意味着编译器可以假设这个指针没有别名（alias），即没有其他指针指向相同的内存位置。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">myKernel</span><span class="params">(<span class="type">float</span>* __restrict__ ptrA, <span class="type">float</span>* __restrict__ ptrB, <span class="type">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 内核代码，假设 ptrA 和 ptrB 指向不重叠的内存区域</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="occupancy-设计"><a href="#occupancy-设计" class="headerlink" title="occupancy 设计"></a>occupancy 设计</h2><ol>
<li>(重要) <code>最理想的情况下为 sm max threads 个 thread 都分配资源，占用率 100%， 但受限于 Max warps or max blocks per SM, registers per SM, shared memory per SM, register, 占用率可能不到 100%</code></li>
<li>想得到令人满意的 GPU 性能<code>关键是找到合适的group size与资源的平衡点</code></li>
<li><code>--ptxas-options=-v</code> or <code>-Xptxas -v</code> or <code>--resource-usage</code> 加上编译选项， 显示 register， shared memory 使用<ul>
<li><code>nvcc  -Xptxas=&quot;-v&quot; --ptxas-options=-v -O3 -o my_sgemm my_sgemm.cu -lcublas  2&gt;&amp;1 | c++filt</code> demangle</li>
</ul>
</li>
<li>nishgt compute 里 occupancy 有详细显示</li>
<li><a target="_blank" rel="noopener" href="https://xmartlabs.github.io/cuda-calculator/">cuda-calculator</a> 填入数值，计算 occupancy</li>
<li>注意 shared memory 是动态配置的，可以尝试改变 shared memory 大小来提升性能</li>
</ol>
<h2 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h2><ol>
<li>cudaStream_t 和 cudaEvent_t 都是数字类型， stream 默认为 0，如果使用默认 stream，直接用 0，如果使用其他 stream，需要 <code>cudaStream_t stream; cudaStreamCreate(&amp;stream);doing_something(); cudaStreamDestroy(stream);</code></li>
</ol>
<figure class="highlight c++"><figcaption><span>cuda_runtime.h</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="type">int</span> cudaEvent_t;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">int</span> cudaStream_t;</span><br></pre></td></tr></table></figure>

<ol>
<li>stream 主要为了隐藏 host device 之间数据搬移的延迟，不是内存和计算</li>
<li>CUDA 流表示一个 GPU 操作队列，该队列中的操作将以添加到流中的先后顺序而依次执行。</li>
<li>stream 作用：在 Stream 的帮助下，CUDA 程序可以有效地将内存读取和数值运算并行，从而提升数据的吞吐量。 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/51402722">link</a><br>由于 GPU 和 CPU 不能直接读取对方的内存，CUDA 程序一般会有一下三个步骤：1）将数据从 CPU 内存转移到 GPU 内存，2）GPU 进行运算并将结果保存在 GPU 内存，3）将结果从 GPU 内存拷贝到 CPU 内存。</li>
<li>cuda7 可以开启每个线程有一个默认 stream, 之前每个设备有一个 stream <a target="_blank" rel="noopener" href="https://developer.nvidia.com/zh-cn/blog/gpu-pro-tip-cuda-7-streams-simplify-concurrency/">gpu-pro-tip-cuda-7-streams-simplify-concurrency&#x2F;</a><ul>
<li><code>nvcc --default-stream per-thread ./pthread_test.cu -o pthreads_per_thread</code>需要加编译选项</li>
</ul>
</li>
</ol>
<h2 id="cuda-grammer"><a href="#cuda-grammer" class="headerlink" title="cuda grammer"></a>cuda grammer</h2><ol>
<li><p>在 CUDA 编程中，高效的并行算法往往需要线程协作(threads cooperate)以及共享数据(share data)来完成集体计算(collective computations)。要共享数据，线程间必然会涉及同步，而共享的粒度因算法而异，因此线程间的同步应尽量足够灵活，比如开发者可以显示地指定线程间同步，这样就可以确保程序的安全性、可维护性和模块化设计。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#cooperative-groups:~:text=do%20not%20match.-,8.%20Cooperative%20Groups,%EF%83%81,-8.1.%20Introduction">Cooperative Groups</a></p>
<ul>
<li>CUDA Cooperative Groups 提供了一种更灵活、更高效的线程协作方式，适用于高性能并行计算。它增强了传统 __syncthreads() 的能力，并支持 warp 级、block 级、grid 级的同步，在某些场景下可以显著提升计算效率。</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#function-execution-space-specifiers">Function Execution Space Specifiers</a></p>
<ul>
<li><code>__global__</code> 在设备上执行，在主机上调用</li>
<li><code>__device__</code> 在设备上执行，在设备上调用</li>
<li><code>__host__</code> 在主机上执行，在主机上调用</li>
<li>不填默认在<code>__host__</code></li>
<li>__global__和__host__执行空间说明符不能一起使用。</li>
<li>__device__和__host__执行空间说明符可以一起使用，在这种情况下，函数将针对主机和设备分别进行编译。</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#shared:~:text=7.2.3.-,__shared__,-%EF%83%81">shared</a></p>
<ul>
<li>要共享数据，线程间必然会涉及同步   </li>
<li>__shared__： <code>__shared__ unsigned int u1 = 1;</code></li>
<li>extern:<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ <span class="type">float</span> array[];</span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">func</span><span class="params">()</span>      <span class="comment">// __device__ or __global__ function</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">short</span>* array0 = (<span class="type">short</span>*)array;</span><br><span class="line">    <span class="type">float</span>* array1 = (<span class="type">float</span>*)&amp;array0[<span class="number">128</span>];</span><br><span class="line">    <span class="type">int</span>*   array2 =   (<span class="type">int</span>*)&amp;array1[<span class="number">64</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>算index的时候需要用到built-in variables, 由Index确定要处理的数据</p>
<ul>
<li>blockIdx</li>
<li>blockDim</li>
<li>threadIdx</li>
<li>总体的原则是 global_index &#x3D; block首地址的index + local_index <code>int tid = blockIdx.x * blockDim.x + threadIdx.x;</code></li>
</ul>
</li>
<li><p><code>int tid = blockIdx.x * blockDim.x + threadIdx.x; =&gt; int index = h * W + w;</code></p>
</li>
<li><p>所有的 kernel 函数返回类型都是 void</p>
</li>
<li><p><code>&lt;&lt;&lt; M , T &gt;&gt;&gt;</code> Which indicate that a kernel launches with a grid of M thread blocks. Each thread block has T parallel threads.</p>
</li>
<li><p>dim3 threadsPerBlock(16, 16); dim3 numBlocks(N &#x2F; threadsPerBlock.x, N &#x2F; threadsPerBlock.y); MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);</p>
</li>
<li><p>NOTE: dim3是按(x, y, z)设置的，矩阵输入数据是按(y1, x1)索引的</p>
<ul>
<li>dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE); name: blockDim,</li>
<li>dim3 dimGrid(B.width &#x2F; dimBlock.x, A.height &#x2F; dimBlock.y); name: gridDim</li>
</ul>
</li>
<li><p>首先确定thread和block处理的数据shape, 根据input shape， 推出gridDim(blocksPerGrid)</p>
<ul>
<li>注意cuda的block处理的数据shape和threadsPerBlock的区别，threadsPerBlock和一个thread处理的数据shape共同确定一个block处理的数据shape，等效triton的BLOCK_SIZE</li>
<li>triton tuning 一般是tune 一个block要处理的数据大小, block处理的数据大小确定也能算出一个thread处理的数据大小</li>
</ul>
</li>
<li><p><code>vectorAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;</code></p>
</li>
<li><p>可以认为 M, T 对应图片的 H, W; 一个 thread 对应一个像素点；一个 block 对应一行，一个 grid 对应一张图片</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cuda-samples/blob/master/Common/helper_cuda.h#L595">checkCudaErrors</a> helper_cuda.h</p>
</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">check</span><span class="params">(T result, <span class="type">char</span> <span class="type">const</span> *<span class="type">const</span> func, <span class="type">const</span> <span class="type">char</span> *<span class="type">const</span> file,</span></span></span><br><span class="line"><span class="params"><span class="function">           <span class="type">int</span> <span class="type">const</span> line)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (result) &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;CUDA error at %s:%d code=%d(%s) \&quot;%s\&quot; \n&quot;</span>, file, line,</span><br><span class="line">            <span class="built_in">static_cast</span>&lt;<span class="type">unsigned</span> <span class="type">int</span>&gt;(result), _cudaGetErrorEnum(result), func);</span><br><span class="line">    <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// This will output the proper CUDA error strings in the event</span></span><br><span class="line"><span class="comment">// that a CUDA host call returns an error</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> checkCudaErrors(val) check((val), #val, __FILE__, __LINE__)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>cutil.h NVIDIA 公司在 CUDA5 之后便不再使用 cutil.h <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/EGLSync_CUDAEvent_Interop.cu#L83">CUDA_SAFE_CALL </a></li>
<li><a target="_blank" rel="noopener" href="https://bohipat.wordpress.com/2014/07/11/replacing-cutil-in-cuda-5-0/">replacing-cutil-in-cuda-5-0</a></li>
</ol>
<h2 id="tensor-core"><a href="#tensor-core" class="headerlink" title="tensor core"></a>tensor core</h2><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/620185229">4 种 tensor core 调用方法</a><ul>
<li>WMMA (Warp-level Matrix Multiply Accumulate) API</li>
<li>WMMA PTX (Parallel Thread Execution)</li>
<li>MMA (Matrix Multiply Accumulate) PTX</li>
<li>SASS</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/data-center/tensor-cores/">tensor-cores</a></li>
<li><code>--set roofline</code>能看到 tensor core roofline; 例如运行<code>cuda-samples/Samples/3_CUDA_Features/cudaTensorCoreGemm</code></li>
<li>cuda-samples&#x2F;Samples&#x2F;3_CUDA_Features 包含多个 tensor core 实例</li>
<li><code>Samples/3_CUDA_Features/cudaTensorCoreGemm</code>比<code>Samples/0_Introduction/matrixMul</code> 计算性能高很多<ul>
<li>cudaTensorCoreGemm 测试的是 fp16 性能</li>
</ul>
</li>
<li>cublas 满足特定条件才会使用 tensor core <a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cublas/index.html#tensor-core-usage">link</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc">Tensor Core Requirements</a></li>
<li><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1893665">FP32 vs TF32</a><ul>
<li>tf32 整数部分精度与 fp32 相同，小数部分与 fp16 相同， 只用了 19 位</li>
<li>包含 Amphere 架构性能</li>
<li>A100、H100 tf32 算力比 fp32 算力高 8 倍左右</li>
<li>3090 上 tf32 算力跟 fp32 算力相同</li>
<li>最新 trtexec 默认是 tf32，注意和 python fp32 计算比较时结果误差可能较大</li>
</ul>
</li>
</ol>
<h2 id="wmma-vs-mma"><a href="#wmma-vs-mma" class="headerlink" title="wmma vs mma"></a>wmma vs mma</h2><ol>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-multiply-accumulate-instructions">warp-level-matrix-multiply-accumulate-instructions</a></li>
</ol>
<h3 id="tenosr-core-和-cuda-core"><a href="#tenosr-core-和-cuda-core" class="headerlink" title="tenosr core 和 cuda core"></a>tenosr core 和 cuda core</h3><ol>
<li>计算层级：CUDA Core 是线程级别，Tensor Core 是 warp 级别</li>
<li>计算维度：CUDA Core 是一维逐点计算，Tensor Core 是二维逐 tile 计算</li>
<li>CUDA Core 是为通用计算设计，而 Tensor Core 是为特定类型的计算（主要是深度学习中的矩阵运算）优化。</li>
<li>在 NVIDIA 的某些 GPU 架构中，例如 Volta、Turing 和 Ampere，CUDA Core 和 Tensor Core 共同存在。它们可以根据计算任务的性质协同工作，提高整体的计算效率。</li>
<li>在执行深度学习任务时，Tensor Core 可以显著加速计算过程，相较于仅使用 CUDA Core，能实现更快的训练和推理速度。</li>
<li>RT core 用于光线追踪</li>
<li>芯片手册中有 cuda core 算力和 tensor core 算力</li>
<li>利用 tensor core 才能达到最大算力</li>
</ol>
<h2 id="build"><a href="#build" class="headerlink" title="build"></a>build</h2><ol>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#application-compatibility">application-compatibility</a></li>
<li><code>-arch=sm_70</code> is a shorthand for <code>-arch=compute_70 -code=compute_70,sm_70</code> (which is the same as <code>-gencode arch=compute_70,code=\&quot;compute_70,sm_70\&quot;</code>)</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-gpus">Your GPU Compute Capability</a> 包含各种 gpu arch</li>
</ol>
<h2 id="cuda-samples"><a href="#cuda-samples" class="headerlink" title="cuda samples"></a><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cuda-samples">cuda samples</a></h2><ol>
<li>可以全部 sample 一起编译</li>
<li><code>cuobjdump -all  ./matrixMulDrv</code>可以看可执行程序 arch 等信息</li>
<li><code>make SMS=&quot;86&quot;</code>选择 arch</li>
<li><code>make dbg=1</code> debug 编译</li>
<li><code>Samples/1_Utilities/bandwidthTest</code> 可以查看 host &lt;-&gt; memory 之间传输速度</li>
<li>(good)<code>Samples/1_Utilities/deviceQuery</code> 可以查看设备信息, 包含 arch 信息, 多少 sm，每个 sm 多少 cuda core</li>
<li>11.6 之后代码放在 github 上</li>
<li><a target="_blank" rel="noopener" href="https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/">hello world</a></li>
<li><code>/usr/local/cuda-11.4/samples</code> tree -L 2</li>
<li><code>/usr/local/cuda-10.2/samples/0_Simple/vectorAdd</code></li>
<li><code>nvprof ./vectorAdd</code> 查看 kenerl 耗时</li>
</ol>
<h2 id="CUDALibrarySamples"><a href="#CUDALibrarySamples" class="headerlink" title="CUDALibrarySamples"></a><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/CUDALibrarySamples">CUDALibrarySamples</a></h2><ol>
<li>cublas</li>
<li>cutlass</li>
<li>npp</li>
</ol>
<h3 id="cuda-info"><a href="#cuda-info" class="headerlink" title="cuda info"></a>cuda info</h3><ol>
<li><a target="_blank" rel="noopener" href="https://linuxconfig.org/how-to-get-cuda-cores-count-on-linux">查看 cuda core</a><br><code>cd /usr/local/cuda-11.4/samples/1_Utilities/deviceQuery &amp;&amp; make &amp;&amp; ./deviceQuery</code></li>
<li>bandwith test<br><code>cd /usr/local/cuda-11.4/samples/1_Utilities/bandwidthTest &amp;&amp; make &amp;&amp; ./bandwidthTest</code></li>
</ol>
<h2 id="NVIDIA-Developer-Tools"><a href="#NVIDIA-Developer-Tools" class="headerlink" title="NVIDIA Developer Tools"></a><a target="_blank" rel="noopener" href="https://developer.nvidia.com/tools-overview">NVIDIA Developer Tools</a></h2><ol>
<li>各工具关系<br><img src="https://i.ibb.co/2qN87rv/QVJcq2r-QQ3.png" alt="tools"></li>
</ol>
<h3 id="nsight-system"><a href="#nsight-system" class="headerlink" title="nsight system"></a>nsight system</h3><ol>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/nsight-systems/get-started">cuda toolkit 不自带 需要下载安装</a><ul>
<li>wget 下载 linux CLI Only deb, dpkg 安装</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-systems/InstallationGuide/index.html#package-manager-installation">package-manager-installation</a><ul>
<li>apt install</li>
</ul>
</li>
</ul>
</li>
<li>viztracer + nsys + ncu + nvtx 分析性能瓶颈</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#python-profiling">nsight system python-profiling</a></li>
<li>分析系统性能， help you to pinpoint performance issues and identify optimization opportunities; 帮助分析性能问题和识别优化机会<ul>
<li>gpu kernel 运行时间太长</li>
<li>某些 process cpu 处理时间太长</li>
<li>cpu gpu pcie copy 耗时过大</li>
</ul>
</li>
<li>GPU timeline 方便分析</li>
<li>profiling 可以简单地分为粗粒度和细粒度。粗粒度主要是判断瓶颈是不是在 GPU 上，具体又是哪个 kernel，典型代表就是 nsight system 工具，会显示出整个程序的 timeline。可以从 timeline 上直接清晰明了地看到瓶颈是在 CPU 还是 GPU，如果是 GPU，那又是在 GPU 的哪个 kernel 上。</li>
<li>如果是 timeline 中 GPU kernel 的占比很小，CPU 占比很大，那说明瓶颈在 CPU 侧，需要注意是不是数据读取花了太多时间。如果 GPU kernel 的占比很大，说明瓶颈在 GPU 侧，需要重点花精力去优化 GPU kernel 实现。还有一种情况是，如果数据一直放在 GPU 上，但是 kernel 的时间占比不是特别多，那可能是因为 kernel 本身不太耗时，可能只运行了 4us。但 kernel lauch 就花了 6us。这个时间就要想着采用 kernel fusion 的方式，尽可能地在一个 kernel 里面多干点活。</li>
<li>点击时注意竖线上的小三角号, 表示关联</li>
<li>从结果分析看多个 stream 下 kernel 可以同时运行<ul>
<li>all stream 或者 kernels 显示不出所有的 kernel 运行，起始位置被其他 kernel 覆盖的检测不出来</li>
<li>all stream 显示不出的 kernel 可能在被隐藏的 stream 里，鼠标放到 kernel 上能显示出在第几个 stream</li>
</ul>
</li>
<li><code>enqueue</code>异步接口没有很快返回的原因：<ul>
<li>nsight system 上看 tensorrt node 调用， 对应 cuda api 里有 cudaStreamSync()函数， 会阻塞 cpu 导致 enqueue 不返回</li>
<li>有多个 stream sync, 每个 stream sync 执行之后之前通过 cuda api 调用的 kernel 都已执行完</li>
<li>为什么要多个 stream？node 不相关可以并行加速, 可以看到 kernel 执行时间有并行， 为什么要 sync? 后面的节点需要前面的节点都执行完，有关联</li>
<li>点击 tensorrt 下的 node 可以看到 node 执行信息</li>
</ul>
</li>
<li>打开文件注意生成 log 时的错误</li>
<li>gui 可以远程 profiling， 将 nsys 安装到 target 机器, 类似 compute<ul>
<li><code>~/.local/share/nsight_systems/nsys</code>安装路径</li>
</ul>
</li>
<li><code>nsys profile</code> 类似 perf record 来记录信息<ul>
<li><code>nsys profile --trace=cuda --gpu-metrics-device all</code></li>
</ul>
</li>
<li><code>--trace</code> 可以看看参数：cuda,nvtx, cudnn, python-gil …</li>
<li><code>nsys status --all</code>打印 nsys 支持的状态，比如是否支持采集 cpu 信息</li>
<li>nsys stats 类似 perf stats 来查看统计信息<ul>
<li><code>nsys stats report1.nsys-rep</code></li>
<li><code>nsys stats --report cuda_gpu_trace report1.nsys-rep</code></li>
</ul>
</li>
<li>gui summary 里可以看 log 具体执行命令</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#python-profiling">python-profiling</a><ul>
<li>Python Sampling requires Python version 3.9 or later. Python Sampling is therefore disabled.</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#cuda-trace">跟踪 cuda</a><ul>
<li><code>--trace=cuda</code></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#gpu-metrics">可以收集 gpu-metrics</a><ul>
<li>Is my GPU idle?</li>
<li>Is my GPU full? Enough kernel grids size and streams? Are my SMs and warp slots full?</li>
<li>Am I using TensorCores?</li>
<li>Is my instruction rate high?</li>
<li>Am I possibly blocked on IO, or number of warps, etc</li>
</ul>
</li>
<li>分析系统性能</li>
<li><code>nvprof</code> 旧版本</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html">user guide</a></li>
<li>NsightSystems-2023.2.1.122-3259852.msi 安装包</li>
<li>Nsight_Systems_User_Guide_2023.2.1.122-3259852.pdf 文档</li>
<li>鼠标放到 kernel 上有 kernel 详细信息，<ul>
<li>24.5.1 版本之后点击 kernel，可以在左侧(蓝边)找到关联的事项，如 cuda 调用对应的 kernel</li>
<li>包括执行时间</li>
<li>latency：launch latency, 与执行时间不一样，latency 是 api 调用到 kernel 开始执行时间<ul>
<li><a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/nsys-timeline-end-start-is-not-the-same-as-latency/238043">NSys Timeline: End - Start is not the same as latency</a></li>
<li>CUDA kernel launch latency could be defined as the time range from the beginning of the launch API call to the beginning of the kernel execution.</li>
<li>执行的是 <code>cudaStreamSynchronize</code>, 没执行这个函数之前，stream 中的 kernel 不会 launch</li>
</ul>
</li>
<li>gird, block 设置;(注意，同一个 stream 下相同函数调用可能设置不一样导致时间不同)</li>
<li>一个线程用多少 register</li>
<li>理论 occupancy, 打开 gpu metrics 可以看对应的实际 occupancy</li>
<li>注意各种颜色</li>
</ul>
</li>
<li>可以在 thread 上看到 <code>cpu call stack</code><ul>
<li>每个线程对应行分层的最后一层 <code>sampling point</code></li>
<li>gpu 空闲时看 CPU 采样点 可以知道 CPU 在干啥</li>
<li>是否可以生成火焰图？</li>
</ul>
</li>
<li>timeline 上点击 stream 下的 tensorrt node， 可以显示对应的 kernel 执行和 cuda api 调用时间点, 注意竖线上的小三角号</li>
<li>tensorrt 多个维度来看<ul>
<li>thread</li>
<li>stream</li>
<li>cuda</li>
</ul>
</li>
<li>左上角 timeline view 可以选择 analysis summary，有各种总结</li>
<li>左侧右键选<code>show in events view</code>， 可以看具体时间, 可以在 all 上操作，看所有 event 运行时间</li>
<li>右键 reset room 显示全部</li>
<li><code>shift + mouseleftdoubleclick</code> timeline 可以找到对应 event 在 event view 位置, 刚打开时可以按 name 排序，会看到相关算子集中到一起，再按其他指标排序会混乱</li>
<li><code>ctrl + mouseleftdoubleclick</code> timeline 可以 fit to screen</li>
<li><code>backspace</code> timeline 可以 undo room</li>
<li><code>ctrl + mouseleftdoubleclick</code> 可以找到 event view 对应的 timeline 位置</li>
<li><code>sudo nsys profile &lt;app&gt;</code></li>
<li><code>nsys stats report1.nsys-rep</code> 输出各种 report</li>
<li>可以看 cpu 执行情况， tensort 可以看详细算子耗时，也有对应 cuda 执行情况</li>
<li>analysis summary 中有各个线程的 cpu 利用率总结</li>
<li>可以关注 cpu 空闲的地方，为什么会空闲(同步数据？)</li>
<li>可以缩小看颜色占比，关注占比大的模块</li>
<li>cudaMemcpy 会阻塞 cpu 执行， 可以多注意 cudaMemcpy 影响</li>
<li>cudaStreamSynchronize 是 CUDA API 中的一个函数，用于等待指定的 CUDA 流上的所有 CUDA 核函数执行完毕。当 CUDA 核函数被执行时，它们会被添加到一个 CUDA 流中，这些核函数的执行可能是异步的，也可能是同步的，具体取决于如何在代码中调用它们。当我们调用 cudaStreamSynchronize 时，它将会阻塞当前 CPU 线程，直到指定的流上的所有核函数都执行完毕。</li>
</ol>
<h3 id="nsight-compute"><a href="#nsight-compute" class="headerlink" title="nsight compute"></a>nsight compute</h3><ol>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#enable-docker-collection">enable-docker-collection</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/nsight-compute">cudatoolkit 自带</a></li>
<li><code>balance throughput</code> compute and memory throughput are near; 平衡比较重要，不平衡时说明使用率较高的是瓶颈</li>
<li>Both SM (Compute) and Memory SOL report the categories’ throughput as the achieved percentage of utilization with respect to the theoretical maximum, i.e. the “Speed Of Light”. Both metrics are composed of sub-metrics, with the respective highest contributor defining the resulting value. The Breakdown tables below the chart can be used to identify all such contributors and their values. SM（计算）和内存 SOL 都将类别的吞吐量报告为相对于理论最大值（即“speed of light”）所实现的利用率百分比</li>
<li>SOL(speed of light): 相对于理论最大值的比例</li>
<li>有开销 <a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/2023.3/ProfilingGuide/index.html#overhead">overhead</a></li>
<li><code>metrics</code> 是指性能指标，这些指标用于衡量 CUDA 应用程序的性能和行为。性能指标可以包括各种硬件级别的统计数据，如内存访问效率、计算操作的执行时间、流处理器（SM）的利用率、寄存器使用情况、分支效率等等。</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/nvidia-development-tools-solutions-err_nvgpuctrperm-permission-issue-performance-counters">permission 问题</a><ul>
<li>可以增加临时权限</li>
</ul>
</li>
<li>分析 kernel 性能, 可以选 kernel</li>
<li>NVIDIA Nsight Compute is an interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool. In addition, its baseline feature allows users to compare results within the tool. NVIDIA Nsight Compute provides a customizable and data-driven user interface and metric collection and can be extended with analysis scripts for post-processing results.</li>
<li>需要 windows 客户端通过 connect 将 ncu 送到开发环境<ul>
<li>可以通过 activity 复制命令到板端执行</li>
<li>metrics 可以选择 Sets 和 rules</li>
</ul>
</li>
<li>profile -&gt; metrics details<ul>
<li>点击统计界面某个 metrics 可以看 metrics 详细信息</li>
</ul>
</li>
<li><code>--import-source yes --source-folders ./</code> 导入 source</li>
<li><code>ncu --replay-mode application --set full  ./preprocess</code> 详细信息显示到命令行<ul>
<li>Duration 为 kernel 执行时间</li>
</ul>
</li>
<li><code>ncu -k matrixMul --print-summary per-gpu ./test</code> 查看某个 kernel 信息</li>
<li><code>/tmp/var/target/linux-desktop-glibc_2_11_3-x64/ncu --config-file off --export &quot;/tmp/var/test&quot; --force-overwrite --section-folder /tmp/var/sections --set full ./test</code></li>
<li><code>ncu --set full -f --export nsight_compute ./test</code></li>
<li><code>docker run -itd -v /mnt:/mnt -p 30022:22 --user root --gpus all --name=Ubuntu20.04-CUDA-admin --shm-size 2g --cap-add=SYS_ADMIN nvidia/cuda:11.4.3-cudnn8-devel-ubuntu20.04</code> 尽量使用官方 docker<ul>
<li>需要 <code>--gpus all --cap-add=SYS_ADMIN</code></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/index.html">nsight-compute docs</a><ul>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html">ProfilingGuide</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html">user manual</a></li>
</ul>
</li>
<li>左上角可以显示：<ul>
<li>session: gpu cpu 等信息</li>
<li>detailed：overview, compute, memory 等</li>
<li>source: 汇编代码及耗时</li>
<li>summary: 耗时，compute and memory throughput; 底下有优化建议</li>
</ul>
</li>
<li>可以添加 baseline，对比多次结果, 分析结果变化</li>
<li><code>ncu --set roofline</code>可以测量详细 roofline</li>
<li><code>ncu --metrics smsp__inst_executed.sum ./matrixMul</code> 打印 metrics</li>
<li><code>--set roofline</code>能看到 tensor core roofline; 例如运行<code>cuda-samples/Samples/3_CUDA_Features/cudaTensorCoreGemm</code></li>
</ol>
<h4 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h4><ol>
<li>The application returned an error code (9).<ul>
<li><code>ncu --replay-mode &lt;application/kernel&gt;</code> 加参数； 见<a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/nsight-profiling-crashes-with-error-code-9/230094/5">link</a></li>
<li>可以使用<code>–replay-mode application</code>切换到应用程序重播。 这避免了内存存储需要重放。</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/2023.3/ProfilingGuide/index.html#replay">replay</a><ul>
<li>kernels might need to be replayed one or more times, since not all metrics can be collected in a single pass</li>
<li>the number of metrics originating from hardware (HW) performance counters that the GPU can collect at the same time is limited.</li>
<li>kernal replay 只重跑 kernel, application replay 重跑应用</li>
</ul>
</li>
</ol>
<h4 id="metrics"><a href="#metrics" class="headerlink" title="metrics"></a><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/2023.3/ProfilingGuide/index.html#metrics-guide">metrics</a></h4><ol>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/2023.3/ProfilingGuide/index.html#metrics-reference">metrics-reference</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/2019.5/NsightComputeCli/index.html#nvprof-metric-comparison">nvprof-metric-comparison</a></li>
<li><code>ncu --devices 0 --query-metrics &gt;my_metrics.txt</code> 查看 metrics</li>
</ol>
<h4 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h4><ol>
<li>每项下面会有建议</li>
<li>compute 分析延迟很关键 目标是计算要掩盖延迟; 分析 stall 原因，stall 就是 warp 闲着</li>
<li>避免 bank 冲突能解决指令的延迟</li>
<li>overview(GPU speed of light throughput)<ul>
<li><code>用于查看计算和内存吞吐对理论值的占比以及roofline</code></li>
<li>High-level overview of the <code>throughput for compute and memory</code> resources of the GPU 主要关注计算和内存</li>
<li>Achieved compute throughput and&#x2F;or memory bandwidth below 60.0% of peak typically indicate latency issues.</li>
<li>低于 60% 表明有延迟问题, 例如：指令有延迟，可以看 scheduler statistics 和 warp state statistics 进一步分析;延迟问题可能是由于 occupancy 较低， 也可能是指令执行延迟太大，无法隐藏;</li>
<li>roofline</li>
</ul>
</li>
<li>comupte workload<ul>
<li><code>用于分析 SM 计算资源使用情况</code></li>
<li>IPC</li>
<li>指令执行占比</li>
<li>LSU: load store unit</li>
</ul>
</li>
<li>memory workload<ul>
<li><code>用于分析 GPU memory 使用情况</code></li>
<li>可以选择看 transfer size 和 throughput</li>
<li>要提升 cache 命中率</li>
<li>多用 shared memory(可作为中间结果)</li>
<li>多种 memory<ul>
<li>global</li>
<li>local: 线程私有的。local memory 不是物理空间，而是 global memory 的一部分，所以延时较大。</li>
<li>texture: 只读?</li>
<li>surface</li>
<li>load global stroe shared</li>
<li>shared</li>
</ul>
</li>
</ul>
</li>
<li>scheduler statistics<ul>
<li><code>用于分析每个 scheduler active, eligible, issue warp 情况</code></li>
<li>Issued Warp Per Scheduler: 平均每个 cycle 发射的 warp 数</li>
<li>On cycles with no eligible warps, the issue slot is skipped and no instruction is issued. Having many skipped issue slots indicates poor latency hiding.</li>
<li>Out of the maximum of 12 warps per scheduler(Ampere 1 个 SM 有 4 个 scheduler), this kernel allocates an average of 2.00 active warps per scheduler, but only an average of 0.07 warps were eligible(合格的) per cycle.</li>
<li>可以看出平局每个 sm 有几个 warps; 参考可以看 Theoretical Occupancy 是多少，有可能受 regitster 和 shared memory 等限制</li>
<li>Eligible warps are the subset of active warps that are ready to issue their next instruction.</li>
</ul>
</li>
<li>warp state statistics<ul>
<li><code>用于分析 warp stall 原因</code></li>
<li>Check the Warp Stall Sampling (source counters 中) table for the top stall locations in your source based on sampling data. 查看 stalll source 位置</li>
<li>statll 解决办法： Try to increase the number of active warps to hide the existent latency or try changing the instruction mix to utilize all available pipelines in a more balanced way.</li>
<li>The warp cycles per instruction define the latency between two consecutive instructions. 每条指令的 warp 周期定义两个连续指令之间的延迟</li>
<li>可以查看两个 warp instruction 之间 cyles 组成： stall math pipe throttle, stall mio throttle;</li>
</ul>
</li>
<li>instructions statistics<ul>
<li><code>用于查看指令的类型和执行次数</code></li>
<li>Statistics of the executed low-level assembly instructions (SASS). SASS 指令统计</li>
<li>统计执行的指令数，可以看出哪些指令执行的较多</li>
</ul>
</li>
<li>launch statistics<ul>
<li><code>用于查看 grid, block 设置和 register, shared memory 使用情况</code></li>
</ul>
</li>
<li>occupancy<ul>
<li><code>用于查看occupancy情况及限制原因</code></li>
<li>Occupancy is the ratio of the number of active warps per multiprocessor to the maximum number of possible active warps.</li>
<li>可以看出理论占用率及不能到 100%的原因</li>
<li>一个 warp 中用太多 register 和 shared memory 会影响 Occupancy， Occupancy 会影响 scheduler， 进而会影响延迟隐藏</li>
<li>Occupancy 是 CUDA 编程中一个重要的性能指标,它表示 GPU 中 Streaming Multiprocessor (SM)上的处理单元被运用的比例。</li>
<li>右上角点开 table，可以可视化</li>
</ul>
</li>
<li>source counters<ul>
<li><code>用于分析分支指令是否有影响，是否合并访存</code></li>
<li>Source metrics, including branch efficiency and sampled warp stall reasons.</li>
</ul>
</li>
</ol>
<h3 id="NVTX"><a href="#NVTX" class="headerlink" title="NVTX"></a>NVTX</h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/karpathy/llm.c/blob/2ddf128365773670ceb4e76ab7b04ab671edda64/llmc/cuda_common.h#L108-L117">(good)llm.c nvtx 使用</a></li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NvtxRange</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">NvtxRange</span>(<span class="type">const</span> <span class="type">char</span>* s) &#123; <span class="built_in">nvtxRangePush</span>(s); &#125;</span><br><span class="line">    <span class="built_in">NvtxRange</span>(<span class="type">const</span> std::string&amp; base_str, <span class="type">int</span> number) &#123;</span><br><span class="line">        std::string range_string = base_str + <span class="string">&quot; &quot;</span> + std::<span class="built_in">to_string</span>(number);</span><br><span class="line">        <span class="built_in">nvtxRangePush</span>(range_string.<span class="built_in">c_str</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    ~<span class="built_in">NvtxRange</span>() &#123; <span class="built_in">nvtxRangePop</span>(); &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NVTX_RANGE_FN() NvtxRange nvtx_range(__FUNCTION__)</span></span><br></pre></td></tr></table></figure>

<ol>
<li>和 nsight system, viztracer 一起非常好用</li>
<li><a target="_blank" rel="noopener" href="https://nvtx.readthedocs.io/en/latest/">doc</a><ul>
<li>Annotate code ranges and events in Python 在 Python 中注释代码范围和事件</li>
</ul>
</li>
<li>sample</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@nvtx.annotate()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_func</span>():</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> nvtx.annotate(<span class="string">&quot;for_loop&quot;</span>, color=<span class="string">&quot;green&quot;</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        sleep_for(i)</span><br><span class="line">        my_func()</span><br><span class="line"></span><br><span class="line">rng = nvtx.start_range(message=<span class="string">&quot;my_message&quot;</span>, color=<span class="string">&quot;blue&quot;</span>, domain=<span class="string">&quot;rng&quot;</span>)</span><br><span class="line"><span class="comment"># ... do something ... #</span></span><br><span class="line">nvtx.end_range(rng)</span><br></pre></td></tr></table></figure>

<ol>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/nvidia-tools-extension-api-nvtx-annotation-tool-for-profiling-code-in-python-and-c-c/">NVIDIA Tools Extension API: An Annotation Tool for Profiling Code in Python and C&#x2F;C++</a></li>
</ol>
<h3 id="cupti"><a href="#cupti" class="headerlink" title="cupti"></a><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cupti">cupti</a></h3><h3 id="nsgiht-graphics"><a href="#nsgiht-graphics" class="headerlink" title="nsgiht graphics"></a>nsgiht graphics</h3><h2 id="cuda-debug"><a href="#cuda-debug" class="headerlink" title="cuda-debug"></a><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-visual-studio-code-edition/cuda-debugger/index.html">cuda-debug</a></h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cutlass/tree/main/examples/02_dump_reg_shmem">02_dump_reg_shmem</a><ul>
<li>dump_shmem</li>
<li>dump_fragment</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-gdb/index.html#compiling-the-application">compiling 要求</a><ul>
<li><code>nvcc -g -G foo.cu -o foo</code></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://marketplace.visualstudio.com/items?itemName=NVIDIA.nsight-vscode-edition">vs code plugin: nsight-vscode-edition</a></li>
<li>shared memory(L1 cache?) dump<ul>
<li>申请 shared memory 变量，存中间结果， shared memory 对 block 全局可见。</li>
<li>可以申请多于 L1 cache 大小的存储，系统会自动调度</li>
</ul>
</li>
<li>传递主存指针到 kernel，用于 dump</li>
<li>print<ul>
<li><code>if(threadIdx.x == 0) printf...</code> 条件打印</li>
<li>cudaDeviceReset(); 不打印可以加</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/nsight-visual-studio-code-edition">nsight-visual-studio-code-edition</a></li>
<li>cuda-gdb<ul>
<li><a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/cant-use-cuda-gdb/235380/4">Can’t use Cuda-gdb</a></li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/a/46676907/23011500">Error disabling address space randomization</a></li>
</ul>
</li>
<li>cuda-memcheck</li>
</ol>
<h2 id="link"><a href="#link" class="headerlink" title="link"></a>link</h2><ol>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-zone">cuda 相关开发</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/gpu-accelerated-libraries">gpu-accelerated-libraries</a></li>
</ol>
<h2 id="build-1"><a href="#build-1" class="headerlink" title="build"></a>build</h2><h3 id="cmake"><a href="#cmake" class="headerlink" title="cmake"></a>cmake</h3><ol>
<li><a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9444-build-systems-exploring-modern-cmake-cuda-v2.pdf">build-systems-exploring-modern-cmake-cuda-v2.pdf</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/building-cuda-applications-cmake/">building-cuda-applications-cmake</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/CUDALibrarySamples/blob/master/cuBLAS/Level-3/gemm/CMakeLists.txt">CUDALibrarySamples</a></li>
<li>basic sample</li>
</ol>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.8</span>)</span><br><span class="line"><span class="comment"># project(my_cuda_project LANGUAGES CXX CUDA)</span></span><br><span class="line"><span class="keyword">project</span>(my_cuda_project)</span><br><span class="line"><span class="keyword">enable_language</span>(CUDA) <span class="comment"># 需要enable language</span></span><br><span class="line"><span class="keyword">add_executable</span>(preprocess kernel.cu preprocess.cpp )</span><br><span class="line"><span class="keyword">find_package</span>(CUDA REQUIRED)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(preprocess <span class="variable">$&#123;CUDA_cudart_LIBRARY&#125;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="compile"><a href="#compile" class="headerlink" title="compile"></a>compile</h3><ol>
<li>混合编译, 注意-lcudart 顺序</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvcc -O3 -c kernel.cu -o kernel.o</span><br><span class="line">g++ -L /usr/local/cuda/targets/x86_64-linux/lib/ preprocess.cpp kernel.o -o preprocess -lcuda -lcudart &amp;&amp; ./preprocess</span><br></pre></td></tr></table></figure>

<h2 id="unified-memory"><a href="#unified-memory" class="headerlink" title="unified memory"></a>unified memory</h2><ol>
<li>不明白原理时不推荐使用</li>
<li>优缺点<ul>
<li>优点<ul>
<li>简化代码编写和内存管理：cudaMallocManaged 可以简化 CPU 和 GPU 之间数据传递的代码，无需手动管理内存迁移。</li>
</ul>
</li>
<li>缺点<ul>
<li>可能降低性能：在某些情况下，统一内存可能会降低性能，例如在数据访问模式为稀疏的情况下。</li>
<li>可能增加内存占用：统一内存可能会增加内存占用，因为它需要在 CPU 和 GPU 内存中都保留一份数据副本。</li>
</ul>
</li>
</ul>
</li>
<li><code>cudaMalloc -&gt; cudaMallocManaged(&amp;x, N*sizeof(float));</code></li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/a/21990899/23011500">使用 cudaMallocManaged 情况</a><ul>
<li>You are working on a Jetson device.</li>
</ul>
</li>
<li>runtime 负责 copy</li>
<li>unified memory cpu 访问时需要同一个线程。不同线程会 bus error。</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/unified-memory-cuda-beginners/">Unified Memory for CUDA Beginners</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/maximizing-unified-memory-performance-cuda/">Maximizing Unified Memory Performance in CUDA</a></li>
</ol>
<h2 id="design"><a href="#design" class="headerlink" title="design"></a>design</h2><ol>
<li>lidar prprocess; 三重 for, 最外层作为 x, 一个线程执行一个最里面 for 的内容，</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">TransposeDim</span><span class="params">(<span class="type">int</span> kmax_num_point_pillar,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">int</span> kmax_num_point,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">int</span> kdim,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">int</span> voxel_num, <span class="type">float</span> *voxel_data, <span class="type">int8_t</span> *features_s8)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> kWC = kmax_num_point_pillar * kdim;</span><br><span class="line">  <span class="type">int</span> kHW = kmax_num_point * kmax_num_point_pillar;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> c = <span class="number">0</span>; c &lt; kdim; ++c)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> w = <span class="number">0</span>; w &lt; kmax_num_point_pillar; ++w)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> h = <span class="number">0</span>; h &lt; voxel_num; ++h)</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="type">int</span> old_index = h * kWC + w * kdim + c;</span><br><span class="line">        <span class="type">int</span> new_index = c * kHW + w * kmax_num_point + h;</span><br><span class="line">        <span class="type">float</span> features_tmp = <span class="built_in">round</span>(<span class="built_in">static_cast</span>&lt;<span class="type">float</span>&gt;(voxel_data[old_index]));</span><br><span class="line">        features_tmp = std::<span class="built_in">min</span>(std::<span class="built_in">max</span>(features_tmp, <span class="number">-128.f</span>), <span class="number">127.f</span>);</span><br><span class="line">        features_s8[new_index] = <span class="built_in">static_cast</span>&lt;<span class="type">int8_t</span>&gt;(features_tmp);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">TransposeDim5Kernel</span><span class="params">(<span class="type">int</span> kmax_num_point_pillar,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    <span class="type">int</span> kmax_num_point,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    <span class="type">int</span> kdim,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    <span class="type">int</span> voxel_num,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    <span class="type">float</span> *voxel_data,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    <span class="type">int8_t</span> *features_s8)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> c = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="type">int</span> w = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">  <span class="type">int</span> h = blockIdx.z * blockDim.z + threadIdx.z;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (c &lt; kdim &amp;&amp; w &lt; kmax_num_point_pillar &amp;&amp; h &lt; voxel_num)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">int</span> kWC = kmax_num_point_pillar * kdim;</span><br><span class="line">    <span class="type">int</span> kHW = kmax_num_point * kmax_num_point_pillar;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> old_index = h * kWC + w * kdim + c;</span><br><span class="line">    <span class="type">int</span> new_index = c * kHW + w * kmax_num_point + h;</span><br><span class="line">    <span class="type">float</span> features_tmp = <span class="built_in">round</span>(voxel_data[old_index]);</span><br><span class="line"></span><br><span class="line">    features_tmp = <span class="built_in">fmaxf</span>(<span class="built_in">fminf</span>(features_tmp, <span class="number">127.f</span>), <span class="number">-128.f</span>);</span><br><span class="line"></span><br><span class="line">    features_s8[new_index] = <span class="built_in">static_cast</span>&lt;<span class="type">int8_t</span>&gt;(features_tmp);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">dim3 <span class="title">blockSize</span><span class="params">(<span class="number">4</span>, <span class="number">4</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">gridSize</span><span class="params">((kdim + blockSize.x - <span class="number">1</span>) / blockSize.x,</span></span></span><br><span class="line"><span class="params"><span class="function">                (kmax_num_point_pillar + blockSize.y - <span class="number">1</span>) / blockSize.y,</span></span></span><br><span class="line"><span class="params"><span class="function">                (voxel_num + blockSize.z - <span class="number">1</span>) / blockSize.z)</span></span>;</span><br><span class="line"></span><br><span class="line">TransposeDim5Kernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(kmax_num_point_pillar,</span><br><span class="line">                                               kmax_num_point,</span><br><span class="line">                                               kdim,</span><br><span class="line">                                               voxel_num,</span><br><span class="line">                                               d_voxel_data,</span><br><span class="line">                                               d_features_s8);</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2022/03/03/Doxygen/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/03/Doxygen/" class="post-title-link" itemprop="url">Doxygen</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-03 03:58:22" itemprop="dateCreated datePublished" datetime="2022-03-03T03:58:22+08:00">2022-03-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-09-12 17:16:25" itemprop="dateModified" datetime="2024-09-12T17:16:25+08:00">2024-09-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Program/" itemprop="url" rel="index"><span itemprop="name">Program</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/03/03/Doxygen/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/03/03/Doxygen/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="base"><a href="#base" class="headerlink" title="base"></a>base</h2><ol>
<li>markdown 添加 [toc] 为 html 生成目录</li>
<li>参考 opencv</li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/a/57979732">multi projects</a></li>
<li>可以用 cmake 生成 doxygen 配置 <a target="_blank" rel="noopener" href="https://github.com/opencv/opencv/blob/17234f82d025e3bbfbf611089637e5aa2038e7b8/doc/Doxyfile.in">link</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/doxygen/doxygen/tree/master/templates">templates</a></li>
</ol>
<h2 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h2><h3 id="moritz"><a href="#moritz" class="headerlink" title="moritz"></a>moritz</h3><ol>
<li><a target="_blank" rel="noopener" href="https://sourceforge.net/projects/moritz/">moritz 插件 生成流程图</a><ul>
<li>可以单独使用，也可以和 doxygen 一起使用 doxywizard</li>
<li><a target="_blank" rel="noopener" href="https://sourceforge.net/p/moritz/wiki/Home/#31b2">pdf 文档</a></li>
<li>Moritz_Linux_2020_06_10.zip 执行 ansi_c_create.sh 生成 dot 和 html</li>
<li>默认 arm 二进制， x86 需要源码编译 src_abc2xml_xml2abc_2020_06_10.zip, 需要 codeblocks 图形界面来编译，String_help.h 找不到直接替换字符</li>
<li>cfg&#x2F;Doxyfile_ansi_c_xml 中 INPUT 改源码位置， RECURSIVE 要改为 YES</li>
</ul>
</li>
</ol>
<h3 id="XML-pareser"><a href="#XML-pareser" class="headerlink" title="XML pareser"></a>XML pareser</h3><ol>
<li><code>pip install  doxmlparser</code></li>
<li><a target="_blank" rel="noopener" href="https://github.com/doxygen/doxygen/blob/master/addon/doxmlparser/examples/metrics/metrics.py">metrics</a><ul>
<li><code>python metrics.py xml/</code>能够输出统计信息</li>
<li><a target="_blank" rel="noopener" href="https://github.com/doxygen/doxygen/blob/master/addon/doxmlparser/doxmlparser/compound.py#L7025">location 来获取定义文件，start end line</a></li>
</ul>
</li>
<li>跟据 xml 信息提取函数再加上 cxx2flow 生成流程图</li>
<li>如果使用宏定义来区分平台，doxygen 生成 xml 时需要删除其他平台的代码或者提供 compile_commands.json 来生成；否则类的关系会有问题，生成不了具体实现的流程图</li>
<li>也可以配置 doxygen 中的 INPUT, 只包含要使用的平台</li>
<li>给别人生成时需要提供 compile_commands.json 和源码，根据路径在自己电脑创建相应目录，放入源码</li>
<li><code>sed -i &#39;s/\/builds\/platform/\/home\/xiyang\/d\/working/g&#39; compile_commands.json</code>修改路径</li>
<li>compile_commands.json 不太好使;</li>
<li>(good)可以 grep compile_commands.json 要用的 cpp 文件，写到 INPUT(注意 INPUT 不支持正则), FILE_PATTERN 只设置搜索头文件(INPUT 要填最外层文件夹)， EXCLUDE 排除一些文件, 头文件路径设置到 INCLUDE_PATH，</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sudo apt install jq</span></span><br><span class="line">rm file_list.txt; cat compile_commands.json | jq &#x27;.[] | .file&#x27; | while read -r line; do</span><br><span class="line">  echo &quot;$line\\&quot;</span><br><span class="line">done | sort &gt;&gt; file_list.txt</span><br></pre></td></tr></table></figure>

<ol>
<li>写个脚本处理 compile_commands.json 文件， 得到文件和 include 路径，设置到 INPUT 里面</li>
<li>doxyxml</li>
<li><a target="_blank" rel="noopener" href="https://gitlab.com/graphviz/graphviz">graphviz 要用最新的，否则生成的图片有问题</a></li>
</ol>
<h3 id="word-文档"><a href="#word-文档" class="headerlink" title="word 文档"></a>word 文档</h3><ol>
<li><p>XML 格式： Word 文档本质上是一个 XML 文件。可以使用文本编辑器或编程语言（如 Python、C#）打开 Word 文档的 XML 格式，搜索&lt;w:altText&gt;标签，即可找到图片的 Alt 文本。</p>
<ul>
<li>unzip docx: 解压 docx 文件，在 word 里查看 document.xml</li>
<li>windows 下另存为 xml</li>
<li>通过 xml 可以看出通过图片的 name 和 descr 属性可以区分图片</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/python-openxml/python-docx?tab=readme-ov-file">python-docx</a></p>
<ul>
<li>加入可选文字，后面使用 template 替换</li>
<li>把图片写在 bytesIO 里面然后用 from docxtpl import InlineImage 插入的，用了快两年了，很稳 就是楼上这个</li>
<li>通过 descr 属性来处理图片替换问题 <a target="_blank" rel="noopener" href="https://chatgpt.com/c/66e15cd9-20f4-8004-a2fd-945070c91601">link</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">inline_shape = run.add_picture(image_path, width=Inches(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加 descr（图片描述）</span></span><br><span class="line">inline_shape._inline.graphic.graphicData.pic.nvPicPr.cNvPr.<span class="built_in">set</span>(<span class="string">&#x27;descr&#x27;</span>, descr)</span><br></pre></td></tr></table></figure>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/elapouya/python-docx-template">python-docx-template</a></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/elapouya/python-docx-template/blob/master/tests/merge_docx.py">merge_doc</a><ul>
<li>合并之后在下面添加用于下次合并</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://github.com/elapouya/python-docx-template/blob/master/tests/module_execute.py">通过 json 来生成 docx</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/elapouya/python-docx-template/blob/master/tests/replace_picture.py">replace_picture</a><ul>
<li>右击图片，可选文字显示名称</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/h1773655323/article/details/119876821">sample</a></li>
</ul>
</li>
<li><p>流程图加到文档里</p>
</li>
<li><p>pandoc</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yuetaope/article/details/119444970">详解 Python-docx 自动生成 word 图文报告</a></p>
</li>
</ol>
<h2 id="theme"><a href="#theme" class="headerlink" title="theme"></a>theme</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/jothepro/doxygen-awesome-css">doxygen-awesome-css</a></li>
<li><a target="_blank" rel="noopener" href="https://jothepro.github.io/doxygen-awesome-css/index.html">效果</a></li>
</ol>
<h2 id="doxygen-config"><a href="#doxygen-config" class="headerlink" title="doxygen config"></a>doxygen config</h2><ol>
<li><code>sudo apt install doxygen</code></li>
<li><code>doxygen -g &lt;config-name&gt;</code> 产生配置文件，默认为 Doxyfile <code>-s</code> 生成不带注释的配置文件</li>
<li><code>doxygen &lt;config-name&gt;</code> 生成文档</li>
<li>UML 生成 svg 图片<ul>
<li><code>DOT_IMAGE_FORMAT       = svg(png)</code></li>
<li><code>INTERACTIVE_SVG        = YES</code></li>
</ul>
</li>
<li>生成 UML, 需要修改配置文件, 以下改为 YES</li>
</ol>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">RECURSIVE</span><br><span class="line">HAVE<span class="emphasis">_DOT</span></span><br><span class="line"><span class="emphasis">UML_LOOK</span></span><br><span class="line"><span class="emphasis">EXTRACT_</span>ALL</span><br></pre></td></tr></table></figure>

<ol>
<li><code>CLANG_DATABASE_PATH=compile_commands.json</code>提供编译信息更准确的拿到信息 <a target="_blank" rel="noopener" href="https://stackoverflow.com/a/64476238/23011500">link</a></li>
<li><code>INLINE_SOURCES</code>标签。如果设置为 YES，可以将源代码直接包含到文档中。</li>
<li><code>INPUT</code> 标签是输入的源码文件的目录, 空格分开 例如： <code>INPUT = README.md include/pg</code></li>
<li><code>OUTPUT_LANGUAGE</code> &#x3D; 改为 Chinese</li>
<li><code>HTML_TIMESTAMP</code>标签设置为 YES，则每个生成的 HTML 页面的页脚将包含生成页面的日期和时间。将此设置为“是”有助于显示上次运行 doxygen 的时间，从而显示文档是否最新。</li>
<li><code>GENERATE_TREEVIEW</code> 标签用于指定是否应生成树状索引结构以显示分层信息。</li>
<li><code>GENERATE_XML = YES</code> 产生 xml</li>
<li><code>GENERATE_HTML = YES</code> 产生 html</li>
<li><code>EXTRACT_ALL</code></li>
<li><code>EXTRACT_PRIVATE</code> If the EXTRACT_PRIVATE tag is set to YES, all private members of a class will be included in the documentation.</li>
<li><code>EXTRACT_STATIC</code></li>
<li><code>EXTRACT_LOCAL_METHODS</code></li>
<li><code>EXTRACT_ANON_NSPACES</code>提取匿名函数</li>
<li><code>PROJECT_NAME</code></li>
<li><code>PROJECT_NUMBER</code></li>
<li><code>PROJECT_LOGO</code> 首页左侧图标</li>
<li><code>EXTRACT_STATIC</code> 如果设置为 YES，一个文件的所有静态成员都将包含在文档中。</li>
<li><code>EXTRACT_PRIVATE</code> 如果设置为 YES，一个类的所有私有成员都将包含在文档中。</li>
<li><code>IMAGE_PATH</code> 修复 markdown 生成网页时 doc 出错问题</li>
<li><code>USE_MDFILE_AS_MAINPAGE = ./README.md</code> 主页</li>
<li><code>HTML_OUTPUT = doc_html</code></li>
<li><code>LATEX_OUTPUT = doc_latex</code></li>
<li>输出 color <a target="_blank" rel="noopener" href="https://github.com/jothepro/doxygen-awesome-css/blob/main/docs/customization.md#doxygen-generator">link</a></li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HTML_COLORSTYLE_HUE    = 209</span><br><span class="line">HTML_COLORSTYLE_SAT    = 255</span><br><span class="line">HTML_COLORSTYLE_GAMMA  = 113</span><br></pre></td></tr></table></figure>

<h2 id="pdf"><a href="#pdf" class="headerlink" title="pdf"></a>pdf</h2><ol>
<li><code>sudo apt-get install texlive-full texlive-latex-base</code> <a target="_blank" rel="noopener" href="https://tex.stackexchange.com/a/481681">link</a></li>
<li><code>cd latex &amp;&amp; make</code></li>
<li><code>doxygen -w latex header.tex footer.tex doxygen.sty</code> 先生成默认配置，修改 doxygen.config 指定<code>LATEX_HEADER = header.tex</code> <a target="_blank" rel="noopener" href="https://stackoverflow.com/a/16222657">link</a></li>
<li>修改 refman.tex 来改变 pdf 生成</li>
<li><code>sed -i &quot;s/Doxygen/xx xx/&quot; refman.tex</code>修改制作者名字</li>
<li>中文问题 <code>\begin&#123;CJK&#125;&#123;UTF8&#125;</code> 换成 <code>\begin&#123;CJK&#125;&#123;gbsn&#125;</code> <a target="_blank" rel="noopener" href="https://www.cnblogs.com/zyl910/archive/2013/06/02/doxygen_pdf_chinese.html">link</a></li>
<li>空页问题： <code>COMPACT_LATEX</code> to YES</li>
<li>换页问题： <code>\doxysection</code> 之前加 <code>\newpage</code></li>
<li>refman.tex 处理</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">&quot;/fancyfoot/d&quot;</span> latex/refman.tex</span><br><span class="line">sed -i <span class="string">&quot;/fancyhead/d&quot;</span> latex/refman.tex</span><br><span class="line">sed -i <span class="string">&#x27;/&#123;fancyplain&#125;/a\\\cfoot&#123;\\thepage&#125;&#x27;</span> latex/refman.tex</span><br><span class="line">sed -i <span class="string">&#x27;/&#123;fancyplain&#125;/a\\\rhead&#123;&#125;&#x27;</span> latex/refman.tex</span><br><span class="line">sed -i <span class="string">&#x27;/&#123;fancyplain&#125;/a\\\lhead&#123;&#125;&#x27;</span> latex/refman.tex</span><br><span class="line">sed -i <span class="string">&#x27;/doxysection/i\\\newpage&#x27;</span> latex/refman.tex</span><br><span class="line">sed -i <span class="string">&quot;s/Doxygen 1.8.17/PhiGent Robotics/&quot;</span> latex/refman.tex</span><br><span class="line">sed -i <span class="string">&quot;s/&#123;min&#125;/&#123;gbsn&#125;/&quot;</span> latex/refman.tex</span><br></pre></td></tr></table></figure>

<ol>
<li><code>\pagestyle&#123;fancyplain&#125;</code> 删除之后页眉页脚不再有横杠 <code>\pagestyle&#123;plain&#125;</code></li>
</ol>
<h2 id="notes"><a href="#notes" class="headerlink" title="notes"></a>notes</h2><ol>
<li>不要在有 build 的目录下</li>
<li>如果想生成详细的 UML 图，需要设置<code>EXTRACT_STATIC</code> <code>EXTRACT_PRIVATE</code>为 YES</li>
</ol>
<h2 id="文档解析"><a href="#文档解析" class="headerlink" title="文档解析"></a>文档解析</h2><ol>
<li>Class Hierarchy 可以查看类层级关系</li>
</ol>
<h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://fossies.org/dox/all.html">fossies doxygen lists</a></li>
<li><a target="_blank" rel="noopener" href="https://www.doxygen.nl/manual/starting.html">getting start</a></li>
<li><a target="_blank" rel="noopener" href="https://www.guyuehome.com/35640">参数详解</a></li>
<li><a target="_blank" rel="noopener" href="https://doxygen.nl/projects.html">使用 doxygen 的项目</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/sdk-api/index.html">deepstream doxygen</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/ion/base_2logging_8h.html">ion</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.opencv.org/4.x/d9/df8/tutorial_root.html">opencv tutorial</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/opencv/opencv/blob/17234f82d025e3bbfbf611089637e5aa2038e7b8/doc/Doxyfile.in">opencv config</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/doxygen/doxygen/tree/master/templates">templates</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2022/03/03/UML/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/03/UML/" class="post-title-link" itemprop="url">UML</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-03 02:32:22" itemprop="dateCreated datePublished" datetime="2022-03-03T02:32:22+08:00">2022-03-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-09-05 10:46:13" itemprop="dateModified" datetime="2024-09-05T10:46:13+08:00">2024-09-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Program/" itemprop="url" rel="index"><span itemprop="name">Program</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/03/03/UML/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/03/03/UML/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="UML-介绍"><a href="#UML-介绍" class="headerlink" title="UML 介绍"></a>UML 介绍</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.visual-paradigm.com/cn/guide/uml-unified-modeling-language/what-is-uml/">历史</a></li>
<li>图表可大致分为结构性图表和行为性图表两种。结构性图表显示了系统在不同抽象层次和实现层次上的静态结构以及它们之间的相互关系。结构性图表中的元素表示系统中具意义的概念，可能包括抽象的、现实的和實作的概念。</li>
<li>结构性图表有七种类型：<ul>
<li>类图 (Class Diagram)</li>
<li>组件图 (Component Diagram)</li>
<li>部署图 (Deployment Diagram)</li>
<li>对象图 (Object Diagram)-</li>
<li>包图 (Package Diagram)</li>
<li>复合结构图 (Composite Structure Diagram)</li>
<li>轮廓图 (Profile Diagram)</li>
</ul>
</li>
<li>行为性图表显示了系统中对象的动态行为 ，可用以表达系统随时间的变化。行为性图表有七种类型：<ul>
<li>用例图 (Use Case Diagram)</li>
<li>活动图 (Activity Diagram)</li>
<li>状态机图 (State Machine Diagram)</li>
<li>序列图 (Sequence Diagram)</li>
<li>通訊圖 (Communication Diagram)</li>
<li>交互概述图 (Interaction Overview Diagram)</li>
<li>时间图 (Timing Diagram)</li>
</ul>
</li>
</ol>
<h2 id="图种类"><a href="#图种类" class="headerlink" title="图种类"></a>图种类</h2><ol>
<li>class diagram 类图</li>
<li>sequence diagram 时序图</li>
<li>flow chart 流程图</li>
</ol>
<h3 id="class-diagram"><a href="#class-diagram" class="headerlink" title="class diagram"></a>class diagram</h3><h3 id="sequence-diagram"><a href="#sequence-diagram" class="headerlink" title="sequence diagram"></a><a target="_blank" rel="noopener" href="https://www.woshipm.com/ucd/607593.html">sequence diagram</a></h3><h4 id="关系"><a href="#关系" class="headerlink" title="关系"></a>关系</h4><p><img src="https://pica.zhimg.com/v2-941a070601f399d992125ef31261637e_1440w.jpg?source=172ae18b" alt="关系"></p>
<!-- prettier-ignore -->
<table>
<thead>
<tr>
<th align="left">名字</th>
<th align="left">图形</th>
<th align="left">说明</th>
<th align="left">其他</th>
</tr>
</thead>
<tbody><tr>
<td align="left">实现关系</td>
<td align="left">空心三角和虚线组成的箭头</td>
<td align="left">实现类指向接口</td>
<td align="left">类似 rust trait</td>
</tr>
<tr>
<td align="left">泛化关系</td>
<td align="left">空心三角和实线组成的箭头</td>
<td align="left">从子类指向父类</td>
<td align="left">“is a”</td>
</tr>
<tr>
<td align="left">关联关系</td>
<td align="left">带箭头的实线</td>
<td align="left">指向被关联的对象</td>
<td align="left">一个对象含有另一个对象的引用</td>
</tr>
<tr>
<td align="left">依赖关系</td>
<td align="left">带虚线的箭头</td>
<td align="left">使用方指向被使用方</td>
<td align="left">“use a”, 弱关联关系,<br>构造器或方法中的局部变量、方法或构造器的参数、方法的返回值</td>
</tr>
<tr>
<td align="left">聚合关系</td>
<td align="left">空心菱形加实线箭头</td>
<td align="left">空心菱形在整体一方，箭头指向部分一方</td>
<td align="left">“has a”, 具有各自的生命周期</td>
</tr>
<tr>
<td align="left">组合关系</td>
<td align="left">实心菱形加实线箭头</td>
<td align="left">实心菱形在整体一方，箭头指向部分一方</td>
<td align="left">“contains a” 强聚合, 作为整体的对象负责部分的对象的生命周期</td>
</tr>
</tbody></table>
<!-- prettier-ignore -->
<h2 id="mermaid"><a href="#mermaid" class="headerlink" title="mermaid"></a>mermaid</h2><h2 id="mermaid-1"><a href="#mermaid-1" class="headerlink" title="mermaid"></a><a target="_blank" rel="noopener" href="https://github.com/mermaid-js/mermaid">mermaid</a></h2><ol>
<li><a target="_blank" rel="noopener" href="https://mermaid.live/">在线 server</a></li>
<li><a target="_blank" rel="noopener" href="https://jojozhuang.github.io/tutorial/mermaid-cheat-sheet/">cheat sheet</a></li>
<li>markdown 支持</li>
<li>theme <code>%%&#123;init: &#123;&#39;theme&#39;: &#39;base&#39;, &#39;themeVariables&#39;: &#123; &#39;primaryColor&#39;: &#39;#ffcccc&#39;, &#39;edgeLabelBackground&#39;:&#39;#ffffee&#39;, &#39;tertiaryColor&#39;: &#39;#fff0f0&#39;, &#39;fontFamily&#39;: &#39;verdana&#39;&#125;&#125;&#125;%%</code></li>
<li><a target="_blank" rel="noopener" href="https://mermaid-js.github.io/mermaid/#/theming">theming</a></li>
<li>可以用 graph 画关系图<a target="_blank" rel="noopener" href="https://github.com/bitcoin/bitcoin/blob/master/doc/design/libraries.md#L36">bitcoin sample</a></li>
<li>gatte 图也好用</li>
<li>github 用 chrome 插件<a target="_blank" rel="noopener" href="https://chrome.google.com/webstore/detail/markdown-diagrams/pmoglnmodacnbbofbgcagndelmgaclel">markdown-diagrams</a>可以生成图片, 密集图片截屏效果不好</li>
<li><code>%%&#123;init: &#123;&#39;securityLevel&#39;: &#39;loose&#39;, &#39;theme&#39;:&#39;base&#39;&#125;&#125;%%</code> 设置主题</li>
<li><code>%%&#123;init:&#123;&quot;themeVariables&quot;: &#123; &quot;fontSize&quot;: &quot;30px&quot; &#125;&#125;&#125;%%</code> 设置字体大小</li>
<li><code>%%&#123;init:&#123;&#39;theme&#39;:&#39;neutral&#39;, &quot;themeVariables&quot;: &#123; &quot;fontSize&quot;: &quot;20px&quot; &#125;&#125;&#125;%%</code></li>
<li><a target="_blank" rel="noopener" href="https://github.com/mermaid-js/mermaid/issues/3033">字体设置只支持几种图，其他不支持</a></li>
<li>sequence</li>
</ol>
<pre><code class="highlight mermaid">&#123;% mermaid sequenceDiagram %&#125;
Alice-&gt;&gt;John: Hello John, how are you?
loop Healthcheck
    John-&gt;&gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&gt;&gt;Alice: Great!
John-&gt;&gt;Bob: How about you?
Bob--&gt;&gt;John: Jolly good!
&#123;% endmermaid %&#125;</code></pre>

<ol>
<li>flow chart 支持 <a target="_blank" rel="noopener" href="https://fontawesome.com/icons">fontawesome</a></li>
</ol>
<pre><code class="highlight mermaid">classDiagram
    user ..&gt; image
    image ..&gt; MediaProc
    MediaProc &lt;|-- ImgProcImpl
    ImgProcImpl ..&gt; ImageFrame : 代理
    ImageFrame &lt;|-- ImageFrameImpl
    ImageFrameImpl &lt;|-- BpuImageFrame

    class MediaProc&#123;
      &lt;&lt;interface&gt;&gt;
      +Crop()
      +Resize()
      +CvtColor()
      +Decode()
      +Encode()
    &#125;

    class ImgProcImpl&#123;
      +Crop()
      +Resize()
      +CvtColor()
      +Decode()
      +Encode()
    &#125;

    class ImageFrame&#123;
      &lt;&lt;interface&gt;&gt;
      +Crop()
      +Resize()
      +CvtColor()
    &#125;

    class ImageFrameImpl&#123;
      +Crop()
      +Resize()
      +CvtColor()
    &#125;

    class BpuImageFrame&#123;
      +Crop()
      +Resize()
      +CvtColor()
    &#125;
</code></pre>

<ol>
<li>samples<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/tiangolo/fastapi/blob/master/docs/en/docs/tutorial/dependencies/dependencies-with-yield.md#dependencies-with-yield-and-httpexception">fastapi</a></li>
<li><a target="_blank" rel="noopener" href="https://mermaid.live/edit#pako:eNqdVFFr01AU_iuX-6QYW9vabuvDQLoNYVKGKYIaH26Tk-ZCkhtvbqe1FMQndZsOhogwNycMBWHTFwU39M_YrG_-BW9605rNZk7zkNDvnPud85379XSxySzAVRzC3Tb4JsxR0uLEM3wkn4BwQU0aEF-gmkvBF3_iOvBl4ArnYArEW81zxXJZQ8VScfg6r4J1JgBx2nIEYnZCV0X9w4f9dyuoUVtC0fOd6MmKSlbhi7Ozir6q36yrADEFXSaSKd2PSpLZCavMvnCltnjiRLpTCyYSnSw7Jknlp2nAt04ql6Jj9X_TLQUrvUcHG9Hr7Z-Hq_311ejlZzWP_sHXow8rjWv64PtW9Gx3cnMJgK6C67J_mE4CqHMaqoG8TJua8piWhBahM3_fdIjfGkPD5DnmQwbn_8AZlzBx0hnij3VaG35rNHCA6wGYGlqgPg0dsDI4ToUzrvxsIz5eOEPoZPck_5tyOe0fF-yhfUYtSmsg5Q1lldg_Q-dELz5Ga3s_Dt8Mvm1kyJur6yja3h3svx3sf4k-PTpF18Ta0eZa_-lO_9V7RZLL5TKG8LtQbPKtzbMNY1iTxQZVYW1Ut7-3Gj1eT7EavjoxerCGPeAeoZZcaN04ZmDhgAcGlpeKbcYhFAbWUpEbhFPSdCGMU7qKLs70xQLxqNuJ4dujKgZuUA9CVId76DrziJ9wqZjO2twceoXaaIkzA6vYHS1Nq9MHSTuFQiBUTs_we7J30hZM7_gmrgreBg23A0sOKVnIuGoTNxyj8xYVjI9BlxEL5M8uFp0gXuctGgpJaTLfpq0Yb3NXwo4QQVjN5-NwrkWF027mTOblQ2o5cqc7yzOVfKVYmSbFElSmSqRcKllmszAzbRcvF2xr6lKhSHCvp2G5-m8xNuqq9ws-JjhZ">三次握手 config 中有中文支持</a></li>
</ul>
</li>
</ol>
<h2 id="plantuml"><a href="#plantuml" class="headerlink" title="plantuml"></a><a target="_blank" rel="noopener" href="https://github.com/plantuml/plantuml">plantuml</a></h2><ol>
<li><p><a target="_blank" rel="noopener" href="http://www.plantuml.com/plantuml/uml/">在线 server</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/plantuml/plantuml-server">本地 plantuml-server</a></p>
<ul>
<li><code>docker run -d -p 10093:8080 plantuml/plantuml-server:jetty</code></li>
<li><code>docker run -d -p 10093:8080 -e THE_ENV_VARIABLE=THE_ENV_VALUE plantuml/plantuml-server:jetty</code></li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://plantuml.com/zh/guide">pdf guide</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://plantuml.com/zh/class-diagram">class</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://plantuml.com/zh/sequence-diagram">时序图</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/iluwatar/java-design-patterns">java-design-patterns</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/iluwatar/java-design-patterns/blob/master/factory-method/etc/factory-method.urm.puml">puml config file demo</a></p>
</li>
<li><p>markdown gitlab github 不支持， 用<a target="_blank" rel="noopener" href="https://chrome.google.com/webstore/detail/markdown-diagrams/pmoglnmodacnbbofbgcagndelmgaclel">markdown-diagrams</a>来支持浏览器显示</p>
</li>
<li><p>test plantuml</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@startuml</span><br><span class="line">object Object01</span><br><span class="line">object Object02</span><br><span class="line">object Object03</span><br><span class="line">object Object04</span><br><span class="line">object Object05</span><br><span class="line">object Object06</span><br><span class="line">object Object07</span><br><span class="line">object Object08</span><br><span class="line"></span><br><span class="line">Object01 &lt;|-- Object02</span><br><span class="line">Object03 *-- Object04</span><br><span class="line">Object05 o-- &quot;4&quot; Object06</span><br><span class="line">Object07 .. Object08 : some labels</span><br><span class="line">@enduml</span><br></pre></td></tr></table></figure>

<h2 id="dot-language"><a href="#dot-language" class="headerlink" title="dot language"></a><a target="_blank" rel="noopener" href="https://graphviz.org/doc/info/lang.html">dot language</a></h2><ol>
<li><a target="_blank" rel="noopener" href="https://gitlab.com/graphviz/graphviz/-/tree/main/cmd/dot">dot 命令源码</a></li>
<li><code>sudo apt-get install graphviz</code></li>
<li><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-cn/DOT%E8%AF%AD%E8%A8%80">维基介绍</a></li>
<li><a target="_blank" rel="noopener" href="https://itopic.org/graphviz.html">属性</a></li>
<li><a target="_blank" rel="noopener" href="http://www.graphviz.org/gallery/">samples</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zywvvd.com/notes/tools/graphviz/graphviz/">Graphviz 使用教程</a></li>
<li>流程图条件分支连接线不居中的原因是 portpos 不对齐</li>
<li>sample</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">digraph test123 &#123;</span><br><span class="line">        pack=8</span><br><span class="line">        subgraph cluster0 &#123;</span><br><span class="line">          packmode=array</span><br><span class="line">          x y x0 y0 x1</span><br><span class="line">          subgraph cluster1 &#123;</span><br><span class="line">            m n</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        b [shape=box];</span><br><span class="line">        c [label=&quot;helloenworld&quot;,color=blue,fontsize=24,</span><br><span class="line">             fontname=&quot;Palatino-Italic&quot;,fontcolor=red,style=filled];</span><br><span class="line">        a -&gt; z</span><br><span class="line">        x -&gt; z</span><br><span class="line">        a -&gt; b -&gt; c;</span><br><span class="line">        a -&gt; &#123;x y&#125;;</span><br><span class="line">        edge [style=dashed,color=red];</span><br><span class="line">        b -&gt; x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>颜色, 给 node 加上属性</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">digraph G &#123;</span><br><span class="line">  node [style=filled, color=&quot;#999999&quot;, fillcolor=&quot;#eeeeee&quot;]; edge [color=&quot;#666666&quot;];</span><br><span class="line">  node [</span><br><span class="line">    style=&quot;filled&quot;</span><br><span class="line">    color=&quot;#9370db&quot;</span><br><span class="line">    fillcolor=&quot;#ececff&quot;</span><br><span class="line">  ]</span><br><span class="line">  start -&gt; a0;</span><br><span class="line">  start -&gt; b0;</span><br><span class="line">  a1 -&gt; b3;</span><br><span class="line">  b2 -&gt; a3;</span><br><span class="line">  a3 -&gt; a0;</span><br><span class="line">  a3 -&gt; end;</span><br><span class="line">  b3 -&gt; end;</span><br><span class="line"></span><br><span class="line">  start [shape=Mdiamond];</span><br><span class="line">  end [shape=Msquare];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="doxygen-生成-UML"><a href="#doxygen-生成-UML" class="headerlink" title="doxygen 生成 UML"></a>doxygen 生成 UML</h2><h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/shindo/p/5579191.html">关系</a></li>
<li><a target="_blank" rel="noopener" href="https://www.51fusa.com/client/information/informationdetail/id/1561.html">基于 SOME&#x2F;IP 的 AP AUTOSAR 实战</a></li>
<li><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844904039902085134">适合程序员的 UML 绘图工具</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2022/03/02/Nvidia-NPP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/02/Nvidia-NPP/" class="post-title-link" itemprop="url">Nvidia-NPP</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-02 11:30:48" itemprop="dateCreated datePublished" datetime="2022-03-02T11:30:48+08:00">2022-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-10-09 19:56:16" itemprop="dateModified" datetime="2023-10-09T19:56:16+08:00">2023-10-09</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/03/02/Nvidia-NPP/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/03/02/Nvidia-NPP/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="notes"><a href="#notes" class="headerlink" title="notes"></a>notes</h2><ol>
<li>need <code>sudo</code> to run exe</li>
<li><code>export CUDACXX=/usr/local/cuda/bin/nvcc</code> when build cuda</li>
<li>CMakeLists.txt: <code>CUDA_ADD_EXECUTABLE(resize resize.cpp)</code></li>
</ol>
<h2 id="yuyv-2-rgb"><a href="#yuyv-2-rgb" class="headerlink" title="yuyv 2 rgb"></a>yuyv 2 rgb</h2><ol>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/a/71473363">link</a> nvcc 替换成 g++也可用</li>
</ol>
<h2 id="basic"><a href="#basic" class="headerlink" title="basic"></a>basic</h2><ol>
<li>install path: <code>/usr/local/cuda-xxx/</code></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/npp/nppi_conventions_lb.html">函数名称中简写的意义</a></li>
<li></li>
</ol>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&quot;A&quot; <span class="keyword">if</span> the image <span class="keyword">is</span> a <span class="number">4</span> channel image this indicates the result alpha channel <span class="keyword">is</span> <span class="keyword">not</span> affected <span class="keyword">by</span> the primitive.</span><br><span class="line">&quot;Cn&quot; the image consists <span class="keyword">of</span> n channel packed pixels, <span class="keyword">where</span> n can be <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span> <span class="keyword">or</span> <span class="number">4.</span></span><br><span class="line">&quot;Pn&quot; the image consists <span class="keyword">of</span> n separate image planes, <span class="keyword">where</span> n can be <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span> <span class="keyword">or</span> <span class="number">4.</span></span><br><span class="line">&quot;C&quot; (<span class="keyword">following</span> the channel information) indicates that the primitive <span class="keyword">only</span> operates <span class="keyword">on</span> one <span class="keyword">of</span> the color channels, the &quot;channel-of-interest&quot;. <span class="keyword">All</span> other output channels are <span class="keyword">not</span> affected <span class="keyword">by</span> the primitive.</span><br><span class="line">&quot;I&quot; indicates that the primitive works &quot;in-place&quot;. <span class="keyword">In</span> this <span class="keyword">case</span> the image-data pointer <span class="keyword">is</span> usually named pSrcDst <span class="keyword">to</span> indicate that the image data serves <span class="keyword">as</span> source <span class="keyword">and</span> destination at the same <span class="type">time</span>.</span><br><span class="line">&quot;M&quot; indicates &quot;masked operation&quot;. These <span class="keyword">types</span> <span class="keyword">of</span> primitives have an additional &quot;mask image&quot; <span class="keyword">as</span> <span class="keyword">as</span> <span class="keyword">input</span>. <span class="keyword">Each</span> pixel <span class="keyword">in</span> the destination image corresponds <span class="keyword">to</span> a pixel <span class="keyword">in</span> the mask image. <span class="keyword">Only</span> pixels <span class="keyword">with</span> a corresponding non-zero mask pixel are being processed.</span><br><span class="line">&quot;R&quot; indicates the primitive operates <span class="keyword">only</span> <span class="keyword">on</span> a rectangular &quot;region-of-interest&quot; <span class="keyword">or</span> &quot;ROI&quot;. <span class="keyword">All</span> ROI primitives take an additional <span class="keyword">input</span> parameter <span class="keyword">of</span> <span class="keyword">type</span> NppiSize, which specifies the width <span class="keyword">and</span> height <span class="keyword">of</span> the rectangular region that the primitive should process. <span class="keyword">For</span> details <span class="keyword">on</span> how primitives operate <span class="keyword">on</span> ROIs see: Region-<span class="keyword">of</span>-Interest (ROI).</span><br><span class="line">&quot;Sfs&quot; indicates the result <span class="keyword">values</span> are processed <span class="keyword">by</span> fixed scaling <span class="keyword">and</span> saturation <span class="keyword">before</span> they<span class="string">&#x27;re written out.</span></span><br></pre></td></tr></table></figure>

<ol>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/npp/nppi__support__functions_8h_source.html">image malloc functions</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/npp/nppi__geometry__transforms_8h_source.html">resize function</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cuda-samples/tree/master/Common/UtilNPP">npp utils</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/npp/group__image__color__model__conversion.html">cvtcolor</a></li>
</ol>
<h2 id="samples"><a href="#samples" class="headerlink" title="samples"></a>samples</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/CUDALibrarySamples.git">NVIDIA-CUDALibrarySamples</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.51cto.com/u_15357586/3790330">simple sample</a></li>
<li><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/PacktPublishing/Learn-CUDA-Programming/-/blob/Chapter08/08_cuda_libs_and_other_languages/05_npp/imageFilter.cpp">malloc sample</a></li>
</ol>
<h2 id="Links"><a href="#Links" class="headerlink" title="Links"></a>Links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/npp/index.html">main page</a></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2022/02/15/Gitlab-CI/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/15/Gitlab-CI/" class="post-title-link" itemprop="url">Gitlab-CI</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-15 23:27:31" itemprop="dateCreated datePublished" datetime="2022-02-15T23:27:31+08:00">2022-02-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-06-28 15:42:21" itemprop="dateModified" datetime="2024-06-28T15:42:21+08:00">2024-06-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tools/" itemprop="url" rel="index"><span itemprop="name">Tools</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tools/CI/" itemprop="url" rel="index"><span itemprop="name">CI</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/02/15/Gitlab-CI/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/02/15/Gitlab-CI/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="base"><a href="#base" class="headerlink" title="base"></a>base</h2><ol>
<li><a target="_blank" rel="noopener" href="https://lrita.github.io/2022/07/30/auto-clang-format-cpp-code/">使用 clang-format 在 CI 中自动格式化 C++代码</a></li>
</ol>
<h2 id="badges"><a href="#badges" class="headerlink" title="badges"></a>badges</h2><ol>
<li>显示 build 状态</li>
<li><a target="_blank" rel="noopener" href="https://www.benjaminrancourt.ca/what-are-gitlab-badges/">what-are-gitlab-badges</a></li>
</ol>
<h2 id="format-check"><a href="#format-check" class="headerlink" title="format check"></a>format check</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">check-format:</span><br><span class="line">  image:</span><br><span class="line">    name: witekio/clang-format-checker</span><br><span class="line">    entrypoint: [&quot;&quot;]</span><br><span class="line">  script:</span><br><span class="line">    - run-clang-format.py -r src</span><br></pre></td></tr></table></figure>

<h2 id="include"><a href="#include" class="headerlink" title="include"></a><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/yaml/#includelocal">include</a></h2><ol>
<li>可以 include local file, private project and remote file。</li>
</ol>
<h2 id="release-artifacts"><a href="#release-artifacts" class="headerlink" title="release artifacts"></a><a target="_blank" rel="noopener" href="https://gitlab.phigent.io/help/user/project/releases/index">release artifacts</a></h2><ol>
<li><a target="_blank" rel="noopener" href="https://crypt.codemancers.com/posts/2021-08-31-release-artifacts-using-gitlab-cicd/#generating-the-artifacts">release-artifacts-using-gitlab-cicd</a></li>
<li><a target="_blank" rel="noopener" href="https://gitlab.phigent.io/help/user/project/releases/index#use-a-generic-package-for-attaching-binaries">gitlab release 和 artifactory 结合</a><ul>
<li>notes: 注意 tag-name， ci 跑完之后会打 tag，然后又会运行 ci, 总共会跑两次</li>
<li>不能缺少 tag-name， 使用 rules: - if: $CI_COMMIT_TAG, 只有打 tag 的时候才运行</li>
<li><a target="_blank" rel="noopener" href="https://kinsta.com/knowledgebase/401-error/">401 error</a></li>
</ul>
</li>
<li>删除 tag 就能删除 release 对应内容</li>
<li>gitlab release comment 支持 markdown 和 mermaid</li>
</ol>
<h2 id="pipeline"><a href="#pipeline" class="headerlink" title="pipeline"></a>pipeline</h2><ol>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/triggers/">trigger other pipeline</a></li>
<li>前面加 dot，可以隐藏 job <a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/jobs/#hide-jobs">link</a></li>
</ol>
<h2 id="ssh"><a href="#ssh" class="headerlink" title="ssh"></a><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/ssh_keys/">ssh</a></h2><ol>
<li>区分多种执行方式：<ul>
<li>shell: 需要 runenr</li>
<li>docker: 在 docker 下执行，不需要指定 runner</li>
<li>ssh</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://gitlab.com/gitlab-examples/ssh-private-key/-/blob/master/.gitlab-ci.yml">example</a></li>
<li><a target="_blank" rel="noopener" href="https://gitlab.com/gitlab-examples/ssh-private-key/-/issues/1#note_48526556">ssh-key 要求</a></li>
<li>需要在 deploy 机器上生成 ssh， private key 作为变量传入配置中</li>
<li>shell 需要在 runner 机器上秘钥对，把公钥复制到部署板子上 <code>ssh-copy-id -i ~/.ssh/id_rsa.pub xxx@xxx</code></li>
</ol>
<h2 id="runner"><a href="#runner" class="headerlink" title="runner"></a><a target="_blank" rel="noopener" href="https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-section">runner</a></h2><ol>
<li>可以 reset token <a target="_blank" rel="noopener" href="https://docs.gitlab.com/runner/commands/#gitlab-runner-reset-token">link</a></li>
<li>gitlab repo ci 配置可以显示安装 runner 命令</li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/runner/commands/">commands</a></li>
<li><code>gitlab-ci-multi-runner list</code> list runners</li>
<li><code>gitlab-ci-multi-runner status</code></li>
<li><code>/etc/gitlab-runner/</code> 配置路径</li>
<li>注册 project for runner:<ul>
<li><code>gitlab-runner register</code></li>
<li><code>gitlab-runner verify</code> 如果是感叹号执行这条命令</li>
<li><code>gitlab-runner unregister --name test-runner</code> 删除 runner</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#docker-in-docker-with-tls-enabled-in-the-docker-executor">docker in docker</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runnersdocker-section">docker image param setting</a><ul>
<li>需要再创建 runner 的时候设置</li>
<li>&#x2F;etc&#x2F;gitlab-runner&#x2F;config.toml 可以直接改传递参数</li>
</ul>
</li>
<li>使用 <a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/runners/runners_scope.html">shared runner</a>:<ul>
<li>需要 admin 用户</li>
<li>group 下默认有</li>
</ul>
</li>
<li>Group runners:This project does not belong to a group and cannot make use of group runners. 只需要 group tocken 就好</li>
</ol>
<h2 id="script"><a href="#script" class="headerlink" title="script"></a>script</h2><ol>
<li>所有 job 都执行</li>
</ol>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">default:</span></span><br><span class="line"><span class="symbol">  before_script:</span></span><br><span class="line">    - echo <span class="string">&quot;Execute this script in all jobs that don&#x27;t already have a before_script section.&quot;</span></span><br><span class="line"><span class="symbol"></span></span><br><span class="line"><span class="symbol">job1:</span></span><br><span class="line"><span class="symbol">  script:</span></span><br><span class="line">    - echo <span class="string">&quot;This script executes after the global before_script.&quot;</span></span><br><span class="line"><span class="symbol"></span></span><br><span class="line"><span class="symbol">job:</span></span><br><span class="line"><span class="symbol">  before_script:</span></span><br><span class="line">    - echo <span class="string">&quot;Execute this script instead of the global before_script.&quot;</span></span><br><span class="line"><span class="symbol">  script:</span></span><br><span class="line">    - echo <span class="string">&quot;This script executes after the job&#x27;s `before_script`&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="deploy"><a href="#deploy" class="headerlink" title="deploy"></a>deploy</h2><ol>
<li><code>sshpass -p $PASSWORD scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -r ./build $CUSTOM_USERNAME@$CUSTOM_IP:/var/www/html</code> sshpass 设置 ci 变量</li>
<li><code>sshpass -p $PASSWORD sshpass -p root rsync -avz -e &quot;ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null&quot; -r ./build $CUSTOM_USERNAME@$CUSTOM_IP:/var/www/html</code></li>
</ol>
<h2 id="prefill-variables"><a href="#prefill-variables" class="headerlink" title="prefill variables"></a>prefill variables</h2><ol>
<li><a target="_blank" rel="noopener" href="https://gitlab.com/gitlab-org/gitlab/-/issues/300106">how to use prefill variables</a></li>
<li>两种方式：<ul>
<li>yml 文件中<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">variables:</span></span><br><span class="line"><span class="attr">PASSWORD:</span></span><br><span class="line">  <span class="attr">value:</span> <span class="string">&quot;123456&quot;</span></span><br><span class="line">  <span class="attr">pdescription:</span> <span class="string">&quot;password&quot;</span></span><br><span class="line"><span class="attr">CUSTOM_USERNAME:</span></span><br><span class="line">  <span class="attr">value:</span> <span class="string">&quot;petalinux&quot;</span></span><br><span class="line">  <span class="attr">description:</span> <span class="string">&quot;username&quot;</span></span><br></pre></td></tr></table></figure></li>
<li>project CI&#x2F;CD variable settings</li>
</ul>
</li>
</ol>
<h2 id="workflow"><a href="#workflow" class="headerlink" title="workflow"></a><a target="_blank" rel="noopener" href="https://docs.gitlab.com/14.8/ee/ci/yaml/workflow.html">workflow</a></h2><h2 id="keys"><a href="#keys" class="headerlink" title="keys"></a>keys</h2><h3 id="needs"><a href="#needs" class="headerlink" title="needs"></a>needs</h3><ol>
<li>可以用来串联 stage</li>
<li>传递 stage 文件需要 <a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/yaml/index.html#needsartifacts">link</a></li>
<li>可以看 pipeline efficiency <a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/pipelines/pipeline_efficiency.html">link</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/directed_acyclic_graph/">DAG</a></li>
</ol>
<h2 id="rules"><a href="#rules" class="headerlink" title="rules"></a>rules</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/gitlabhq/gitlabhq/blob/2ea638391497c495798e0bab7c704af112789299/.gitlab/ci/rules.gitlab-ci.yml">rules 模板</a></li>
<li>只手动编译， 有个按键可以执行所有 job</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">.rules:if-tag-or-manual:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&lt;&lt;:</span> <span class="string">*if-tag</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">when:</span> <span class="string">manual</span></span><br><span class="line"></span><br><span class="line"><span class="string">.rules:always:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">when:</span> <span class="string">always</span></span><br><span class="line">      <span class="attr">allow_failure:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## fix mr detach issue； merge_request_event or push 禁止一个</span></span><br><span class="line"><span class="attr">workflow:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">if:</span> <span class="string">&#x27;$CI_PIPELINE_SOURCE == &quot;merge_request_event&quot;&#x27;</span></span><br><span class="line">      <span class="attr">when:</span> <span class="string">never</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">when:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line"><span class="attr">stages:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">build</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">test</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Build::GPU_ubuntu20.04:</span></span><br><span class="line">  <span class="attr">extends:</span></span><br><span class="line">    <span class="string">.rules:if-tag-or-manual</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>失败自动 format</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Build::Format:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">if:</span> <span class="string">&#x27;$CI_PIPELINE_SOURCE == &quot;merge_request_event&quot;&#x27;</span></span><br><span class="line">      <span class="attr">when:</span> <span class="string">on_failure</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">when:</span> <span class="string">never</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">build</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">xxx</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">xxx</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">bash</span> <span class="string">ci/format.sh</span></span><br></pre></td></tr></table></figure>

<ol>
<li>在 mr 时自动运行全流程，or 手动选择要编译的平台</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">.if-tag:</span> <span class="string">&amp;if-tag</span></span><br><span class="line">  <span class="attr">if:</span> <span class="string">&#x27;$CI_COMMIT_TAG&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">.if-merge-request:</span> <span class="string">&amp;if-merge-request</span></span><br><span class="line">  <span class="attr">if:</span> <span class="string">$CI_PIPELINE_SOURCE</span> <span class="string">==</span> <span class="string">&quot;merge_request_event&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">.if-tag-or-mr:</span> <span class="string">&amp;if-tag-or-mr</span></span><br><span class="line">  <span class="attr">if:</span> <span class="string">&#x27;$CI_COMMIT_TAG&#x27;</span></span><br><span class="line">  <span class="attr">if:</span> <span class="string">$CI_PIPELINE_SOURCE</span> <span class="string">==</span> <span class="string">&quot;merge_request_event&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">.rules:if-tag-or-mr-or-manual:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&lt;&lt;:</span> <span class="string">*if-tag-or-mr</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">when:</span> <span class="string">manual</span></span><br><span class="line"></span><br><span class="line"><span class="string">.rules:always:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">when:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line"><span class="attr">stages:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">build</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">test</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Build::GPU_ubuntu20.04:</span></span><br><span class="line">  <span class="attr">extends:</span></span><br><span class="line">    <span class="string">.rules:if-tag-or-mr-or-manual</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Build::Vitis:</span></span><br><span class="line">  <span class="attr">extends:</span></span><br><span class="line">    <span class="string">.rules:if-tag-or-mr-or-manual</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/yaml/#workflowrules">workflowrules 控制整个 pipeline</a></li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">workflow:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">if:</span> <span class="string">$CI_COMMIT_TITLE</span> <span class="string">=~</span> <span class="string">/-draft$/</span></span><br><span class="line">      <span class="attr">when:</span> <span class="string">never</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">if:</span> <span class="string">$CI_PIPELINE_SOURCE</span> <span class="string">==</span> <span class="string">&quot;merge_request_event&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">if:</span> <span class="string">$CI_COMMIT_BRANCH</span> <span class="string">==</span> <span class="string">$CI_DEFAULT_BRANCH</span></span><br></pre></td></tr></table></figure>

<ol>
<li>when, can only be always or never when used with workflow. 不能 when: manual, 不支持</li>
<li>可以设置一个伪 job， manual 触发，后续 job 依赖伪 job</li>
<li>完善解决方案： 使用 <a target="_blank" rel="noopener" href="https://github.com/GNOME/gnome-shell/blob/4bbf6d497d34793693e5ac24fbe23854b481002b/.gitlab-ci.yml#L41">temlate</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/jobs/job_control.html#avoid-duplicate-pipelines">avoid-duplicate-pipelines</a></li>
</ol>
<figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rules:</span><br><span class="line">   - <span class="keyword">if</span>: &#x27;<span class="built_in">$CI</span>_PIPELINE_SOURCE == <span class="string">&quot;merge_request_event&quot;</span>&#x27;</span><br></pre></td></tr></table></figure>

<ol>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/jobs/job_control.html#reuse-rules-in-different-jobs">default-rules(&gt;&#x3D;14.3)</a></li>
</ol>
<h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><ol>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/yaml/script.html#split-long-commands">split-long-commands</a></li>
<li>gtest 结果 xml 可以显示到 ci pipeline 结果中去 <a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/unit_test_reports.html">link</a></li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">stages:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">test</span></span><br><span class="line"></span><br><span class="line"><span class="attr">cpp:</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">./gtxxx</span> <span class="string">--gtest_output=xml:report.xml</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">artifacts:</span></span><br><span class="line">    <span class="attr">when:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">reports:</span></span><br><span class="line">      <span class="attr">junit:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">report.xml</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">fail.xml</span></span><br></pre></td></tr></table></figure>

<ol>
<li>cache 时相同的 Key path 文件内容要完全一样，否则不能 cache</li>
<li>deploy 两种方式：<ul>
<li>runner shell Executor: 交叉编译后传到板子上执行</li>
<li>runner ssh Executor: 登录到板子，Mount 服务器执行(板子存储受限，不可重复，慢)</li>
</ul>
</li>
<li><code>sudo su - gitlab-runner</code> ssh board 时要进入 runner 服务器 gitlab-runner 用户</li>
<li>如果想在板子上运行脚本，需要 ssh 执行器<a target="_blank" rel="noopener" href="https://blog.csdn.net/lihao21/article/details/109820904">link</a></li>
<li>ssh 后跟在远端执行的命令</li>
</ol>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">script:</span><br><span class="line">    - echo <span class="string">&quot;ssh board......................&quot;</span></span><br><span class="line">    - ssh -o <span class="attribute">StrictHostKeyChecking</span>=<span class="literal">no</span> -o <span class="attribute">UserKnownHostsFile</span>=/dev/null root@10.31.1.170 <span class="string">&quot;whoami&quot;</span></span><br></pre></td></tr></table></figure>

<ol>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-section">修改 runner build 位置 builds_dir</a> 配置路径<code>/etc/gitlab-runner/</code>或<code>~/.gitlab-runner/</code></li>
</ol>
<h2 id="Links"><a href="#Links" class="headerlink" title="Links"></a>Links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/184936276">Gitlab-ci:从零开始的前端自动化部署</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/">GitLab CI&#x2F;CD</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/variables/index.html#enable-debug-logging">Enable Debug logging</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/variables/index.html#list-all-environment-variables">List all environment variables</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/examples/#cicd-templates">CI&#x2F;CD templates</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.com/ee/ci/ssh_keys/">Using SSH keys with GitLab CI&#x2F;CD</a></li>
<li><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000006120164">概念</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.gitlab.cn/jh/ci/variables/">gitlab 中文文档</a></li>
<li><a target="_blank" rel="noopener" href="https://gitlab.phigent.io/help/ci/unit_test_reports">test reports</a></li>
<li><a target="_blank" rel="noopener" href="https://juejin.cn/post/6847902219837292558">搭建一个使用 GitLab CI 的项目</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/yejingtao703/article/details/83065591">Gitlab-Runner 原理与实现</a></li>
</ol>
<h2 id="samples"><a href="#samples" class="headerlink" title="samples"></a>samples</h2><ol>
<li>gitlab release + jfrog artifactory（如果 docker 有问题，通过 artifacts 传递文件， 在 release 传文件和配置链接）</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">stages:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">build</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">release</span></span><br><span class="line"></span><br><span class="line"><span class="attr">variables:</span></span><br><span class="line">  <span class="attr">TEST_FILE0:</span> <span class="string">&quot;test0-$&#123;PACKAGE_VERSION&#125;-$&#123;CI_COMMIT_TAG&#125;&quot;</span></span><br><span class="line">  <span class="attr">TEST_FILE1:</span> <span class="string">&quot;test1-$&#123;PACKAGE_VERSION&#125;-$&#123;CI_COMMIT_TAG&#125;&quot;</span></span><br><span class="line">  <span class="attr">PACKAGE_VERSION:</span> <span class="string">&quot;1.2.3&quot;</span></span><br><span class="line">  <span class="attr">PACKAGE_REGISTRY_URL:</span> <span class="string">&quot;http://artifacts.xxx.io/artifactory/dcv-cpp&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">default:</span></span><br><span class="line">  <span class="attr">before_script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">JFROG_USER=release</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">JFROG_PASSWD=xxx</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">      push_to_jfrog() &#123;</span></span><br><span class="line"><span class="string">          FILE=$1;</span></span><br><span class="line"><span class="string">          JFROG_PATH=http://artifacts.xxx.io/artifactory/$2;</span></span><br><span class="line"><span class="string">          MD5=$(md5sum $FILE | awk &#x27;&#123;print $1&#125;&#x27;);</span></span><br><span class="line"><span class="string">          curl -u&quot;$&#123;JFROG_USER&#125;:$&#123;JFROG_PASSWD&#125;&quot; -T $FILE -H &quot;X-Checksum-MD5:$&#123;MD5&#125;&quot; -L &quot;$&#123;JFROG_PATH&#125;&quot;;</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="attr">build:</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">build</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">hub.xxx.io/avp/cuda11.3.1-trt8.0.3.4-ros2-desktop-ubuntu20.04:v2.0</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">phigent_runner_gpu</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">$CI_COMMIT_TAG</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">mkdir</span> <span class="string">bin</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">&quot;$&#123;TEST_FILE0&#125;&quot;</span> <span class="string">&gt;</span> <span class="string">bin/$&#123;TEST_FILE0&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">&quot;$&#123;TEST_FILE1&#125;&quot;</span> <span class="string">&gt;</span> <span class="string">bin/$&#123;TEST_FILE1&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">      if [ &quot;$CI_COMMIT_TAG&quot; != &#x27;&#x27; ]; then</span></span><br><span class="line"><span class="string">        push_to_jfrog bin/$&#123;TEST_FILE0&#125; dcv-cpp/$&#123;CI_COMMIT_TAG&#125;/$&#123;TEST_FILE0&#125;</span></span><br><span class="line"><span class="string">        push_to_jfrog bin/$&#123;TEST_FILE1&#125; dcv-cpp/$&#123;CI_COMMIT_TAG&#125;/$&#123;TEST_FILE1&#125;; fi</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="attr">release:</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">phigent_runner_gpu</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">release</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">registry.gitlab.com/gitlab-org/release-cli:latest</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">if:</span> <span class="string">$CI_COMMIT_TAG</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">      release-cli create --name &quot;Release $CI_COMMIT_TAG&quot; --tag-name $CI_COMMIT_TAG \</span></span><br><span class="line"><span class="string">        --assets-link &quot;&#123;\&quot;name\&quot;:\&quot;$&#123;TEST_FILE0&#125;\&quot;,\&quot;url\&quot;:\&quot;$&#123;PACKAGE_REGISTRY_URL&#125;/$&#123;CI_COMMIT_TAG&#125;/$&#123;TEST_FILE0&#125;\&quot;&#125;&quot; \</span></span><br><span class="line"><span class="string">        --assets-link &quot;&#123;\&quot;name\&quot;:\&quot;$&#123;TEST_FILE1&#125;\&quot;,\&quot;url\&quot;:\&quot;$&#123;PACKAGE_REGISTRY_URL&#125;/$&#123;CI_COMMIT_TAG&#125;/$&#123;TEST_FILE1&#125;\&quot;&#125;&quot;</span></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/23/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><span class="page-number current">24</span><a class="page-number" href="/page/25/">25</a><span class="space">&hellip;</span><a class="page-number" href="/page/33/">33</a><a class="extend next" rel="next" href="/page/25/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="贾夕阳"
      src="/images/coder2.jpg">
  <p class="site-author-name" itemprop="name">贾夕阳</p>
  <div class="site-description" itemprop="description">深度学习/自动驾驶/C++/性能优化</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">196</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/jiaxiyang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jiaxiyang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



  <div class="links-of-recent-posts motion-element">
    <div class="links-of-recent-posts-title">
      <i class="fa fa-history fa-fw"></i>
      最近文章
    </div>
    <ul class="links-of-recent-posts-list">
        <li class="links-of-recent-posts-item">
          <a href="/2025/12/29/claude-code/" title="2025&#x2F;12&#x2F;29&#x2F;claude-code&#x2F;">claude code</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2025/08/20/AI-coding/" title="2025&#x2F;08&#x2F;20&#x2F;AI-coding&#x2F;">AI coding</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2025/04/28/Architecture/" title="2025&#x2F;04&#x2F;28&#x2F;Architecture&#x2F;">Computer Architecture</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2025/04/18/pytest/" title="2025&#x2F;04&#x2F;18&#x2F;pytest&#x2F;">pytest</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2025/01/18/cursor/" title="2025&#x2F;01&#x2F;18&#x2F;cursor&#x2F;">cursor</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021 – 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">贾夕阳</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">628k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">9:31</span>
</div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("06/26/2020 14:52:10");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_sphere.min.js"></script>


  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : '[object Object]',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://jiaxiyang.github.io/page/24/',]
      });
      });
  </script>


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'g32ipLmEye1u5l6wBGRJt03S-gzGzoHsz',
      appKey     : 'zHgLkAICsZUl9Mf8LfdoVigP',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

  

  <script src="/js/activate-power-mode.min.js"></script>
  <script>
    POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);
  </script>





 
</body>
</html>

