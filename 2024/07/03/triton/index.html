<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0-rc2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jiaxiyang.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="llvm-objdump &#x2F;share_data&#x2F;triton&#x2F;llvm_19_dir&#x2F;251205&#x2F;bin&#x2F;llvm-objdump --mattr&#x3D;+m,+c,+f,+a,+xsiorigin -zCDS &#39;&#x2F;data&#x2F;users&#x2F;jiaxiyang&#x2F;siorigin_triton&#x2F;.triton&#x2F;cache&#x2F;M32BYEN7L42EZJG5X3YO773ONZ4AROFGAJPD45">
<meta property="og:type" content="article">
<meta property="og:title" content="triton">
<meta property="og:url" content="https://jiaxiyang.github.io/2024/07/03/triton/index.html">
<meta property="og:site_name" content="Xiyang">
<meta property="og:description" content="llvm-objdump &#x2F;share_data&#x2F;triton&#x2F;llvm_19_dir&#x2F;251205&#x2F;bin&#x2F;llvm-objdump --mattr&#x3D;+m,+c,+f,+a,+xsiorigin -zCDS &#39;&#x2F;data&#x2F;users&#x2F;jiaxiyang&#x2F;siorigin_triton&#x2F;.triton&#x2F;cache&#x2F;M32BYEN7L42EZJG5X3YO773ONZ4AROFGAJPD45">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.ibb.co/cF3yF0K/e-Hk7ps-HTk-M.png">
<meta property="og:image" content="https://i.ibb.co/6NMJ8Yk/xo5-Pqj-RPDT.png">
<meta property="og:image" content="https://i.ibb.co/9VLhpNk/du-T6l-PNQfg.png">
<meta property="og:image" content="https://i.ibb.co/qFsBwJv/YMws76l-KOI.png">
<meta property="og:image" content="https://i.ibb.co/NYSS9WV/Xrz-Qku-ZLSo.png">
<meta property="og:image" content="https://i.ibb.co/qszbhN4/NYmmor-R0l-P.png">
<meta property="article:published_time" content="2024-07-03T07:04:53.000Z">
<meta property="article:modified_time" content="2025-12-15T08:54:04.593Z">
<meta property="article:author" content="è´¾å¤•é˜³">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.ibb.co/cF3yF0K/e-Hk7ps-HTk-M.png">

<link rel="canonical" href="https://jiaxiyang.github.io/2024/07/03/triton/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>triton | Xiyang</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WGS6S6YFJ6"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-WGS6S6YFJ6');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="åˆ‡æ¢å¯¼èˆªæ ">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Xiyang</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Think twice, code once!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>é¦–é¡µ</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>å½’æ¡£<span class="badge">195</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>åˆ†ç±»<span class="badge">44</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>æ ‡ç­¾<span class="badge">55</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>å…³äº</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>æœç´¢
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="æœç´¢..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/jiaxiyang" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2024/07/03/triton/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="è´¾å¤•é˜³">
      <meta itemprop="description" content="æ·±åº¦å­¦ä¹ /è‡ªåŠ¨é©¾é©¶/C++/æ€§èƒ½ä¼˜åŒ–">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          triton
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">å‘è¡¨äº</span>

              <time title="åˆ›å»ºæ—¶é—´ï¼š2024-07-03 15:04:53" itemprop="dateCreated datePublished" datetime="2024-07-03T15:04:53+08:00">2024-07-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2025-12-15 16:54:04" itemprop="dateModified" datetime="2025-12-15T16:54:04+08:00">2025-12-15</time>
              </span>

          
            <span class="post-meta-item" title="é˜…è¯»æ¬¡æ•°" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2024/07/03/triton/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/07/03/triton/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>27k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>25 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="llvm-objdump"><a href="#llvm-objdump" class="headerlink" title="llvm-objdump"></a>llvm-objdump</h2><ol>
<li><code>/share_data/triton/llvm_19_dir/251205/bin/llvm-objdump --mattr=+m,+c,+f,+a,+xsiorigin -zCDS &#39;/data/users/jiaxiyang/siorigin_triton/.triton/cache/M32BYEN7L42EZJG5X3YO773ONZ4AROFGAJPD45W3CBWOKVVXRRRA/alu_tile_kernel.elf&#39;  &gt; f32.log</code> åæ±‡ç¼–</li>
</ol>
<h2 id="lit-llvm-integrated-tester"><a href="#lit-llvm-integrated-tester" class="headerlink" title="lit (llvm integrated tester)"></a><a target="_blank" rel="noopener" href="https://llvm.org/docs/CommandGuide/lit.html">lit (llvm integrated tester)</a></h2><ol>
<li><a target="_blank" rel="noopener" href="https://mlir.llvm.org/getting_started/TestingGuide/">MLIR testing guide</a></li>
<li>The MLIR framework encourages existing best practices, e.g. writing and maintaining an IR spec, building an IR verifier, providing the ability to dump and parse MLIR files to text, writing extensive unit tests with the FileCheck tool, and building the infrastructure as a set of modular libraries that can be combined in new ways.</li>
<li><a target="_blank" rel="noopener" href="https://llvm.org/docs/CommandGuide/FileCheck.html">FileCheck</a></li>
<li><a target="_blank" rel="noopener" href="https://mlir.llvm.org/getting_started/TestingGuide/">MLIR lit</a></li>
<li>æ˜¯ LLVM&#x2F;MLIR æ ‡å‡†çš„ æµ‹è¯•è¿è¡Œæ¡†æ¶ã€‚</li>
<li>åœ¨ MLIR ä¸­ï¼Œ90% çš„æµ‹è¯•éƒ½æ˜¯ç”¨ lit + FileCheck ç»„æˆã€‚</li>
<li>å¯ä»¥æµ‹è¯•å¤šç§æ–‡ä»¶ï¼Œpythonä¹Ÿå¯ä»¥ï¼Œéœ€è¦# RUN %PYTHON %s 2&gt;&amp;1</li>
<li>FileCheck ç”¨æ¥åŒ¹é…è¾“å‡º; åˆ æ‰å¯ä»¥æŸ¥çœ‹è¾“å‡ºç»“æœ</li>
<li>ç›´æ¥ä½¿ç”¨triton-op %sæ¥éªŒè¯æ˜¯å¦æœ‰è§£æé”™è¯¯</li>
<li>MLIR çš„ç»å¤§éƒ¨åˆ†æµ‹è¯•ï¼ˆ.mlirã€.tdã€.cpp ç­‰ï¼‰éƒ½ä¾èµ– lit æ¥è¿è¡Œã€‚<ul>
<li><code># RUN: mlir-opt %s -convert-scf-to-cf | FileCheck %s</code> mliræ–‡ä»¶æ³¨é‡Šæ˜¯è¦æ‰§è¡Œçš„å‘½ä»¤; ç”¨ .mlir æ–‡ä»¶ä½œä¸ºè¾“å…¥ï¼Œè¿è¡ŒæŸäº› passï¼Œæœ€åç”¨ FileCheck éªŒè¯è¾“å‡ºã€‚</li>
</ul>
</li>
<li>è§£é‡Š</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// RUN: triton-opt %s -split-input-file -verify-diagnostics</span><br><span class="line">å«ä¹‰æ˜¯ï¼šlit ä¼šç”¨ `triton-opt` è¯»å–è¿™ä¸ªæ–‡ä»¶ `%s`ï¼Œå¹¶åŠ ä¸Šä¸¤ä¸ªå…³é”®é€‰é¡¹ï¼š</span><br><span class="line">- `-split-input-file`ï¼šæŒ‰æ–‡ä»¶ä¸­çš„ `// -----` åˆ†éš”ï¼ŒæŠŠä¸€ä¸ªæ–‡ä»¶**æ‹†æˆå¤šä¸ªå­æ¨¡å—/å­æµ‹è¯•**ï¼Œæ¯ä¸ªå­å—å•ç‹¬è·‘ä¸€éã€‚</span><br><span class="line">- `-verify-diagnostics`ï¼šè®© MLIR æ£€æŸ¥æ¯ä¸ªå—ä¸­ `// expected-error` ä¹‹ç±»çš„æ³¨é‡Šï¼Œ**éªŒè¯è¯Šæ–­ï¼ˆæŠ¥é”™/è­¦å‘Šï¼‰æ˜¯å¦æŒ‰é¢„æœŸå‡ºç°**ã€‚</span><br></pre></td></tr></table></figure>
<ol>
<li>çœ‹ä¸­é—´ç»“æœ</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// RUN: mlir-translate -mlir-to-llvmir %s | llc -mtriple=riscv64-rv64gv-linux-gnu -mcpu=sipu100 | FileCheck %s</span><br><span class="line">æ”¹ä¸º</span><br><span class="line">// RUN: mlir-translate -mlir-to-llvmir %s | tee /dev/tty | llc -mtriple=riscv64-rv64gv-linux-gnu -mcpu=sipu100 | tee /dev/tty | FileCheck %s</span><br><span class="line">æˆ–</span><br><span class="line">// RUN: mlir-translate -mlir-to-llvmir %s &gt; tranlate.llc &amp;&amp; llc -mtriple=riscv64-rv64gv-linux-gnu -mcpu=sipu100 tranlate.llc -o tranlate.llc.s &amp;&amp; FileCheck %s &lt; tranlate.llc.s</span><br><span class="line">æˆ– å»æ‰ FileCheck</span><br><span class="line">// RUN: mlir-translate -mlir-to-llvmir %s | llc -mtriple=riscv64-rv64gv-linux-gnu -mcpu=sipu100</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>ä¿®æ”¹triton Makefileä»£ç test-lintå‘½ä»¤åŠ ä¸Š<code>-v</code>, ä½¿ç”¨ <code>make test-lint</code>å‘½ä»¤å¯ä»¥æ‰“å°å‡ºæµ‹è¯•çš„ä¾‹å­<ul>
<li>åˆ°buildç›®å½•ä¸‹<code>lit -v test/</code>æ‰§è¡Œï¼Œå¯ä»¥çœ‹åˆ°æ¯ä¸€ä¸ªæµ‹è¯•æµ‹è¯•çŠ¶æ€, testæ˜¯è·¯å¾„,æµ‹è¯•è·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶</li>
<li><code>lit --show-tests test/</code> åªæŸ¥çœ‹ä¸æ‰§è¡Œ</li>
<li><code>lit -v test/TritonSIPU/IR/linear-layout-attribute.mlir</code>åªæ‰§è¡Œä¸€ä¸ªæµ‹è¯•</li>
<li><code>lit -a tile-indexed-load-store.mlir</code> æ‰§è¡Œä¸€ä¸ªæ–‡ä»¶çš„æµ‹è¯•</li>
<li><code>lit -a --filter &#39;linear-layout-attribute.mlir&#39; test/</code> filterè¿‡æ»¤ï¼Œfilter_outæ’é™¤</li>
<li><code>-a</code> è¾“å‡ºæµ‹è¯•è¿‡ç¨‹ä¸­çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…å«æµ‹è¯•çš„è¾“å…¥è¾“å‡º</li>
<li><code>--debug</code>æ‰“å°é…ç½®ä¿¡æ¯</li>
</ul>
</li>
<li>cp buildç›®å½•ä¸‹ <code>lit.site.cfg.py</code> åˆ°test&#x2F; æ–‡ä»¶å¤¹ä¸‹ï¼Œå°±èƒ½åœ¨testç›®å½•ä¸‹ç›´æ¥è¿è¡Œlit</li>
</ol>
<h2 id="NOTE"><a href="#NOTE" class="headerlink" title="NOTE"></a>NOTE</h2><ol>
<li>pytorch tritonè°ƒåº¦ï¼šTriton çš„ kernel è°ƒåº¦æ˜¯ PyTorchï¼ˆå‡†ç¡®è¯´æ˜¯ TorchInductorï¼‰æ ¹æ®å›¾ä¼˜åŒ–ç»“æœã€å¼ é‡å½¢çŠ¶å’Œç¡¬ä»¶ä¿¡æ¯æ¥å†³ç­–çš„ï¼ŒTriton åªæ˜¯è´Ÿè´£ç”Ÿæˆå’Œç¼–è¯‘ kernelï¼Œä¸è´Ÿè´£è°ƒåº¦ç­–ç•¥æœ¬èº«ã€‚</li>
<li>tritonæ˜¯thread blockç²’åº¦çš„ç¼–ç¨‹ï¼Œ ä¸éœ€è¦åˆ’åˆ†threads(warp)ï¼Œåªéœ€è¦è®¡ç®—å¥½æ¯ä¸ªthread blockè¦ç®—çš„æ•°ï¼Œå’Œç®—æ³•æµç¨‹<ul>
<li>flashâ€”attention v1 å’Œ v2å¤„ç†çš„æ•°æ®ä¸åŒï¼Œv1 ä¸€ä¸ªthread blockå¤„ç†1ä¸ªhead attention, v2ä¸€ä¸ªthread blockå¤„ç† 1&#x2F;num_m_blocksä¸ªhead attention</li>
</ul>
</li>
<li>kernel å…¥å‚æ²¡ç”¨æœ€å¥½åˆ é™¤ï¼Œç¼–è¯‘å‡ºçš„ttirå’Œdriver.pyå‚æ•°å¯èƒ½å¯¹ä¸ä¸Š</li>
<li>å‚è€ƒmlir dialect td<a target="_blank" rel="noopener" href="https://github.com/llvm/llvm-project/blob/2e82a17f4e71a833cc3ca4a832bd14a5ef537616/mlir/include/mlir/Dialect/Arith/IR/ArithOps.td">llvm-project milr dialect td defination</a></li>
</ol>
<h2 id="valueæ„é€ "><a href="#valueæ„é€ " class="headerlink" title="valueæ„é€ "></a>valueæ„é€ </h2><ol>
<li>include&#x2F;triton&#x2F;Conversion&#x2F;TritonGPUToLLVM&#x2F;Utility.h<ul>
<li>i64_val(3)</li>
<li>#define i64_val(â€¦) LLVM::createConstantI64(loc, rewriter, <strong>VA_ARGS</strong>)</li>
</ul>
</li>
</ol>
<h2 id="recompile"><a href="#recompile" class="headerlink" title="recompile"></a>recompile</h2><ol>
<li>tritonåœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä¼šrecompile kernel</li>
<li>ä¸åŒè¾“å…¥å‘é‡åŒ–é•¿åº¦ä¸ä¸€æ ·ï¼Ÿè¾“å…¥æ•°æ®é•¿åº¦èƒ½å½±å“llirç”Ÿæˆï¼Ÿæµ‹è¯•å‘ç°ç¡®å®å˜äº†ï¼Œ BLOCK_SIZE&#x3D;2048æ—¶ä¼šç”Ÿæˆä¸¤ç§llir</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/triton-lang/triton/blob/99b5e296ca21ba21b6c02dc48391422e53f25ffb/python/triton/runtime/jit.py#L580</span><br><span class="line">https://github.com/triton-lang/triton/blob/99b5e296ca21ba21b6c02dc48391422e53f25ffb/python/triton/runtime/jit.py#L320</span><br><span class="line">https://github.com/triton-lang/triton/blob/99b5e296ca21ba21b6c02dc48391422e53f25ffb/python/triton/backends/compiler.py#L79</span><br><span class="line">å˜é‡æ˜¯16çš„å€æ•°ä¼šç‰¹æ®Šå¤„ç†ï¼Œ specializationå‚æ•°çš„keyä¼šåŠ D</span><br><span class="line">key:  [(&#x27;*i32&#x27;, &#x27;D&#x27;), (&#x27;*i32&#x27;, &#x27;D&#x27;), (&#x27;i32&#x27;, &#x27;&#x27;)]&#123;&#x27;num_warps&#x27;: 1, &#x27;debug&#x27;: False&#125;</span><br><span class="line">key:  [(&#x27;*i32&#x27;, &#x27;D&#x27;), (&#x27;*i32&#x27;, &#x27;D&#x27;), (&#x27;i32&#x27;, &#x27;D&#x27;)]&#123;&#x27;num_warps&#x27;: 1, &#x27;debug&#x27;: False&#125;</span><br><span class="line">æ‰€ä»¥nåœ¨16çš„å€æ•°å’Œé16å€æ•°ä¹‹é—´åˆ‡æ¢æ—¶ä¼šrecompile</span><br></pre></td></tr></table></figure>

<h2 id="mask"><a href="#mask" class="headerlink" title="mask"></a>mask</h2><ol>
<li>åœ¨ Triton ä¸­ï¼Œmask æ˜¯æ§åˆ¶ æ˜¯å¦å‚ä¸è®¡ç®— çš„ä¸€ä¸ªéå¸¸é‡è¦çš„æœºåˆ¶ï¼Œé€šå¸¸ç”¨äº é¿å…è¶Šç•Œè®¿é—® æˆ– æ¡ä»¶æ‰§è¡Œã€‚åœ¨ç¼–å†™ Triton kernel æ—¶ï¼Œmask ä¸€èˆ¬é…åˆ tl.where, tl.load, tl.store ç­‰æŒ‡ä»¤ä½¿ç”¨ã€‚</li>
<li>load, storeåªæ˜¯é¿å…è¶Šç•Œè®¿é—®ï¼Œwhereæ‰æ˜¯maskæ•°æ®æ‰§è¡Œçš„</li>
<li><a target="_blank" rel="noopener" href="https://github.com/triton-lang/triton/blob/607c50cc9fdd2541db88b5a8681164f081dd71ad/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/LoadStoreOpToLLVM.cpp#L210">loadæ ¹æ®ptrå’Œmaskè®¡ç®—å‘é‡åŒ–loadé•¿åº¦</a></li>
<li>triton-cpu<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/triton-lang/triton-cpu/blob/0625715c271426eb61dd37c43deb8bc954bf4f23/third_party/cpu/lib/TritonToTritonCPU/ConvertMemoryOps.cpp#L184">ä¸¤ç§æƒ…å†µä¸‰ç§å¤„ç†æ–¹å¼</a></li>
</ul>
</li>
</ol>
<h2 id="tutorial"><a href="#tutorial" class="headerlink" title="tutorial"></a>tutorial</h2><h3 id="06-fused-attention"><a href="#06-fused-attention" class="headerlink" title="06 fused-attention"></a>06 fused-attention</h3><ol>
<li>â€œon-bandâ€ é€šå¸¸æŒ‡çš„æ˜¯é è¿‘æ³¨æ„åŠ›çŸ©é˜µä¸»å¯¹è§’çº¿çš„éƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯å½“å‰ token æ›´å¤šåœ°å…³æ³¨è‡ªå·±é™„è¿‘çš„ tokenã€‚</li>
<li>â€œoffbandâ€ æŒ‡çš„æ˜¯è·ç¦»å¯¹è§’çº¿è¾ƒè¿œçš„æ³¨æ„åŠ›ï¼Œä¹Ÿå°±æ˜¯ token å…³æ³¨çš„ä½ç½®æ¯”è¾ƒè¿œï¼ˆé•¿è·ç¦»ä¾èµ–ï¼‰</li>
</ol>
<h2 id="libdevice"><a href="#libdevice" class="headerlink" title="libdevice"></a>libdevice</h2><ol>
<li>è°ƒç”¨åº“</li>
<li><a target="_blank" rel="noopener" href="https://github.com/triton-lang/triton/blob/7a83ed78d95e0afcf89ea25289347fb079d47756/python/tutorials/07-extern-functions.py#L43">07-extern-functions.py</a></li>
</ol>
<h2 id="cudaå’ŒtritonåŒºåˆ«"><a href="#cudaå’ŒtritonåŒºåˆ«" class="headerlink" title="cudaå’ŒtritonåŒºåˆ«"></a>cudaå’ŒtritonåŒºåˆ«</h2><ol>
<li><a target="_blank" rel="noopener" href="https://chatgpt.com/share/67dcd467-b918-8004-886d-5d3381653365">gpt</a></li>
<li>ç¼–ç¨‹ç²’åº¦ï¼š cuda æ˜¯thread, triton æ˜¯thread block</li>
</ol>
<h2 id="ALU-å’Œ-SFU"><a href="#ALU-å’Œ-SFU" class="headerlink" title="ALU å’Œ SFU"></a>ALU å’Œ SFU</h2><ol>
<li>ALUï¼ˆArithmetic Logic Unitï¼‰ </li>
<li>SFUï¼ˆSpecial Function Unitï¼‰ </li>
<li>ALUï¼ˆArithmetic Logic Unitï¼‰ å’Œ SFUï¼ˆSpecial Function Unitï¼‰ æ˜¯ç°ä»£å¤„ç†å™¨ï¼ˆå°¤å…¶æ˜¯ GPUï¼‰ä¸­ç»å¸¸å¹¶å­˜çš„ä¸¤ç±»è®¡ç®—å•å…ƒ</li>
</ol>
<h2 id="å¯¹æ•°"><a href="#å¯¹æ•°" class="headerlink" title="å¯¹æ•°"></a>å¯¹æ•°</h2><ol>
<li>mmaç”Ÿæˆæ¯”è¾ƒçŸ©é˜µtxt</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">result = (matmul_outputs_sipu.to(<span class="string">&quot;cpu&quot;</span>)- matmul_outputs_golden).<span class="built_in">abs</span>() &gt; <span class="number">0.1</span>  <span class="comment"># è¯¯å·®å¤§äº 0.1 çš„åœ°æ–¹è®¾ä¸º True</span></span><br><span class="line">result = result.to(torch.<span class="built_in">int</span>)  <span class="comment"># è½¬æ¢ä¸ºæ•´æ•° (1 è¡¨ç¤ºè¯¯å·®è¶…å‡ºï¼Œ0 è¡¨ç¤ºæ­£å¸¸)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨ NumPy åŠ é€Ÿå†™å…¥</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.savetxt(<span class="string">&quot;result1.txt&quot;</span>, result.cpu().numpy()[:<span class="number">64</span>, :<span class="number">64</span>], fmt=<span class="string">&quot;%d&quot;</span>)</span><br><span class="line"></span><br><span class="line">result = (C - golden_C).<span class="built_in">abs</span>() &gt; <span class="number">0.1</span></span><br><span class="line">result = result.to(torch.<span class="built_in">int</span>)  <span class="comment"># å°†å¸ƒå°”å€¼è½¬æ¢ä¸ºæ•´æ•°</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;result1.txt&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(result.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(result.shape[<span class="number">1</span>]):</span><br><span class="line">            f.write(<span class="string">f&quot;<span class="subst">&#123;result[i, j].item()&#125;</span> &quot;</span>)</span><br><span class="line">        f.write(<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="coordinate-åˆ°-indexçš„æ˜ å°„"><a href="#coordinate-åˆ°-indexçš„æ˜ å°„" class="headerlink" title="coordinate åˆ° indexçš„æ˜ å°„"></a>coordinate åˆ° indexçš„æ˜ å°„</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#  åæ ‡(x, y)åˆ°indexçš„è½¬æ¢, å°†Mè¡ŒNåˆ—çŸ©é˜µåˆ’åˆ†ä¸ºï¼ˆm, n) çš„block,blockå†…éƒ¨è¡Œä¼˜å…ˆå­˜å‚¨ï¼Œblockä¹‹é—´ä¹Ÿæ˜¯è¡Œä¼˜å…ˆ</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  block index </span></span><br><span class="line"><span class="comment">#  block_row = x // m</span></span><br><span class="line"><span class="comment">#  block_col = y // n</span></span><br><span class="line"><span class="comment">#  blocks_per_row = N // n</span></span><br><span class="line"><span class="comment">#  block_index = block_row * blocks_per_row + block_col = x // m * (N // n) + y // n</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  local index</span></span><br><span class="line"><span class="comment">#  local_row = x % m</span></span><br><span class="line"><span class="comment">#  local_col = y % n</span></span><br><span class="line"><span class="comment">#  local_index = local_row * n + local_col = x % m * n + y % n</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  global index</span></span><br><span class="line"><span class="comment">#  global_index = block_index * m * n + local_index = (x // m * (N // n) + y // n) * m * n + x % m * n + y % n</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (x, y) -&gt; (x // m * (N // n) + y // n) * m * n + x % m * n + y % n</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#åæ ‡(x, y)åˆ°indexçš„è½¬æ¢, å°†Mè¡ŒNåˆ—çŸ©é˜µåˆ’åˆ†ä¸ºï¼ˆm, n) çš„block,blockå†…éƒ¨åˆ—ä¼˜å…ˆå­˜å‚¨ï¼Œblockä¹‹é—´ä¹Ÿæ˜¯åˆ—ä¼˜å…ˆ</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  block index </span></span><br><span class="line"><span class="comment">#  block_row = x // m</span></span><br><span class="line"><span class="comment">#  block_col = y // n</span></span><br><span class="line"><span class="comment">#  blocks_per_col = M // m</span></span><br><span class="line"><span class="comment">#  block_index = block_col * blocks_per_col + block_row = y // n * (M // m) + x // m</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  local index</span></span><br><span class="line"><span class="comment">#  local_row = x % m</span></span><br><span class="line"><span class="comment">#  local_col = y % n</span></span><br><span class="line"><span class="comment">#  local_index = local_col * m + local_row = y % n * m + x % m</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  global index</span></span><br><span class="line"><span class="comment">#  global_index = block_index * m * n + local_index = (y // n * (M // m) + x // m) * m * n + y % n * m + x % m</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (x, y) -&gt; (y // n * (M // m) + x // m) * m * n + y % n * m + x % m</span></span><br></pre></td></tr></table></figure>


<h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a><a target="_blank" rel="noopener" href="https://github.com/triton-lang/triton/tree/main/bin">Tools</a></h2><ol>
<li>vscode mlir æ’ä»¶é…ç½® triton-lsp<ul>
<li>opå¯ä»¥è·³è½¬åˆ°srcå®šä¹‰</li>
<li>locå¯ä»¥çœ‹è¡Œæ•°</li>
<li>log.txtä¸­å¯ä»¥çœ‹outlineï¼Œèƒ½æ‰¾åˆ°IR Dump Before</li>
<li>éœ€è¦æ³¨å†Œè‡ªå®šä¹‰dialet <a target="_blank" rel="noopener" href="https://github.com/triton-lang/triton/blob/main/bin/RegisterTritonDialects.h">link</a>ï¼šå¤´æ–‡ä»¶å’Œregistry.insert dialect, æ³¨å†Œpass</li>
</ul>
</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;siorigin/include/Dialect/TritonSIPU/IR/Dialect.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;siorigin/include/TritonToTritonSIPU/Passes.h&quot;</span></span></span><br><span class="line">mlir::triton::siorigin::<span class="built_in">registerConvertLoadStoreOpsPass</span>();</span><br><span class="line">registry.insert&lt;mlir::triton::siorigin::TritonSIPUDialect&gt;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li><a target="_blank" rel="noopener" href="https://mlir.llvm.org/docs/Tools/MLIRLSP/#build-system-integration-1">tablegen_compile_commands.yml</a><ul>
<li>é…ç½®mlir tblgen-lsp-server å’Œ tablen_compile_commands.yml</li>
<li>å¯ä»¥ä»tdæ–‡ä»¶è·³è½¬åˆ°ç”Ÿæˆçš„å®šä¹‰</li>
<li>hover</li>
</ul>
</li>
<li>triton-opt</li>
<li>triton-llvm-opt</li>
<li>graphiviz<ul>
<li><code>triton-opt matmul_kernel.ttir --view-op-graph --allow-unregistered-dialect &gt; test.dot 2&gt;&amp;1</code></li>
<li><a target="_blank" rel="noopener" href="https://marketplace.visualstudio.com/items?itemName=tintinweb.graphviz-interactive-preview">vscode plugin open dot file</a></li>
<li><a target="_blank" rel="noopener" href="https://mlir.llvm.org/docs/Passes/#-view-op-graph">view-op-graph</a></li>
</ul>
</li>
</ol>
<h3 id="triton-tensor-layout"><a href="#triton-tensor-layout" class="headerlink" title="triton-tensor-layout"></a>triton-tensor-layout</h3><ol>
<li>bin&#x2F;triton-tensor-layout.cpp æœ‰æµ‹è¯•å‘½ä»¤</li>
<li><code>triton-tensor-layout -i input.mlir -t &quot;tensor&lt;128xf32&gt;&quot; --use-hw-view  -o output1.mlir</code> <ul>
<li>input.mliråªåŒ…å«ç±»ä¼¼ <code>#blocked = #ttg.blocked&lt;&#123;sizePerThread = [1], threadsPerWarp = [1], warpsPerCTA = [1], order = [0]&#125;&gt;</code>çš„è¯­å¥</li>
<li>â€“use-hw-view ä»ç¡¬ä»¶çš„viewæ‰“å°ï¼Œ é»˜è®¤æ˜¯dataçš„view<ul>
<li>hwä¸‹warpä¸‹é¢ä¸€åˆ—ä»£è¡¨ä¸€ä¸ªthread</li>
</ul>
</li>
</ul>
</li>
<li><code>triton-tensor-layout -l &quot;#ttg.blocked&lt;&#123;sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]&#125;&gt;&quot; -t &quot;tensor&lt;16x16xf16&gt;&quot;</code> æ³¨æ„ï¼šç”¨ttgï¼Œä¸ç”¨triton_gpu</li>
<li><code>triton-tensor-layout -l &quot;#ttg.nvidia_mma&lt;&#123;versionMajor = 3, versionMinor = 0, warpsPerCTA = [8, 1], CTAsPerCGA = [1, 1], CTASplitNum = [1, 1], CTAOrder = [1, 0], instrShape = [16, 256, 32]&#125;&gt;&quot; -t &quot;tensor&lt;128x256xf16&gt;&quot;</code><ul>
<li>unittest&#x2F;Dialect&#x2F;TritonGPU&#x2F;DumpLayoutTest.cppé‡Œæœ‰æµ‹è¯•ä»£ç </li>
<li>å…³é”®ä»£ç : shared layout, distribute layout<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">std::string mlir::triton::gpu::<span class="built_in">getLayoutStr</span>(RankedTensorType tensorType,</span><br><span class="line">                                            <span class="type">bool</span> useHWPointOfView) &#123;</span><br><span class="line">  <span class="keyword">auto</span> layout = tensorType.<span class="built_in">getEncoding</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// tensorType is needed later on (e.g., getDimSize(j)), so we still have to</span></span><br><span class="line">  <span class="comment">// pass it as a param</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">auto</span> sharedLayout = mlir::<span class="built_in">dyn_cast</span>&lt;SharedEncodingAttr&gt;(layout)) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">getSharedLayoutStr</span>(tensorType, useHWPointOfView);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">auto</span> distributedLayout =</span><br><span class="line">                 mlir::<span class="built_in">dyn_cast</span>&lt;DistributedEncodingTrait&gt;(layout)) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">getDistributedLayoutStr</span>(tensorType, useHWPointOfView);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// else unimplemented, return error</span></span><br><span class="line">  llvm::<span class="built_in">report_fatal_error</span>(<span class="string">&quot;Unimplemented usage of getLayoutStr&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h3 id="lit"><a href="#lit" class="headerlink" title="lit"></a>lit</h3><h2 id="è¯­æ³•"><a href="#è¯­æ³•" class="headerlink" title="è¯­æ³•"></a>è¯­æ³•</h2><ol>
<li>tt.splat æ“ä½œç”¨äºå°†ä¸€ä¸ªæ ‡é‡å€¼æ‰©å±•ä¸ºä¸€ä¸ªå¼ é‡ï¼Œå…¶ä¸­æ‰€æœ‰å…ƒç´ éƒ½å…·æœ‰ç›¸åŒçš„æ ‡é‡å€¼ã€‚</li>
<li>tt.broadcast æ“ä½œç”¨äºå°†ä¸€ä¸ªè¾ƒå°çš„å¼ é‡æ‰©å±•ä¸ºä¸€ä¸ªè¾ƒå¤§çš„å¼ é‡ï¼Œé€šè¿‡å¤åˆ¶å…¶å…ƒç´ æ¥åŒ¹é…ç›®æ ‡å¼ é‡çš„å½¢çŠ¶ã€‚</li>
<li>NOTE: tutorial ä¸­çš„BLOCK_SIZEå’Œcudaä¸­çš„block_sizeä¸æ˜¯ä¸€æ ·çš„ï¼Œ BLOCK_SIZEæ˜¯data size, block sizeæ˜¯cudaä¸­ä¸€ä¸ªblockæœ‰å¤šå°‘thread<ul>
<li>BLOCK_SIZE æ˜¯ä¸€ä¸ªç¼–è¯‘æ—¶å¸¸é‡ï¼Œç”¨æ¥æŒ‡å®šæ¯ä¸ª kernel å®ä¾‹ï¼ˆä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯â€œtileâ€æˆ–â€œblockâ€ï¼‰è¦å¤„ç†çš„æ•°æ®é‡ï¼Œå³æ¯ä¸ªç¨‹åºå®ä¾‹è´Ÿè´£å¤„ç†å¤šå°‘ä¸ªå…ƒç´ ã€‚</li>
<li>block_size é€šå¸¸æ˜¯æŒ‡æ¯ä¸ª block ä¸­çš„çº¿ç¨‹æ€»æ•°ï¼ˆå³ num_warps Ã— 32ï¼‰ä»¥åŠæ¯ä¸ªçº¿ç¨‹è´Ÿè´£çš„å·¥ä½œé‡ï¼ˆsizePerThreadï¼‰</li>
<li>Triton ç¼–è¯‘å™¨å’Œè¿è¡Œæ—¶ä¼šæ ¹æ®è¿™ä¸ª BLOCK_SIZE è‡ªåŠ¨ç¡®å®šå®é™…çš„çº¿ç¨‹ç»„ç»‡ï¼ˆæ¯”å¦‚å¦‚ä½•åˆ†é…åˆ° warps ä¸­ï¼‰ï¼Œä»è€Œéšå¼åœ°ç®¡ç† num_warps å’Œ sizePerThread</li>
<li>æ•™ç¨‹ä¸­å®šä¹‰çš„ BLOCK_SIZE å¹¶æ²¡æœ‰å’Œæˆ‘ä»¬ä¹‹å‰è®¨è®ºçš„æ¦‚å¿µå†²çªï¼Œè€Œæ˜¯ç”¨ä¸€ç§æ›´é«˜å±‚çš„æŠ½è±¡æ¥è¡¨è¾¾åŒæ ·çš„æ€æƒ³ã€‚å®ƒæ—¢ä»£è¡¨äº†ä¸€ä¸ª block ä¸­éœ€è¦å¤„ç†çš„æ•°æ®æ€»é‡ï¼Œä¹Ÿé—´æ¥å½±å“äº†å†…éƒ¨çº¿ç¨‹æ•°å’Œæ¯ä¸ªçº¿ç¨‹çš„å·¥ä½œé‡ï¼Œåªä¸è¿‡è¿™äº›åº•å±‚ç»†èŠ‚ç”± Triton è‡ªåŠ¨å¤„ç†äº†ã€‚</li>
<li><code>BLOCK_SIZE = block_size Ã— sizePerThread = num_warps x threadsPerWarp Ã— sizePerThread</code></li>
</ul>
</li>
<li>å½“è¾“å…¥ä¸æ˜¯const, å¦‚ä½•ä¼ é€’tl.constexp? BLOCK_SIZE &#x3D; triton.next_power_of_2(n_cols)</li>
</ol>
<h2 id="é€‚é…-DSL"><a href="#é€‚é…-DSL" class="headerlink" title="é€‚é… DSL"></a>é€‚é… DSL</h2><ol>
<li>intel<br><img src="https://i.ibb.co/cF3yF0K/e-Hk7ps-HTk-M.png" alt="intel backend architecture"></li>
<li><a target="_blank" rel="noopener" href="https://github.com/intel/intel-xpu-backend-for-triton">intel-xpu-backend-for-triton</a></li>
<li>é«˜é€š<br><img src="https://i.ibb.co/6NMJ8Yk/xo5-Pqj-RPDT.png" alt="architecture"><br><img src="https://i.ibb.co/9VLhpNk/du-T6l-PNQfg.png" alt="pytorch"></li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=ONrKkI7KhU4&list=PLc_vA1r0qoiTjlrINKUuFrI8Ptoopm8Vz&index=18">Triton Conference 2024: Afternoon Session</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/microsoft/triton-shared">microsoft&#x2F;triton-shared</a></li>
<li><a target="_blank" rel="noopener" href="https://llvm.org/docs/TableGen/ProgRef.html">tablegen æ¥ç”Ÿæˆ MLIR ä»£ç </a></li>
</ol>
<h2 id="tensorå’Œçº¿ç¨‹layout"><a href="#tensorå’Œçº¿ç¨‹layout" class="headerlink" title="tensorå’Œçº¿ç¨‹layout"></a>tensorå’Œçº¿ç¨‹layout</h2><ol>
<li><p>è¦å®ç°å³°å€¼æ€§èƒ½ï¼Œä¸ä»…éœ€è¦åˆ©ç”¨ä¸“ç”¨ç¡¬ä»¶å•å…ƒï¼Œè¿˜éœ€è¦ç²¾å¿ƒè®¾è®¡å¼ é‡å¸ƒå±€å’Œè½¬æ¢, tensor layout and layout conversion</p>
</li>
<li><p>åœ¨ç¼–è¯‘è¿‡ç¨‹ä¸­ï¼ŒTriton çš„ Python ä»£ç é¦–å…ˆè¢«ç¿»è¯‘æˆ Triton æ–¹è¨€ ( tt )ï¼Œç„¶åå†ç¿»è¯‘æˆ TritonGPU æ–¹è¨€ ( ttg )ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªå¼ é‡éƒ½ä¸ç‰¹å®šçš„å¸ƒå±€ç›¸å…³è”ï¼Œä»¥å……åˆ†åˆ©ç”¨ç°ä»£ GPU ä¸Šå¯ç”¨çš„ç¡¬ä»¶åŠŸèƒ½å•å…ƒã€‚</p>
</li>
<li><p>layoutä¸ä»…é’ˆå¯¹load store, ä¸åŒçš„opæœ‰ä¸åŒçš„layoutåå¥½ï¼Œéœ€è¦è¿›è¡Œlayoutè½¬æ¢æ¥ä½¿ç”¨æœ€ä½³layout, æ­¤æ—¶ï¼Œéœ€è¦è¿›è¡Œæ•°æ®é‡æ’</p>
</li>
<li><p>loweringè¿‡ç¨‹ä¸ä»…éœ€è¦sizePerThreadä¿¡æ¯ï¼Œè¿˜éœ€è¦contiguityä¿¡æ¯ï¼Œ contiguityè¡¨æ˜é€»è¾‘å’Œç‰©ç†çš„æ˜ å°„è¿ç»­æ€§; </p>
<ul>
<li>æœ‰äº†threadè¦å¤„ç†çš„æ•°æ®å’Œæ•°æ®çš„è¿ç»­æ€§ä¿¡æ¯æ‰èƒ½lowering</li>
</ul>
</li>
<li><p>tensoråˆ’åˆ†çš„é¡ºåºä»å·¦åˆ°å³ï¼ŒsizePerThread -&gt; threadsPerWarp -&gt; warpsPerCTA â€¦; å¦‚æœå’Œtensor shapeä¸åŒ¹é…ï¼Œéœ€è¦å¹¿æ’­</p>
<ul>
<li>å·¦è¾¹æ˜¯æœ€é‡Œé¢çš„ç»´åº¦, æ˜¯ç§»åŠ¨æœ€å¿«çš„ç»´åº¦ã€‚</li>
</ul>
</li>
<li><p>åªæœ‰memoryç›¸å…³çš„æ“ä½œæ‰å…³å¿ƒsizePerThreadï¼›å…¶ä»–opåœ¨regä¸Šéƒ½æ˜¯è¿ç»­çš„   </p>
</li>
<li><p>sizePerThreadè¡¨æ˜ä¸€ä¸ªthreadä¸€æ¬¡å¯è¿ç»­å¤„ç†çš„æ•°æ®ï¼Œ elementPerThreadæ˜¯ä¸€ä¸ªthreadéœ€è¦å¤„ç†çš„æ•°ï¼Œ sizePerThreadç”±contiguityå’Œç¡¬ä»¶é™åˆ¶ç­‰å‚æ•°ç®—å‡ºï¼ŒsizePerThread[order[0]]ï¼Œåªä¼šï¼Œè®¾ç½®order[0]å¯¹åº”ç»´åº¦çš„sizePerThreadï¼Œå…¶ä»–ä¸º1</p>
<ul>
<li>å…·ä½“é€»è¾‘è§ lib&#x2F;Dialect&#x2F;TritonGPU&#x2F;Transforms&#x2F;Coalesce.cpp</li>
</ul>
</li>
<li><p>sizePerThread å’Œ elementPerThread æœ‰åŒºåˆ«ï¼ŒsizePerThreadæ ¹æ®contiguityç®—çš„ï¼ŒelementPerThreadæ˜¯ä¸€ä¸ªçº¿ç¨‹çœŸæ­£è¦ç®—çš„æ•°</p>
<ul>
<li>The legacy Triton layout system requires each layout to define its own interface methodsâ€”such as <code>the number of elements per thread</code> and <code>the number of contiguous elements</code></li>
</ul>
</li>
<li><p>sizePerThreadå¯¹åº”reg, threadsPerWarpå¯¹åº”thread, warpsPerCTAå¯¹åº”warp</p>
</li>
<li><p>sizePerThread &#x3D; [2, 2], threadsPerWarp &#x3D; [8, 4], warpsPerCTA &#x3D; [1, 2]. å› ä¸ºæ­¤æ—¶sizePerThread<em>threadsPerWarp</em>warpsPerCTA &#x3D; 16x16, å°äºtensorçš„shape 32x32, æ‰€ä»¥è¿™ä¸ª16x16çš„layoutä¼šæŒ‰ç…§[2, 2]çš„shapeè¿›è¡Œå¹¿æ’­, å¡«æ»¡æ•´ä¸ª32x32çš„tensor.</p>
</li>
<li><p><code>./triton-tensor-layout -l &quot;#triton_gpu.blocked&lt;&#123;sizePerThread = [1, 1], threadsPerWarp = [8, 4], warpsPerCTA = [2, 2], order = [1, 0]&#125;&gt;&quot; -t &quot;tensor&lt;16x8xf32&gt;&quot;</code></p>
</li>
<li><p>ConvertTritonToTritonGPU passåŠ çš„layoutä¿¡æ¯</p>
<ul>
<li>typeconverteré‡Œé‡æ–°æ„é€ äº†tensor typeï¼Œ åŠ äº†layoutä¿¡æ¯, æ£€æµ‹åˆ°æ˜¯tensor, å°±æ·»åŠ é»˜è®¤layoutä¿¡æ¯</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">  <span class="built_in">addConversion</span>([<span class="keyword">this</span>](RankedTensorType tensorType) -&gt; RankedTensorType &#123;</span><br><span class="line">  <span class="comment">// types with encoding are already in the right format</span></span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> check for layout encodings more specifically</span></span><br><span class="line">  <span class="keyword">if</span> (tensorType.<span class="built_in">getEncoding</span>())</span><br><span class="line">    <span class="keyword">return</span> tensorType;</span><br><span class="line">  ArrayRef&lt;<span class="type">int64_t</span>&gt; shape = tensorType.<span class="built_in">getShape</span>();</span><br><span class="line">  triton::gpu::BlockedEncodingAttr encoding =</span><br><span class="line">      <span class="built_in">getDefaultBlockedEncoding</span>(<span class="keyword">this</span>-&gt;context, shape, <span class="keyword">this</span>-&gt;numWarps,</span><br><span class="line">                                <span class="keyword">this</span>-&gt;threadsPerWarp, <span class="keyword">this</span>-&gt;numCTAs);</span><br><span class="line">  <span class="keyword">return</span> RankedTensorType::<span class="built_in">get</span>(shape, tensorType.<span class="built_in">getElementType</span>(), encoding);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></li>
<li><p><code>ptr+index &lt;-shape stride-&gt; coodinate &lt;-layout-&gt; thread id</code></p>
<ul>
<li>tensoræä¾›coodinateåˆ°index, valueçš„æ˜ å°„</li>
<li>layoutæä¾›coodinateåˆ°thread idæ˜ å°„, layout(coodinate) &#x3D; thread id</li>
</ul>
</li>
<li><p>ä¸åŒçš„Layoutå¯ä»¥çœ‹ä½œæ˜¯ä¸åŒçš„æ˜ å°„å‡½æ•°ï¼Œä»£è¡¨äº†ä¸åŒè®¿é—®æ¨¡å¼ã€‚</p>
</li>
<li><p>Layoutæ˜¯tensor coodinateåˆ°çº¿ç¨‹çš„æ˜ å°„ï¼Œwe define a layout as a function that maps a multi-dimensional tensor index to a set of integers T corresponding to the indices of the CUDA threads allowed to access some data at index i. <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/672720213">link</a></p>
<ul>
<li>coodinateåˆ°indexæ˜¯ç”±tensor axis infoå†³å®šçš„</li>
</ul>
</li>
<li><p>tritonä¹Ÿé€šè¿‡Layoutæ¥è¡¨å¾Threadå¯¹æ•°æ®(tensor)çš„è®¿é—®æ¨¡å¼ï¼Œä¾‹å¦‚blockedå’Œblocked1åˆ†åˆ«è¡¨ç¤ºA,Bä¸¤ä¸ªOperandçš„è®¿é—®æ¨¡å¼ï¼Œå³æ¯ä¸ªThreadå–è¿ç»­çš„8ä¸ªf16ç­‰ç­‰ã€‚</p>
<ul>
<li>tensor&lt;64x64x!tt.ptr<f32>, #blocked1&gt; æ—¢æœ‰tensor, ä¹Ÿæœ‰layout, data layout </li>
<li>AxisInfo ä¼šè®°å½•å¼ é‡å„è½´çš„å°ºå¯¸ã€æ­¥å¹…ä»¥åŠä¸ç¡¬ä»¶æ˜ å°„ç›¸å…³çš„ä¿¡æ¯ï¼Œç”¨äºæŒ‡å¯¼åç»­çš„å†…å­˜åˆå¹¶ï¼ˆcoalesceï¼‰å’Œå…¶å®ƒä¼˜åŒ–æ“ä½œï¼Œâ€œAxisInfoâ€å¹¶ä¸æ˜¯å­˜å‚¨å¼ é‡æ‰€æœ‰ä¿¡æ¯çš„å®¹å™¨ï¼Œå®ƒä¸»è¦å…³æ³¨é‚£äº›å¯¹é«˜æ•ˆå†…å­˜è®¿å­˜è‡³å…³é‡è¦çš„è½´ä¿¡æ¯ï¼ˆä¾‹å¦‚å„è½´çš„å¤§å°ã€æ­¥å¹…ã€æ’åˆ—é¡ºåºç­‰ï¼‰ï¼Œè€Œå®Œæ•´çš„å¼ é‡ä¿¡æ¯è¿˜å¯èƒ½åˆ†å¸ƒåœ¨å…¶ä»– IR å±æ€§æˆ–æ•°æ®ç»“æ„ä¸­ã€‚å› æ­¤ï¼Œå¯ä»¥è¯´ï¼ŒTriton çš„ AxisInfo åˆ†ææå–å¹¶è¡¨è¾¾äº†å¼ é‡ä¸­ä¸è®¿å­˜å’Œå¹¶è¡Œè°ƒåº¦å¯†åˆ‡ç›¸å…³çš„é‚£éƒ¨åˆ†ä¿¡æ¯ã€‚</li>
</ul>
</li>
<li><p>data layout æ˜¯ TritonGPU Dialect çš„ Type system çš„å…³é”®ï¼Œç¡®å®šäº† Data(å„å±‚çº§memoryä¸­çš„Tensor) åˆ° thread ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚</p>
</li>
<li><p>æ€»çš„æ¥è¯´ tensor ä¸ºæ•°æ®åœ¨å†…å­˜ä¸­çš„ç‰©ç†ç»„ç»‡æä¾›é™æ€æè¿°ï¼Œè€Œlayout åˆ™é€šè¿‡è¿è¡Œæ—¶ç´¢å¼•å†³å®šæ¯ä¸ªçº¿ç¨‹åº”å¤„ç†æ•°æ®ä¸­çš„å“ªä¸€éƒ¨åˆ†ã€‚ä¸¤è€…å¿…é¡»é…åˆï¼Œæ‰èƒ½è®©æ¯ä¸ªæ‰§è¡Œå•å…ƒæ­£ç¡®ä¸”é«˜æ•ˆåœ°è¯»å–ã€å¤„ç†å’Œå†™å›æ•°æ®ï¼Œä»è€Œå……åˆ†å‘æŒ¥ GPU çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›</p>
</li>
<li><p>nvidia åœ¨ttgirç”Ÿæˆålayoutç›¸å…³ä¼˜åŒ–å·²ç»åšå®Œäº†ï¼Œloweringåˆ°llvm iræ ¹æ®ttgir æ–¹æ¡ˆæ¥ï¼Œä¸ä¼šå†åšlayoutçš„ä¼˜åŒ–</p>
</li>
<li><p>ttgiré‡Œå·²ç»æœ‰æ¯ä¸ªthreadè¦ç®—æ•°æ®çš„æ‰€æœ‰ä¿¡æ¯</p>
<ul>
<li>å¯ä»¥åˆ é™¤compiler.pyé™¤äº†add_convert_to_ttgpuir passä¹‹å¤–çš„passçœ‹çœ‹ç»“æœæ­£ç¡®æ€§å’Œir</li>
</ul>
</li>
<li><p>loadä¹‹åæ•°æ®åœ¨regä¸Š, åé¢çš„æ•°æ®ä¸ç”¨å…³å¿ƒcontigutyå’Œsize_per_thread; åªç”¨çœ‹shape</p>
<ul>
<li>åªæœ‰loadå’Œstoreè€ƒè™‘è¿ç»­æ€§çš„é—®é¢˜ï¼Œåé¢çš„è®¡ç®—opä¸éœ€è¦è€ƒè™‘ï¼Œå·²ç»åŠ è½½åˆ°regä¸Šäº†</li>
</ul>
</li>
<li><p>coalesce passé‡Œä¼šåˆ†æcontinutyç­‰ä¿¡æ¯æ¥ç¡®è®¤ä¸€æ¬¡loadå’Œstoreå¤šå°‘æ•°æ®,æ”¹å˜load store layoutå¹¶æ·»åŠ conver layout op   </p>
</li>
<li><p>coalesceæ·»åŠ æ–°çš„layoutå¹¶æ·»åŠ convert_layout; remove_layoutè´Ÿè´£layoutçš„ä¼ æ’­å’Œåˆ é™¤</p>
</li>
</ol>
<h3 id="linear-layout"><a href="#linear-layout" class="headerlink" title="linear layout"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.23819">linear layout</a></h3><ol>
<li>æ³¨æ„ linear layoutè¡¨ç¤ºçš„æ˜¯è¾“å‡ºåˆ°è¾“å…¥çš„ç´¢å¼•ï¼Œç»™å®šè¾“å‡ºindexï¼Œç»è¿‡linear mapå·¦ä¹˜ï¼Œå¾—åˆ°è¾“å…¥indexï¼› Vin &#x3D; T@Vout</li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/PDFshzgcj_udaFu3aJr1tQ">è¯¦ç»†ä»‹ç»</a><ul>
<li>å¤åˆ Composition è®²çš„æ¯”è¾ƒå¥½</li>
</ul>
</li>
<li>linear layoutå¯ä»¥è¡¨ç¤ºå¤šç§å«ä¹‰ï¼š<ul>
<li>ä½œä¸ºtonsorå±æ€§ï¼šç¡¬ä»¶ä½ç½®å’Œtensor é€»è¾‘indexæ˜ å°„</li>
<li>ä½œä¸ºopçš„å±æ€§ï¼štensor é€»è¾‘indexä¹‹é—´çš„æ˜ å°„</li>
<li>ä¸¤ä¸ªtensorå’Œä¸€ä¸ªconvert_layout op; convert_layout opä¸å¸¦å±æ€§<ul>
<li>ç›´æ¥ä½¿ç”¨linear ç»„åˆåŠŸèƒ½</li>
</ul>
</li>
<li>ä¸¤ä¸ªtensorå’Œä¸€ä¸ªopï¼Œéƒ½å¸¦linear layoutå±æ€§ï¼š<ul>
<li>æ¯”ä¸¤ä¸ªtensorä¹‹é—´è½¬æ¢å¤šåŠ äº†é€»è¾‘ä¹‹é—´çš„è½¬æ¢</li>
<li>ç»“åˆèµ·æ¥å¯ä»¥å¾—åˆ°ç¡¬ä»¶ä½ç½®ä¹‹é—´çš„æ˜ å°„; ç¡¬ä»¶æŒ‡ä»¤åŠŸèƒ½ä¹Ÿç”¨linear layoutè¡¨ç¤ºï¼Œé€šè¿‡ç»„åˆæ¥Lowering</li>
</ul>
</li>
</ul>
</li>
<li><code>https://github.com/triton-lang/triton/blob/main/include/triton/Tools/LinearLayout.h</code> å®˜æ–¹è¯´æ˜</li>
<li><code>In Triton, a linear layout (LL) is a function that maps from a &quot;hardware location&quot; to a &quot;logical tensor index&quot;.</code></li>
<li><code>To summarize, a linear layout is a function from tuples of integers to tuples of integers.  We specify some key values of the function, and then we can compute all the other values using the linearity rule.</code></li>
<li>æ˜¯ä¸€ç§æ˜ å°„:<code>ç¡¬ä»¶ç´¢å¼• -&gt; tensor åæ ‡ç´¢å¼•</code>; æŸ¥æ‰¾è¡¨ï¼Œlinear layoutæ˜¯æŸ¥æ‰¾è¡¨çš„ä¸€ç§å‹ç¼©<ul>
<li>tensoråæ ‡åˆ°å­˜å‚¨tensor memoryçš„indexå¹¶ä¸ä»linear layoutæ¥è·å–</li>
</ul>
</li>
<li>åªè¦ç»™ç¡¬ä»¶ä½ç½®basic vectorå¯¹åº”çš„è¾“å‡ºtensor index(coodinatate)ï¼Œå°±å¯ä»¥ç®—å‡º linear mapï¼Ÿ<ul>
<li>ä»ç¡¬ä»¶è¾“å…¥ç»´åº¦å’Œtensor indexå¯ä»¥çœ‹å‡ºè¾“å…¥è¾“å‡ºç»´åº¦</li>
<li>ç±»ä¼¼çº¿æ€§æ–¹ç¨‹ç»„ï¼Œç»™å®šå‡ ä¸ªè¾“å…¥è¾“å‡ºï¼Œå¯ä»¥å¾—åˆ°çº¿æ€§æ–¹ç¨‹ç»„çš„å‚æ•°</li>
</ul>
</li>
<li>å¯¹äº tensor layoutï¼Œæˆ‘ä»¬é€šå¸¸ä¼šé—®ä¸€ä¸ªé—®é¢˜ï¼šæŸä¸ªçº¿ç¨‹ indexï¼ˆä¾‹å¦‚ [lane_x, warp_y, thread_z]ï¼‰è´Ÿè´£è®¿é—®å¼ é‡ä¸­çš„å“ªä¸ª [i, j, k] å…ƒç´ ï¼Ÿ<ul>
<li>ä½œè€…çš„å…³é”®æƒ³æ³•æ˜¯ï¼šè¿™ç§æ˜ å°„å¯ä»¥å†™æˆä¸€ä¸ªçº¿æ€§æ˜ å°„ï¼š[i, j, k]^T &#x3D; M Ã— [lane_x, warp_y, thread_z]^T   ï¼ˆæ¨¡ 2 è¿ç®—ï¼‰å…¶ä¸­ M æ˜¯ä¸€ä¸ª ğ”½â‚‚ ä¸Šçš„çŸ©é˜µï¼Œå½¢çŠ¶ä¸º [å¼ é‡ç»´åº¦ Ã— ç¡¬ä»¶ç»´åº¦]</li>
</ul>
</li>
<li>çŸ©é˜µlayout M å°±å®šä¹‰äº†â€œçº¿ç¨‹ index åˆ° tensor indexâ€ä¹‹é—´çš„å¸ƒå±€æ˜ å°„ã€‚<ul>
<li>Mæ²¡ä»€ä¹ˆå«ä¹‰ï¼Œå°±æ˜¯çº¿æ€§æ–¹ç¨‹ç»„å‚æ•°ï¼Œæ˜¯ä¸€ç§æ˜ å°„projection;</li>
<li>Mçš„è¡Œåˆ—é•¿åº¦éœ€è¦å’Œç¡¬ä»¶çš„[reg, thread, warp]ä¸tensorçš„[i, j, k]äºŒè¿›åˆ¶ä½æ•°åŒ¹é…ä¸Š</li>
</ul>
</li>
<li>linear layoutæ˜¯ä¸€ç§è¡¨ç¤ºï¼šè¡¨æ˜tensor å¼ é‡å…ƒç´ åˆ†å¸ƒå¹¶æ˜ å°„åˆ°è®¡ç®—å’Œå†…å­˜å±‚æ¬¡ç»“æ„ï¼›ä¸åŒçš„linear layoutè¡¨æ˜tensorçš„æ˜ å°„ä¸åŒã€‚æ˜ å°„å…³ç³»å¯ä»¥é€šè¿‡linear mapæ¥è¡¨ç¤ºï¼›ä¸¤ä¸ªlinear layoutè½¬æ¢ä¹Ÿå¯ä»¥é€šè¿‡linear mapæ¥è½¬æ¢ã€‚   </li>
<li>linear layout: <code>x = M * p</code>; Mæ˜¯äºŒè¿›åˆ¶çŸ©é˜µï¼Œpæ˜¯ç¡¬ä»¶äºŒè¿›åˆ¶ç¼–ç å‘é‡ï¼Œxæ˜¯å¯¹åº”çš„tenosr åæ ‡ï¼Œxç®—å‡ºæ¥æ˜¯ä¸€åˆ—ï¼Œå‰å‡ ä½è¡¨ç¤ºj, åå‡ ä½è¡¨ç¤ºi<ul>
<li>linearçš„æ„æ€åº”è¯¥æ˜¯é€šè¿‡çº¿æ€§è¿ç®—å°±èƒ½åšlayoutæ˜ å°„å’Œè½¬æ¢</li>
<li><code>T_index = A * HW_index^T</code></li>
</ul>
</li>
<li>linear layoutæ˜¯ä»ç¡¬ä»¶å¯„å­˜å™¨æ‰¾tensor é€»è¾‘index, <code>ä¸€ä¸ªregåªå¯¹åº”ä¸€ä¸ªé€»è¾‘index, ä¹‹å‰çš„layoutæ˜¯ä»tensor é€»è¾‘åœ°å€æ‰¾ç¡¬ä»¶å¯„å­˜å™¨ï¼›ä¸€ä¸ªé€»è¾‘indexå¯ä»¥å¯¹åº”å¤šä¸ªç¡¬ä»¶reg</code>, è¾“å…¥æ˜¯ç¡¬ä»¶ä½ç½®äºŒè¿›åˆ¶ç¼–ç ï¼Œè¾“å‡ºæ˜¯tensor é€»è¾‘åæ ‡ã€‚<ul>
<li>ä½¿ç”¨layout äºŒè¿›åˆ¶çŸ©é˜µæ¥è¿›è¡Œlayoutæ¥è®¡ç®—</li>
</ul>
</li>
<li>linear layoutå’Œlinear mapæ˜¯æœ‰åŒºåˆ«çš„ï¼Œlinear mapå¯ä»¥å°†ä¸€ç§layoutè½¬åŒ–ä¸ºå¦ä¸€ç§</li>
<li>linear layoutæ°¸è¿œæ˜¯äºŒç»´çš„ï¼Œè¾“å…¥è¾“å‡ºå¯ä»¥æ˜¯å„ç§ç»´åº¦ï¼šè¾“å…¥æ˜¯ä¸‰ç»´ï¼Œä¼šå˜æˆä¸€ç»´ï¼Œå¦‚i, j, k, shapeæ˜¯ï¼ˆ2ï¼Œ 4ï¼Œ 8ï¼‰ï¼Œ åˆ†åˆ«ç”¨1ï¼Œ 2ï¼Œ3bitè¡¨ç¤ºï¼Œé‚£ä¹ˆè¾“å…¥å°±æ˜¯6bitçš„ä¸€ç»´å‘é‡ï¼Œè¡¨ç¤ºçš„èŒƒå›´ä¸º2<em>4</em>8 &#x3D; 2çš„6æ¬¡æ–¹ &#x3D; 64ï¼›è¾“å‡ºä¹Ÿä¸€æ ·<ul>
<li>è¾“å…¥æ˜¯è¡Œï¼Œè¾“å‡ºæ˜¯åˆ—</li>
</ul>
</li>
<li>linear layoutçš„base vector,åŸºå‘é‡<ul>
<li>è¡¨ç¤ºlabelæ‰€åœ¨åˆ—ä¸º1å¯¹åº”çš„bitä½æ‰€åœ¨è¡Œå·çš„2çš„æŒ‡æ•°ç»“æœï¼Œä»0å¼€å§‹ï¼›å¦‚ä¸‹é¢warp&#x3D;2 -&gt; (8),æœ€åä¸€åˆ—ä¸º1çš„è¡Œå·æ˜¯3ï¼Œ 2çš„3æ¬¡æ–¹ä¸º8</li>
<li>obè¡¨ç¤ºäºŒè¿›åˆ¶</li>
<li>è¾“å‡ºç»´åº¦ä¸º1ï¼Œdim0ä¸º2çš„4æ¬¡æ–¹16 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">   shape: [16]</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">ttg.blocked&lt;&#123;sizePerThread = [1], threadsPerWarp = [4], warpsPerCTA = [4], order = [0]&#125;&gt;</span></span><br><span class="line">RepOrder: [0]</span><br><span class="line">TotalElemsPerThread: 1</span><br><span class="line">ElemsPerThread: [1]</span><br><span class="line">- register is a size 1 dimension</span><br><span class="line">- lane=1 -&gt; (1)</span><br><span class="line">  lane=2 -&gt; (2)</span><br><span class="line">- warp=1 -&gt; (4)</span><br><span class="line">  warp=2 -&gt; (8)</span><br><span class="line">- block is a size 1 dimension</span><br><span class="line">where out dims are: [dim0 (size 16)]</span><br><span class="line">0b1000</span><br><span class="line">0b0100</span><br><span class="line">0b0010</span><br><span class="line">0b0001</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>äºŒç»´<ul>
<li>è¾“å‡ºæ˜¯äºŒç»´çš„ï¼Œå‰6bitè¡¨ç¤ºç¬¬ä¸€ç»´ï¼Œå7bitè¡¨ç¤ºç¬¬äºŒç»´ï¼Œregister&#x3D;1 -&gt; (1, 0) è¡¨ç¤ºç¬¬ä¸€ç»´çš„ç¬¬ä¸€åˆ—çš„ç¬¬ä¸€ä½ä¸º1ï¼› register&#x3D;8 -&gt; (0, 16)è¡¨ç¤ºç¬¬4åˆ—çš„ç¬¬äºŒç»´çš„ç¬¬5ä½ä¸º1, è¡¨æ˜ç¬¬å››ä¸ªregçš„ä½ç½®å†³å®šäº†ç¬¬äºŒç»´ç¬¬5ä½çš„å€¼<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">shape: [64, 128]</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">ttg.blocked&lt;&#123;sizePerThread = [8, 1], threadsPerWarp = [8, 4], warpsPerCTA = [1, 4], order = [0, 1], CTAsPerCGA = [1, 2], CTASplitNum = [1, 2], CTAOrder = [1, 0]&#125;&gt;</span></span><br><span class="line">th 4 * 4 = 16 -&gt; 64</span><br><span class="line">RepOrder: [0, 1]</span><br><span class="line">TotalElemsPerThread: 32</span><br><span class="line">ElemsPerThread: [8, 4]</span><br><span class="line">- register=1 -&gt; (1, 0) </span><br><span class="line">  register=2 -&gt; (2, 0)</span><br><span class="line">  register=4 -&gt; (4, 0)</span><br><span class="line">  register=8 -&gt; (0, 16)</span><br><span class="line">  register=16 -&gt; (0, 32)</span><br><span class="line">- lane=1 -&gt; (8, 0)</span><br><span class="line">  lane=2 -&gt; (16, 0)</span><br><span class="line">  lane=4 -&gt; (32, 0)</span><br><span class="line">  lane=8 -&gt; (0, 1)</span><br><span class="line">  lane=16 -&gt; (0, 2)</span><br><span class="line">- warp=1 -&gt; (0, 4)</span><br><span class="line">  warp=2 -&gt; (0, 8)</span><br><span class="line">- block=1 -&gt; (0, 64)</span><br><span class="line">where out dims are: [dim0 (size 64 b6), dim1 (size 128 b7)]</span><br><span class="line">0b1000000000000</span><br><span class="line">0b0100000000000</span><br><span class="line">0b0010000000000</span><br><span class="line">0b0000010000000</span><br><span class="line">0b0000001000000</span><br><span class="line">0b0000000100000</span><br><span class="line">0b0000000010000</span><br><span class="line">0b0000000001000</span><br><span class="line">0b0000000000100</span><br><span class="line">0b0000000000010</span><br><span class="line">0b0001000000000</span><br><span class="line">0b0000100000000</span><br><span class="line">0b0000000000001</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>linear layoutæŸä¸€åˆ—å¯ä»¥ä¸ºå…¨0ï¼Œå¦‚warp2ä¸º0ï¼Œè¡¨æ˜æ²¡æœ‰ç”¨å®Œwarp</li>
<li>linear layoutçš„è¡Œåˆ—çš„bitæ•°è¡¨æ˜æœ‰è¾“å…¥è¾“å‡ºæœ‰å¤šå°‘ç§æƒ…å†µï¼Œç”¨ä¸€ä¸ªçŸ©é˜µå¯ä»¥è¡¨æ˜è¾“å…¥å’Œè¾“å‡ºçš„å„ç§ç»„åˆ</li>
<li><code>include/triton/Tools/LinearLayout.h</code>æœ‰è¯´æ˜</li>
<li><code>unittest/Tools/LinearLayoutTest.cpp</code> æœ‰æµ‹è¯•<ul>
<li><code>./unittest/Tools/LinearLayout  --gtest_filter=LinearLayoutTest.Empty</code></li>
<li>linear layout base vector &#x3D; 0, è¡¨ç¤ºrepeat; å½“å‰åˆ—å†³å®šä¸äº†è¾“å‡ºï¼Œæ‰€ä»¥ä¼šå’Œå…¶ä»–è¾“å…¥çš„ç»“æœé‡å¤</li>
<li>è¾“å…¥è¾“å‡ºå¯ä»¥å…ˆå°†bitä¸ªæ•°è½¬æˆshape, bitä½ä¸æ˜¯å¾ˆç†Ÿæ‚‰</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://github.com/triton-lang/triton/blob/main/unittest/Dialect/TritonGPU/LinearLayoutConversionsTest.cpp">LinearLayoutConversionsTest</a><ul>
<li>Linear Layout	æ‰€æœ‰å¼ é‡å…ƒç´ åœ¨å†…å­˜ä¸­æŒ‰ä¸€ç»´çº¿æ€§æ’åˆ—</li>
<li><code>unittest/Dialect/TritonGPU/LinearLayoutConversions --gtest_filter=LinearLayoutConversionsTest.ShapeLargerThanLayout</code></li>
</ul>
</li>
<li>Every tensor layout is modeled as a linear functionâ€”a matrixâ€”that maps physical resource indices into a logical tensor of size n2 using binary arithmetic on the bits of the input and the output.<ul>
<li>æ¯ä¸ªå¼ é‡å¸ƒå±€éƒ½è¢«å»ºæ¨¡ä¸ºä¸€ä¸ªçº¿æ€§å‡½æ•°ï¼ˆçŸ©é˜µï¼‰ï¼Œå®ƒä½¿ç”¨å¯¹è¾“å…¥å’Œè¾“å‡ºä½çš„äºŒè¿›åˆ¶ç®—æœ¯å°†ç‰©ç†èµ„æºç´¢å¼•æ˜ å°„åˆ°å¤§å°ä¸ºnæ–¹çš„é€»è¾‘å¼ é‡ã€‚</li>
<li>çŸ©é˜µæ˜¯ä¸€ä¸ªæ˜ å°„ï¼Œ å°†ç‰©ç†èµ„æºæ˜ å°„ä¸ºé€»è¾‘å¼ é‡çš„ç´¢å¼•</li>
</ul>
</li>
<li>We define a Linear Layout as a linear map between (labeled) vector spaces over F2<ul>
<li>For example, we can define layout L as:â€ƒâ€ƒL : Reg Ã— Thr Ã— Wrp â†’ ğ”½â‚‚â¿ Ã— ğ”½â‚‚áµ (n, mæ˜¯åæ ‡shapeçš„äºŒè¿›åˆ¶é•¿åº¦, å¦‚16x32, n&#x3D;4, m&#x3D;5)</li>
</ul>
</li>
<li>ä½¿ç”¨linear layoutå¸ƒå±€çš„ä¼ æ’­å°±æ¯”è¾ƒå¥½å®ç°ï¼Œç›´æ¥ä½¿ç”¨ç»„åˆä»ä¸€ç§layoutåˆ°å¦ä¸€ç§layout</li>
<li>linear layoutå·¥å…·<ul>
<li>çŸ¢é‡åŒ–ï¼šä¸ç”¨å†æ‰‹åŠ¨ç®—Contiguous elementsç­‰ä¿¡æ¯ï¼Œæ ¹æ®Læ¥ç®—</li>
<li>Broadcasting: æ•°æ®å°äºçº¿ç¨‹ï¼Œå¤šä¸ªçº¿ç¨‹ç®—ä¸€ä¸ªæ•°æ®ï¼Œæ•°æ®å¤šä½™çº¿ç¨‹ï¼Œä¸€ä¸ªçº¿ç¨‹ç®—å¤šä¸ªæ•°æ®ï¼Œéœ€è¦å¹¿æ’­ã€‚ä¹‹å‰çš„layoutå¾ˆéš¾å¤„ç†ï¼›linear layoutåªè¦æŒ‰éœ€æ”¹LçŸ©é˜µ</li>
</ul>
</li>
<li>Linear Layouts ä½œä¸ºç¼–è¯‘å™¨çš„ä¸€éƒ¨åˆ†ï¼Œå®ç°äº†å¸ƒå±€æ¨ç†ï¼ˆinferenceï¼‰ã€å¸ƒå±€è½¬æ¢ï¼ˆconversionï¼‰ä»¥åŠä»£ç ç”Ÿæˆï¼ˆcodegenï¼‰çš„ä¸€ä½“åŒ–æµç¨‹ã€‚é€šè¿‡çŸ©é˜µæ“ä½œï¼Œç¼–è¯‘å™¨èƒ½å¤Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å¸ƒå±€ã€æ’å…¥è½¬æ¢å¹¶è°ƒåº¦ç¡¬ä»¶æŒ‡ä»¤ï¼Œè€Œä¸å†ä¾èµ–ç¹æ‚çš„ä¸“é—¨ä»£ç æˆ–æ‰‹å·¥ä¼˜åŒ–</li>
<li>Triton Linear Layout æ˜¯ ç¼–è¯‘å™¨ä¸­ç«¯ä¼˜åŒ–é˜¶æ®µçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œä¸“æ³¨äºè§£å†³å¼ é‡å¸ƒå±€çš„ç¡¬ä»¶æ˜ å°„ä¸è½¬æ¢é—®é¢˜ã€‚å…¶é€šè¿‡ä»£æ•°å»ºæ¨¡ç»Ÿä¸€äº† NVIDIA&#x2F;AMD ç­‰ç¡¬ä»¶çš„å¸ƒå±€è§„åˆ™ï¼Œæ˜¾è‘—é™ä½ç¼–è¯‘å™¨å¼€å‘å¤æ‚æ€§å’Œé”™è¯¯ç‡ï¼Œå¹¶ä¸ºé«˜æ€§èƒ½ç®—å­ï¼ˆå¦‚ GEMMï¼‰æä¾›æ¥è¿‘ç¡¬ä»¶çš„å³°å€¼æ€§èƒ½ã€‚</li>
<li>ä¹‹å‰çš„åšæ³•æ˜¯ä¸ºæ¯ç§ layoutï¼ˆblocked, swizzled, pitch-linear, tiled ç­‰ï¼‰ç¡¬ç¼–ç æ˜ å°„é€»è¾‘ï¼Œå¾ˆå®¹æ˜“é€ æˆä»£ç é‡å¤ã€ä¸å¯ç»„åˆã€ç»´æŠ¤éš¾ã€‚   </li>
<li>èƒ½çœ‹åˆ° layout Ã— thread çš„è¿‡ç¨‹å—ï¼Ÿå¯ä» Triton IR æˆ– TTGIR ä¸­çœ‹åˆ°åœ°å€åç§»è®¡ç®—æŒ‡ä»¤ï¼Œå« mul, add, bitwise ç­‰<ul>
<li>ttgirçš„layoutï¼ˆä¹‹å‰block) å¯ä»¥ç¡®è®¤æ¯ä¸ªçº¿ç¨‹è®¡ç®—çš„æ•°æ®ï¼Œ linear layoutä¹Ÿå¯ä»¥</li>
</ul>
</li>
<li>åŒä¸€ä¸ªæ•°æ®ï¼Œå…¶å®é¢å¯¹ä¸¤ä¸ªæ ‡å·ï¼š<code>ç©ºé—´é€»è¾‘ä½ç½®å’Œthreadçš„å…¨å±€æ ‡å·</code>ï¼Œlayoutåˆ™æ˜¯å»ºç«‹äºŒè€…ä¹‹é—´çš„æ˜ å°„å…³ç³»ï¼Œè¿™æ ·ç¼–ç¨‹çš„æ—¶å€™å°±çŸ¥é“å½“å‰çš„threadåº”è¯¥æ“ä½œå“ªä¸ªæ•°æ®ï¼Œè¿›è€Œæ¨å¹¿åˆ°å½“å‰çš„ä¸€ç°‡threadï¼ˆæ¯”å¦‚ä¸€ä¸ªwarpï¼Œä¸€ä¸ªwarp groupï¼‰åº”è¯¥æ“ä½œå“ªä¸€ä¸ªé›†åˆå†…çš„æ•°æ®<ul>
<li>æ¯ä¸ªthreadç”±äºæ‰€å¤„çš„warpï¼Œclusterï¼Œblockä¸åŒï¼Œä¹Ÿæœ‰è‡ªå·±å”¯ä¸€çš„å…¨å±€æ ‡å·&lt;block_id, warp_id, lane_id&gt;</li>
</ul>
</li>
<li>é˜¶æ®µ	               ä¼ ç»Ÿæ–¹æ¡ˆ     	Linear Layout æ–¹æ¡ˆ<ul>
<li>å‰ç«¯ â†’ TTGIR      ç¡¬ç¼–ç å¸ƒå±€å£°æ˜	å¸ƒå±€å®šä¹‰ä¸º F2 çŸ©é˜µ</li>
<li>å¸ƒå±€è½¬æ¢	       æ‰‹å·¥ç¼–å†™è½¬æ¢è§„åˆ™	çŸ©é˜µä¹˜æ³•ï¼ˆA * B^{-1}ï¼‰</li>
<li>åç«¯ä»£ç ç”Ÿæˆ	   é€šç”¨å…±äº«å†…å­˜é‡æ’	æ˜ å°„è‡³ç¡¬ä»¶åŸè¯­ï¼ˆå¦‚ ldmatrixï¼‰</li>
</ul>
</li>
<li>å¦‚æœä½ æœ‰ä¸€ä¸ªå¼ é‡ A[i,j,k]ï¼Œåˆ†é…åˆ° thread blockã€warpã€lane çš„é¡ºåºæ˜¯é”™ç»¼å¤æ‚çš„ï¼Œä¼ ç»Ÿåšæ³•éœ€è¦æ‰‹å†™æ˜ å°„å‡½æ•°ã€‚ç°åœ¨ï¼Œåªéœ€ç”¨ä¸€ä¸ªäºŒè¿›åˆ¶çŸ©é˜µ M_layoutï¼Œä½ å°±èƒ½è¡¨è¾¾è¿™ç§ä» hardware index â†’ tensor index çš„æ˜ å°„ï¼š<ul>
<li>tensor_index &#x3D; M_layout Ã— hardware_indexï¼ˆmod 2</li>
</ul>
</li>
<li>ttgirç”Ÿæˆçš„blocked mma ç­‰ layout å¯ä»¥tolinear_layoutç„¶åå†ä½¿ç”¨ï¼Œæ ¹æ®è‡ªå·±ç¡¬ä»¶çš„ç‰¹æ€§å¯ä»¥å¯¹to linear layoutåšhack</li>
<li>Tritonâ€™s operations fall into four categories: (1) computation, (2) memory (global, shared, tensor, etc.), (3) layout conversion, and (4) shape operations.<ul>
<li>Triton çš„æ“ä½œåˆ†ä¸ºå››ç±»ï¼š(1) è®¡ç®—ï¼Œ(2) å†…å­˜ï¼ˆå…¨å±€ã€å…±äº«ã€å¼ é‡ç­‰ï¼‰ï¼Œ(3) å¸ƒå±€è½¬æ¢ï¼Œä»¥åŠ (4) å½¢çŠ¶æ“ä½œã€‚</li>
</ul>
</li>
</ol>
<h4 id="ä»linear-layoutè·å–æ¯ä¸ªthreadè¦å¤„ç†çš„æ•°æ®"><a href="#ä»linear-layoutè·å–æ¯ä¸ªthreadè¦å¤„ç†çš„æ•°æ®" class="headerlink" title="ä»linear layoutè·å–æ¯ä¸ªthreadè¦å¤„ç†çš„æ•°æ®"></a>ä»linear layoutè·å–æ¯ä¸ªthreadè¦å¤„ç†çš„æ•°æ®</h4><ol>
<li>LinearLayout::apply()å‡½æ•°æ¥æ”¶ç¡¬ä»¶äºŒè¿›åˆ¶indicesï¼Œè¾“å‡ºtensor indexï¼›è¾“å…¥åªæ˜¯å¸¸é‡ï¼Œæ˜¯int32</li>
<li>SmallVector&lt;std::pair&lt;StringAttr, Value&gt;&gt; applyLinearLayoutï¼Œ è¾“å…¥è¾“å‡ºéƒ½æ˜¯å˜é‡ï¼Œæ˜¯value<ul>
<li>è¾“å‡ºæœ‰label + valueç»„æˆï¼Œå‡ ç»´çš„è¾“å‡ºç»“æœçš„sizeå°±æ˜¯å‡ </li>
</ul>
</li>
</ol>
<h3 id="convert-layout"><a href="#convert-layout" class="headerlink" title="convert_layout"></a><a target="_blank" rel="noopener" href="https://superjomn.github.io/posts/triton-mlir-publish/#convertlayoutop">convert_layout</a></h3><ol>
<li>convert_layoutï¼š %out &#x3D; convert_layout %in: tensor&lt;128x128xf32, #layoutA&gt; -&gt; tensor&lt;128x128xf32, #layoutB&gt; ç”¨çº¿ç¨‹å»è¯»å– layoutA ä¸‹çš„æ•°æ®ï¼Œç„¶åå†™å…¥ layoutB å¯¹åº”çš„ä½ç½®ã€‚<ul>
<li>ç¼–è¯‘å™¨ä¼šè‡ªåŠ¨ç”Ÿæˆä¸€å¥—æ•°æ®æ¬è¿é€»è¾‘ï¼ˆé€šå¸¸æ˜¯å¤šä¸ªçº¿ç¨‹åä½œ copyï¼‰ï¼Œå®ç°è¿™ä¸ªè½¬æ¢ã€‚</li>
</ul>
</li>
<li>convert_layout çš„æœ¬è´¨æ˜¯ï¼šé‡æ–°å®‰æ’ tensor æ•°æ®åœ¨å†…å­˜ä¸­çš„æ’åˆ—é¡ºåºï¼Œä»¥ä¾¿é€‚é…ä¸åŒçš„çº¿ç¨‹è®¿é—®æ¨¡å¼æˆ–ç¡¬ä»¶ç‰¹æ€§ã€‚<ul>
<li>convert_layout çš„ç›®çš„ï¼šåœ¨è®¡ç®—æˆ–æ¬è¿ä¹‹å‰ï¼ŒæŠŠæ•°æ®å¸ƒå±€å˜æ¢æˆ é€‚åˆå½“å‰çº¿ç¨‹è®¿é—®æ–¹å¼ çš„å½¢å¼ã€‚</li>
<li>ä¸æ˜¯ç›´æ¥åœ¨ global memory ä¸Šé‡æ’ï¼Œè€Œæ˜¯ï¼š æ¯ä¸ª thread ä» global memory æŒ‰åŸ layout è¯»å–æ•°æ®åˆ°è‡ªå·±çš„å¯„å­˜å™¨ï¼Œ ç„¶åæ ¹æ®ç›®æ ‡ layout çš„è§„åˆ™ï¼Œé€šè¿‡ thread ä¹‹é—´çš„ shuffleã€store ç­‰æ“ä½œï¼Œå°†æ•°æ®æ¬è¿æˆæ–°å¸ƒå±€</li>
<li><a target="_blank" rel="noopener" href="https://chatgpt.com/share/68819589-cd78-8004-864f-95b3b46e7577">gpt</a></li>
<li>loadä¹‹åçš„blocked layoutæ˜¯åœ¨å¯„å­˜å™¨ä¸Š</li>
<li>#blocked -&gt; #shared ï¼Œä»£è¡¨æ•°æ®ä» register file å­˜å‚¨åˆ° shared memory ä¸­ï¼Œ</li>
<li>#blocked -&gt; #blocked1 ï¼Œä»£è¡¨æ•°æ®ä» register file å­˜å‚¨åˆ°register file ä¸­ï¼Œthreadå†…éƒ¨åªéœ€è¦æ”¹å˜é¡ºåºï¼Œthreadé—´å¯èƒ½éœ€è¦shared memoryå¤„ç†</li>
<li>#mma -&gt; #blocked ï¼Œæ­£å¸¸æ˜¯ DotOp çš„è¾“å‡ºè½¬æ¢ä¸ºæ›´ç®€å•çš„ layout æ¥è¿›ä¸€æ­¥è®¡ç®—ï¼Œç”±äºæ¶‰åŠåˆ°è·¨ thread é—´çš„æ•°æ®ä¼ é€’ï¼Œå› æ­¤ä¸€èˆ¬ä¼šå€Ÿç”± shared memory ä¸­è½¬ä¸€æ¬¡</li>
</ul>
</li>
</ol>
<h2 id="axis-info"><a href="#axis-info" class="headerlink" title="axis info"></a>axis info</h2><ol>
<li>å…ˆAnalysiså†Transform <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/687394750">link</a></li>
<li>include&#x2F;triton&#x2F;Analysis&#x2F;AxisInfo.h ä¸­æœ‰è§£é‡Šcontiguityã€divisibility å’Œ constancy, æ˜¯ç”¨äºæè¿°å¼ é‡ï¼ˆTensorï¼‰åœ¨ä¸åŒç»´åº¦ä¸Šçš„å†…å­˜å¸ƒå±€å’Œå€¼çš„åˆ†å¸ƒç‰¹æ€§çš„é‡è¦å±æ€§ï¼Œå®ƒä»¬é€šå¸¸ç”¨äºä¼˜åŒ–ç¼–è¯‘å™¨çš„ä»£ç ç”Ÿæˆï¼Œç‰¹åˆ«æ˜¯åœ¨ GPU ä¸Šç”Ÿæˆé«˜æ•ˆçš„å†…å­˜è®¿é—®æ¨¡å¼æ—¶ã€‚<ul>
<li><a target="_blank" rel="noopener" href="https://chatgpt.com/share/6826a649-edc8-8004-bb2e-fe9255d2b68e">gpt</a></li>
</ul>
</li>
<li>æ‰“å°axis infoä»£ç ä½ç½®ï¼š<a target="_blank" rel="noopener" href="https://github.com/triton-lang/triton/blob/676227a023b88d48f59d660df6c12d98630ed240/lib/Analysis/AxisInfo.cpp#L1336">link</a></li>
<li>å¯ä»¥è·å–Valueçš„axis info</li>
<li>contiguity	æœ€çŸ­çš„è¿ç»­æ•´æ•°æ®µé•¿åº¦	å†…å­˜å¸ƒå±€æ˜¯å¦ç´§å¯†</li>
<li>divisibility	æ¯æ®µèµ·å§‹å€¼èƒ½è¢«æ•´é™¤çš„æœ€å¤§ 2 çš„å¹‚æ¬¡	å€¼æ˜¯å¦æœ‰è§„å¾‹ã€å¯¹é½</li>
<li>constancy	æœ€çŸ­çš„ç›¸åŒæ•°å€¼åºåˆ—é•¿åº¦	æ˜¯å¦åŒ…å«é‡å¤å¸¸æ•°ï¼Œç”¨äºä¼˜åŒ–å¹¿æ’­ç­‰</li>
<li>æ¯ä¸ªå±æ€§æ˜¯å¤šä¸ºçš„ï¼Œdim 0è¡¨ç¤ºæœ€é«˜ç»´ï¼Œæœ€åé¢ä¸€ä¸ªæ•°æ˜¯æœ€ä½ç»´</li>
<li>AxisInfo Analysis<ul>
<li>TRITON_LLVM_DEBUG_ONLY&#x3D;â€tritongpu-coalesceâ€ æ‰“å°AxisInfo</li>
<li>Contiguity: è¿ç»­æ€§ï¼Œå½“æ•°æ®ï¼ˆå¦‚æ•°ç»„æˆ–å‘é‡ï¼‰çš„å„ä¸ªå…ƒç´ åœ¨å†…å­˜ä¸­æŒ‰ç…§é¡ºåºæ’åˆ—ã€åœ°å€è¿ç»­æ—¶ï¼Œæˆ‘ä»¬ç§°è¯¥æ•°æ®ç»“æ„æ˜¯è¿ç»­çš„</li>
<li>Divisibilityï¼šå¯åˆ†æ€§, åœ¨å¤„ç†æ•°ç»„æˆ–çŸ©é˜µæ—¶ï¼Œå¦‚æœæ•°æ®ç»´åº¦çš„é•¿åº¦èƒ½æ•´é™¤åˆ†å—å¤§å°ï¼Œåˆ™å¯ä»¥å°†æ•°æ®åˆ†å‰²ä¸ºè¿ç»­ä¸”å¤§å°å‡ä¸€çš„å—ï¼ˆä¾‹å¦‚åœ¨ tiling æ“ä½œä¸­ï¼‰ï¼Œè¿™æœ‰åŠ©äºå†…å­˜è®¿é—®çš„å±€éƒ¨æ€§å’Œç¼“å­˜åˆ©ç”¨ç‡ã€‚<ul>
<li>tt.divisibility å±æ€§å°±æ˜¯ç”¨æ¥ç»™å‡ºå¯¹æ•°æ®ï¼ˆé€šå¸¸æ˜¯æŒ‡é’ˆæˆ–è€…æ•´æ•°å€¼ï¼‰çš„æ•´é™¤æ€§ï¼ˆæˆ–å¯¹é½æ€§ï¼‰çš„ä¿è¯</li>
<li>è¿™ç§æœºåˆ¶ç±»ä¼¼äºå…¶ä»–ç¼–è¯‘å™¨ä¸­é€šè¿‡â€œå¯¹é½â€è¯´æ˜ç¬¦ï¼ˆå¦‚ attribute((aligned(16))) ç­‰ï¼‰æä¾›çš„ä¼˜åŒ–æç¤ºï¼Œä½†åœ¨ Triton IR ä¸­ä»¥ä¸€ç§ä¸“ç”¨çš„æ–¹å¼è¡¨è¾¾ã€‚</li>
</ul>
</li>
<li>Constancy(Constant Value): æŒ‡è¿™ä¸ªTensoræ˜¯å¸¸é‡ï¼Œå¾—åˆ°å…¶å¸¸é‡çš„é•¿åº¦ï¼Œå¯¹äº%1æ˜¯é€šè¿‡arith.constantå¾—åˆ°çš„ï¼Œå…¶é•¿åº¦ä¸º128ï¼Œconstant valueä¸º1</li>
</ul>
</li>
<li>gpu blocked layoutæ˜¯çº¿ç¨‹åˆ†é…æ•°æ®çš„layoutï¼Œä¸æ˜¯æ•°æ®çš„layout   </li>
<li>è®¿å­˜åˆå¹¶éœ€è¦çœ‹load storeçš„oprandçš„<code>çº¿ç¨‹è®¿é—®é¡ºåºå’Œæ•°æ®çš„æ’å¸ƒ</code>å†³å®šæ˜¯ä¸æ˜¯éœ€è¦åˆå¹¶è®¿å­˜  sample:</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#blocked1 = #triton_gpu.blocked&lt;&#123;sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]&#125;&gt;</span><br><span class="line">%10 = tt.addptr %7, %9 : tensor&lt;64x64x!tt.ptr&lt;f32&gt;, #blocked1&gt;, tensor&lt;64x64xi32, #blocked1&gt;</span><br><span class="line">%19 = tt.load %10, %cst, %cst_0 &#123;cache = 1 : i32, evict = 1 : i32, isVolatile = false&#125; : tensor&lt;64x64xf32, #blocked1&gt;</span><br><span class="line">// %10 çš„AxisInfo contiguity = [1, 64], divisibility = [4, 16], constancy = [1, 1], constant_value = &lt;none&gt;</span><br><span class="line">// %10çš„blocked threadsPerWarp = [32, 1]è¡¨æ˜çº¿ç¨‹æŒ‰åˆ—å–æ•°ï¼ŒAxisInfo  contiguity = [1, 64]è¡¨æ˜æ•°æ®æ˜¯è¡Œä¼˜å…ˆçš„ï¼Œloadçš„æ—¶å€™è®¿å­˜æ•ˆç‡ä¸é«˜ï¼Œéœ€è¦è®¿å­˜åˆå¹¶coalesce,  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="lowering"><a href="#lowering" class="headerlink" title="lowering"></a>lowering</h2><h3 id="for"><a href="#for" class="headerlink" title="for"></a><a target="_blank" rel="noopener" href="https://mlir.llvm.org/docs/Dialects/SCFDialect/#scffor-scfforop">for</a></h3><ol>
<li>for -&gt; scf -&gt; cf -&gt; llvm.cf -&gt; br</li>
</ol>
<h3 id="make-range"><a href="#make-range" class="headerlink" title="make_range"></a>make_range</h3><ol>
<li>tt.make_rangeå†³å®šæ¯ä¸€ä¸ªçº¿ç¨‹è®¡ç®—çš„æ•°æ®é‡ï¼Œtritonæ˜¯block levelçš„ç¼–ç¨‹ï¼Œé€šè¿‡make_rangeå˜æˆthread level</li>
<li>make_rangeé‡Œä¼šè·å–cluster, block, warp, threadçš„id, ä¼šå°†æ•°æ®åˆ’åˆ†åˆ°idå¯¹åº”index, ttiré‡Œæ— layoutä¿¡æ¯ï¼Œttgiré‡Œæœ‰ï¼Œæ ¹æ®ttgiræ¥lowering<ul>
<li>TTIR ä¸­çš„æ“ä½œæ˜¯æŠ½è±¡çš„å¼ é‡çº§æ“ä½œï¼Œæ²¡æœ‰è¯´æ˜å…·ä½“ç”±å“ªä¸ªçº¿ç¨‹å¤„ç†ä»€ä¹ˆæ•°æ®ã€‚</li>
<li>TTGIR æ˜ç¡®äº†ï¼š<ul>
<li>æ¯ä¸ªçº¿ç¨‹å¤„ç†å“ªäº›å…ƒç´ </li>
<li>çº¿ç¨‹çš„çº¿ç¨‹ç´¢å¼•&#x2F;ç»´åº¦</li>
<li>block&#x2F;grid çš„ç»“æ„</li>
</ul>
</li>
<li><code>./triton-tensor-layout -l &quot;#triton_gpu.blocked&lt;&#123;sizePerThread = [1, 1], threadsPerWarp = [8, 4], warpsPerCTA = [2, 2], order = [1, 0]&#125;&gt;&quot; -t &quot;tensor&lt;16x8xf32&gt;&quot;</code></li>
<li><code>python/build/cmake.linux-x86_64-cpython-3.10/bin/triton-tensor-layout -l &quot;#ttg.blocked&lt;&#123;sizePerThread = [1], threadsPerWarp = [1], warpsPerCTA = [1], order = [0]&#125;&gt;&quot; -t=&quot;tensor&lt;256xf32&gt;&quot;</code></li>
</ul>
</li>
<li>sipu ä¸­tile_formatè¾“å…¥æ—¶ï¼Œ make_rangeå†³å®šæ•°æ®åç§»</li>
</ol>
<h2 id="base"><a href="#base" class="headerlink" title="base"></a>base</h2><ol>
<li>intrinsic, asm, builtin<ul>
<li>asmï¼ˆå†…è”æ±‡ç¼–ï¼‰æ‰‹åŠ¨åœ¨ C&#x2F;C++ ä»£ç ä¸­åµŒå…¥æ±‡ç¼–æŒ‡ä»¤ï¼Œæä¾›æœ€åº•å±‚ã€æœ€ç²¾ç»†çš„æ§åˆ¶ï¼Œä½†å¯ç§»æ¤æ€§æœ€å·®ï¼Œéœ€è¦é’ˆå¯¹ä¸åŒæ¶æ„å•ç‹¬ç¼–å†™æ±‡ç¼–è¯­å¥ã€‚ </li>
<li>intrinsicï¼ˆç¼–è¯‘å™¨å†…å»ºå‡½æ•°ï¼‰çœ‹ä¼¼æ™®é€šå‡½æ•°è°ƒç”¨ï¼Œç¼–è¯‘å™¨å°†å…¶â€œå†…è”â€æ›¿æ¢ä¸ºå¯¹åº”ç¡¬ä»¶æŒ‡ä»¤æˆ–æŒ‡ä»¤åºåˆ—ï¼Œæ—¢èƒ½ä¿è¯æ€§èƒ½ï¼Œåˆæé«˜äº†å¯ç»´æŠ¤æ€§å’Œè·¨å¹³å°æ€§ï¼ˆåœ¨æ”¯æŒè¯¥ intrinsic çš„æ¶æ„ä¸Šç›´æ¥ç”ŸæˆæŒ‡ä»¤ï¼Œå¦åˆ™å›é€€è‡³é€šç”¨å®ç°ï¼‰ã€‚ </li>
<li>builtinï¼ˆGCC&#x2F;Clang å†…ç½®å‡½æ•°ï¼‰ä»¥ _<em>builtin</em> å‰ç¼€å‡ºç°ï¼Œæ— é¡»åŒ…å«å¤´æ–‡ä»¶ï¼Œç”±ç¼–è¯‘å™¨åŸç”Ÿè¯†åˆ«å¹¶ä¼˜åŒ–ï¼ˆå¦‚ __builtin_popcount å¯æ˜ å°„ä¸ºç¡¬ä»¶ POPCNT æŒ‡ä»¤ï¼‰ï¼Œå…¼å…·å†…å»ºå‡½æ•°ä¸è¯­è¨€æ‰©å±•çš„ç‰¹ç‚¹ï¼Œå¯ç”¨äºåŸå­æ“ä½œã€æ•°å­¦è®¡ç®—ç­‰å¤šç§åœºæ™¯</li>
</ul>
</li>
<li>intrinsicï¼ˆå†…åœ¨å‡½æ•°ï¼‰å’Œ asmï¼ˆInline assembly å†…è”æ±‡ç¼–ï¼‰å„æœ‰ä¼˜ç¼ºç‚¹ï¼šå†…åœ¨å‡½æ•°æä¾›äº†ä¸€ç§è¾ƒé«˜çº§ã€ä¾¿æ·ä¸”å®‰å…¨çš„æ–¹å¼è°ƒç”¨åº•å±‚æŒ‡ä»¤ï¼ŒåŒæ—¶è®©ç¼–è¯‘å™¨èƒ½å……åˆ†ä¼˜åŒ–ä»£ç ï¼›è€Œå†…è”æ±‡ç¼–åˆ™æä¾›äº†æè‡´çš„æ§åˆ¶èƒ½åŠ›ï¼Œä½†ä¹Ÿå¸¦æ¥å¯ç§»æ¤æ€§å’Œç»´æŠ¤æ€§ä¸Šçš„æŒ‘æˆ˜ã€‚</li>
<li>åœ¨ç¼–è¯‘å™¨å’Œç¼–ç¨‹è¯­è¨€æ–‡æ¡£ä¸­ï¼Œâ€intrinsicâ€ é€šå¸¸æŒ‡ç”±ç¼–è¯‘å™¨ç›´æ¥å†…ç½®çš„å‡½æ•°ï¼Œç”¨äºæé«˜æ•ˆç‡ï¼Œå°†å‡½æ•°è°ƒç”¨è½¬åŒ–ä¸ºå†…è”ä»£ç æˆ–ç‰¹å®šçš„æœºå™¨æŒ‡ä»¤ã€‚â€builtinâ€ åˆ™å¤šç”¨ä½œ â€œintrinsicâ€ çš„åŒä¹‰è¯</li>
<li>builtinæ˜¯ç¼–è¯‘å™¨å†…ç½®ï¼Œintrinsicéœ€è¦å¤´æ–‡ä»¶</li>
<li>builtinæ˜¯æ›´å¹¿æ³›çš„â€œç¼–è¯‘å™¨æ‰©å±•â€é›†åˆï¼šé™¤äº†æ˜ å°„ç¡¬ä»¶æŒ‡ä»¤å¤–ï¼Œè¿˜åŒ…æ‹¬è¯¸å¦‚åˆ†æ”¯é¢„æµ‹æç¤ºï¼ˆ__builtin_expectï¼‰ã€ç±»å‹æ£€æŸ¥ï¼ˆ__builtin_types_compatible_pï¼‰ã€å†…å­˜å±éšœã€æ•°å­¦å‡½æ•°ï¼ˆ__builtin_sinï¼‰ç­‰</li>
<li>ç”¨c++å†™kernelæ—¶ç”¨builtin, è¢«ç¼–è¯‘æˆlliræ—¶ï¼Œè½¬æ¢æˆintrinsic; c++ä¹Ÿèƒ½è°ƒç”¨intrinsicï¼Œä¾‹å¦‚arm neon intrinsic</li>
<li>Intrinsic æ˜¯ç¼–è¯‘å™¨æä¾›çš„ç‰¹æ®Šå‡½æ•°ï¼Œé€šå¸¸ç›´æ¥æ˜ å°„åˆ°ç‰¹å®šçš„æœºå™¨æŒ‡ä»¤ã€‚å®ƒä»¬å…è®¸ç¨‹åºå‘˜ä»¥å‡½æ•°çš„å½¢å¼ä½¿ç”¨åº•å±‚ç¡¬ä»¶æŒ‡ä»¤ï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚Builtin æ˜¯ç¼–è¯‘å™¨å†…ç½®çš„å‡½æ•°ï¼Œé€šå¸¸ä»¥ _<em>builtin</em> ä¸ºå‰ç¼€ï¼Œæä¾›äº†ä¸€äº›æ²¡æœ‰å¤´æ–‡ä»¶ä¹Ÿå¯ä»¥ä½¿ç”¨çš„åŠŸèƒ½ï¼Œå¦‚æ•°å­¦è¿ç®—ã€ä½æ“ä½œç­‰ã€‚è¿™äº›å‡½æ•°ç”±ç¼–è¯‘å™¨ç›´æ¥è¯†åˆ«å’Œå¤„ç†ï¼Œå¯èƒ½è¢«ä¼˜åŒ–ä¸ºç‰¹å®šçš„æœºå™¨æŒ‡ä»¤ã€‚</li>
<li>å½“ä½ è¦è°ƒç”¨ç‰¹å®šæŒ‡ä»¤é›†ï¼ˆå¦‚ SSEã€NEONï¼‰æˆ–ç›´æ¥æ“ä½œç‰¹æ®Šå¯„å­˜å™¨ï¼Œç”¨ intrinsicï¼›å½“ä½ è¦åˆ©ç”¨ç¼–è¯‘å™¨æä¾›çš„å„ç§ä½çº§ä¼˜åŒ–æˆ–æ‰©å±•ï¼ˆåˆ†æ”¯é¢„æµ‹ã€å†…å­˜å±éšœã€å†…ç½®æ•°å­¦å‡½æ•°ç­‰ï¼‰ï¼Œç”¨ builtinã€‚</li>
<li>polyhedral compilationï¼Œ  scheduling languagesä¸triton<ul>
<li>å¦‚æœä½ åšç¼–è¯‘ä¼˜åŒ–ï¼ˆLLVM, ç¼–è¯‘å™¨åç«¯å¼€å‘ï¼‰â†’ é€‰æ‹© Polyhedral Compilation</li>
<li>å¦‚æœä½ ä¼˜åŒ–è®¡ç®—å›¾ï¼ˆHalide, TVM, è®¡ç®—è°ƒåº¦ï¼‰â†’ é€‰æ‹© Scheduling Languages</li>
<li>å¦‚æœä½ ä¼˜åŒ–æ·±åº¦å­¦ä¹ ï¼ˆGPU kernel åŠ é€Ÿï¼‰â†’ é€‰æ‹© Triton</li>
</ul>
</li>
<li>å‡è®¾è¦ä¼˜åŒ–çŸ©é˜µä¹˜æ³• C &#x3D; A Ã— Bï¼š<ul>
<li>Polyhedral Compilationï¼šè‡ªåŠ¨åˆ†æ for å¾ªç¯ä¾èµ–ï¼Œè°ƒæ•´ i, j, k è®¡ç®—é¡ºåºï¼Œè¿›è¡Œ loop tiling å’Œ å‘é‡åŒ–ã€‚ç”Ÿæˆé€‚ç”¨äº CPU&#x2F;GPU çš„é«˜æ•ˆä»£ç ã€‚</li>
<li>Scheduling Languagesï¼ˆHalide, TVMï¼‰ï¼šå…è®¸ç”¨æˆ·æ‰‹åŠ¨è®¾å®šè®¡ç®—é¡ºåºï¼Œæ¯”å¦‚å…ˆè®¡ç®—å°å—çŸ©é˜µã€å†åˆå¹¶ç»“æœã€‚é€‚ç”¨äºè‡ªåŠ¨è°ƒåº¦å’Œæœç´¢æœ€ä¼˜ç­–ç•¥ã€‚</li>
<li>Tritonï¼šç›´æ¥ç¼–å†™ triton.kernelï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜æ•ˆ CUDA ä»£ç ã€‚é€šè¿‡ memory tiling å’Œ å¯„å­˜å™¨ä¼˜åŒ– æé«˜ GPU æ‰§è¡Œæ•ˆç‡ã€‚</li>
</ul>
</li>
<li>ç¬¬ä¸€æ¬¡ç¼–è¯‘æ—¶ä¼šåœ¨&#x2F;tmpç›®å½•ä¸‹ç”Ÿæˆmain.cppç„¶åç¼–è¯‘æˆè¿è¡Œkernelæ—¶æ‰€éœ€soï¼Œç¼–è¯‘ååˆ é™¤main.cppï¼Œç”Ÿæˆå†…å®¹è§driver.pyã€‚<ul>
<li>main.cppä¸åŒ…å«mainå‡½æ•°ï¼Œæœ‰å‡½æ•°ç”¨äºè°ƒç”¨kernel</li>
<li>main.cppä¸­åŒ…å«ç”Ÿæˆçš„kenerlè·¯å¾„, éœ€è¦åŠ è½½</li>
</ul>
</li>
<li>ä½¿å¾—ç®—å­å¼€å‘çš„éƒ¨åˆ†å¤æ‚åº¦åˆ†é…ç»™ä¸Šå±‚ kernel å¼€å‘ç”¨æˆ·ï¼Œéƒ¨åˆ†å¤æ‚åº¦åˆ†é…ç»™åº•å±‚çš„ Triton compilerã€‚åŒæ—¶å¯¹æ¥ä¸Šå±‚æ¡†æ¶çš„å·¥ä½œåˆ™äº¤ç»™äº†ä¸Šå±‚è½¯ä»¶æ ˆï¼Œä½¿å¾— Triton èƒ½å¤Ÿä¸“æ³¨åœ¨è‡ªå·±è¿™ä¸ªå±‚æ¬¡éœ€è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ä¸Šï¼Œæ‰¾åˆ°äº†ä¸€ä¸ªæ¯”è¾ƒä¸é”™çš„â€product&#x2F;technologyâ€ fitã€‚</li>
<li>Triton çš„æ ¸å¿ƒè®¾è®¡æ€æƒ³â€”-Block-wise ç¼–ç¨‹ï¼ŒBlock ä¸Šé¢çš„å½’ç”¨æˆ·ï¼ŒBlock å†…éƒ¨çš„å½’ Triton compiler è‡ªåŠ¨åŒ–å¤„ç†ã€‚ç›¸åº”åœ°ï¼ŒBlock å†…éƒ¨çš„ä¼˜åŒ–ç»†èŠ‚ï¼Œä¹Ÿäº¤ç”± Triton compiler å¤„ç†äº†ã€‚</li>
<li>Triton è¿™ä¸ªé¡¹ç›®ç›®å‰è¿˜æ›´åƒæ˜¯ä¸€ä¸ªæ»¡è¶³ç»†åˆ†åœºæ™¯(é«˜æ•ˆé«˜æ€§èƒ½ Kernel å¼€å‘)éœ€æ±‚çš„â€œå°è€Œç¾â€çš„é¡¹ç›®</li>
<li>triton kernel ä¸­çš„è®¡ç®—æ˜¯ block level, è·Ÿæ® ptr + offset ç›´æ¥è®¡ç®—ä¸€ä¸ª blockï¼Œblock å…·ä½“å¦‚ä½•åˆ’åˆ†æˆ thread ç”±ç¼–è¯‘å™¨å†³å®š<ul>
<li>é€šè¿‡ arrange + stride æ¥è®¡ç®— block ä¸­æ¯ä¸ªæ•°æ®çš„ offset</li>
</ul>
</li>
<li>æ³¨æ„ä»£ç ä¸­çš„ pid å«ä¹‰å’Œ cuda çš„ä¸åŒï¼štriton è¡¨ç¤º block id, cuda è¡¨ç¤º thread id</li>
<li>è‡ªå®šä¹‰ä¼˜åŒ–æœç´¢ç©ºé—´ï¼Œå‡å°‘æœç´¢æ—¶é—´</li>
<li>ä½¿ç”¨ triton æ¥åš codegen</li>
<li>triton çš„ language è¯­æ³•ç¡®å®å¾ˆç®€å•ï¼Œç›¸æ¯”è¾ƒ cuda æ¥è¯´ï¼Œå®ƒèƒ½å¤Ÿå¸®æˆ‘ä»¬å¿«é€ŸéªŒè¯ä¸€äº› ideaï¼ŒåŒæ—¶ç»™å‡ºæ¯” cublas æ€§èƒ½ç›¸å½“çš„ç®—å­ã€‚</li>
<li>Using Triton, you only need to know that a program is divided into multiple blocks</li>
<li>å¤§éƒ¨åˆ†çš„æ¡†æ¶éƒ½ä»¥ python çš„ DSL æš´éœ²ç»™ç”¨æˆ·ï¼Œç„¶åç”¨æˆ·é€šè¿‡å†™å¯¹åº”çš„ python è¯­æ³•ï¼Œè°ƒç”¨å·²ç»ç”¨ C++&#x2F;CUDA æˆ–è€… assemble å†™å¥½çš„é«˜æ€§èƒ½ç»„ä»¶ã€‚</li>
<li><code>pip show triton</code> &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.10&#x2F;dist-packages&#x2F;triton&#x2F;_C&#x2F;libtriton.so</li>
<li>æ”¯æŒ nvidia, AMD GPUï¼› &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.10&#x2F;dist-packages&#x2F;triton&#x2F;backends&#x2F;amd&#x2F;lib&#x2F;libamdhip64.so</li>
<li><code>~/.triton/cache</code> cache è·¯å¾„, é‡Œé¢æœ‰ ptx, cubin, å„ç§ ir æ–‡ä»¶ <a target="_blank" rel="noopener" href="https://chatgpt.com/share/6750222c-3c44-8004-b0a4-483b2d45dead">link</a><br><img src="https://i.ibb.co/qFsBwJv/YMws76l-KOI.png" alt="å„æ–‡ä»¶ä½œç”¨"><ul>
<li>TTIRï¼ˆTriton Tensor Intermediate Representationï¼‰TTIR æ˜¯ Triton ç¼–è¯‘å™¨çš„ä¸€ä¸ªä¸­é—´è¡¨ç¤ºï¼Œä¸“é—¨ç”¨äºæè¿°å¼ é‡çº§åˆ«çš„æ“ä½œã€‚å®ƒæ˜¯ä¸€ä¸ªè¾ƒé«˜å±‚æ¬¡çš„ä¸­é—´è¡¨ç¤ºï¼Œå…³æ³¨è®¡ç®—ä»»åŠ¡ä¸­çš„å¼ é‡æ“ä½œå’Œè®¡ç®—æ¨¡å¼ã€‚</li>
<li>TTGIRï¼ˆTriton Tensor GPU Intermediate Representationï¼‰TTGIR æ˜¯ Triton çš„ä½å±‚ä¸­é—´è¡¨ç¤ºï¼Œä¸“æ³¨äºæè¿°ä¸ GPU ç¡¬ä»¶æ¶æ„ç›¸å…³çš„è®¡ç®—ç»†èŠ‚ã€‚å®ƒå»ºç«‹åœ¨ TTIR ä¹‹ä¸Šï¼Œä½†æ›´åŠ è´´è¿‘ GPU çš„æ‰§è¡Œæ¨¡å‹ã€‚</li>
</ul>
</li>
<li>Triton, a <code>language</code> and <code>compiler</code> for writing highly efficient custom Deep-Learning primitives. The aim of Triton is to provide an open-source environment to write fast code at higher productivity than CUDA, but also with higher flexibility than other existing DSLs.</li>
<li>An open-source python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code â€“ most of the time on par with what an expert would be able to produce</li>
<li>å¼€å‘æ•ˆç‡<br><img src="https://i.ibb.co/NYSS9WV/Xrz-Qku-ZLSo.png" alt="img"></li>
<li>é¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆdomain-specific language DSL)</li>
<li>æœ¬è´¨ä¸Šæ¥è¯´ï¼ŒTriton å’Œ TVM&#x2F;XLA è¿™ç±»å·¥ä½œçš„å®šä½æœ‰æ‰€ä¸åŒï¼Œå¦‚æœè¯´ TVM&#x2F;XLA æ˜¯æ¯”è¾ƒçº¯æ­£çš„ AI ç¼–è¯‘å™¨çš„è¯ï¼ŒTriton æ›´åƒæ˜¯ä¸€ä¸ªé¢å‘ AI åŠ é€Ÿå™¨ç®—å­å¼€å‘çš„é¢†åŸŸå¼€å‘è¯­è¨€ï¼Œä¸ºäº†èƒ½å¤Ÿå°†ç”¨æˆ·ä½¿ç”¨ Triton è¯­è¨€å¼€å‘çš„ kernel æ˜ å°„åˆ°å…·ä½“ç¡¬ä»¶ä¸Šçš„æ‰§è¡Œç ï¼Œéœ€è¦è®¾è®¡å¼€å‘ç›¸åº”çš„ Triton compiler æ¥å®Œæˆè¿™å±‚æ˜ å°„ã€‚æ‰€ä»¥å½“æˆ‘ä»¬è¯´ Triton çš„æ—¶å€™ï¼Œå…¶å®éšæŒ‡äº† Triton è¯­è¨€+Triton ç¼–è¯‘å™¨è¿™ä¸¤ä¸ªäº‹ç‰©çš„ç»¼åˆä½“ã€‚</li>
<li>ä» triton çš„æºç æ¥çœ‹ï¼Œtriton ç›®å‰åœ¨ NV çš„ GPU ä¸Šå·²ç»æœ‰äº†ä¸€å¥—è‡ªå·±æ¯”è¾ƒæˆç†Ÿçš„ mapping è·¯çº¿ï¼Œé€šè¿‡å…ˆå¯¹ python è¯­è¨€å±‚ï¼Œä¹Ÿå°±æ˜¯ triton DSL è¿›è¡ŒæŠ½è±¡ï¼Œå¾—åˆ° ASTï¼Œç„¶åå°† AST ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ lower åˆ° Triton Dialect ä¸Šï¼ŒTriton Dialect åˆ™æ˜¯ä¸€ä¸ªæ¯”è¾ƒè´´è¿‘ä¸Šå±‚è¯­è¨€è¡¨è¾¾çš„ IRï¼Œä»–çš„ä¸»è¦ä½œç”¨åˆ™æ˜¯ä¸ºäº†ä¿æŒç”¨æˆ·åœ¨ä¹¦å†™å¯¹åº”ç®—æ³•æ—¶çš„å‡†ç¡®æ€§ã€‚æ¥ä¸‹æ¥ä¼šè¿›ä¸€æ­¥è¢« map åˆ° TritonGPU Dialect ä¸Šï¼Œé‚£ä¹ˆ TritonGPU Dialect åˆ™æ˜¯ä¸€ä¸ªæ›´åŠ è´´è¿‘ GPU å±‚é¢çš„ IRï¼Œå®ƒåˆ™æ˜¯ä¸ºäº†å…·ä½“çš„æ€§èƒ½ä¼˜åŒ–è€Œè®¾è®¡ã€‚å›¾ä¸­å…¶ä»–çš„è“è‰²æ¨¡å—ï¼Œæ¯”å¦‚ SCFï¼ŒArithï¼ŒTensor ç­‰éƒ½æ˜¯ MLIR ç”Ÿæ€ä¸­å·²ç»è¢«å®ç°å¥½å¹¶ä¸”å¹¿ä¸ºä½¿ç”¨çš„ Dialectã€‚è¿™äº› Dialect ä¼šä¸€èµ·å’Œ TritonGPU Dialect å…±å­˜ï¼Œç„¶åè¢« lower åˆ°å¯¹åº”çš„ LLVM Dialectï¼ŒLLVM Dialect åˆ™æ˜¯æœ€è´´è¿‘ LLVM IR çš„ä¸€å±‚è®¾è®¡ï¼Œä» LLVM Dialect åˆ° LLVM IR çš„è½¬æ¢æ˜¯éå¸¸å®¹æ˜“çš„ï¼Œæœ€ç»ˆä»£ç å°±ä¼šè¢«æ¥å…¥åˆ° LLVM çš„ NVPTX çš„åç«¯ï¼Œä»è€Œç”Ÿæˆåç»­èƒ½è·‘åœ¨ GPU ä¸Šçš„é«˜æ€§èƒ½ machine code. <a target="_blank" rel="noopener" href="http://giantpandacv.com/project/%E9%83%A8%E7%BD%B2%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/OpenAI%20Triton%20MLIR%20%E7%AC%AC%E9%9B%B6%E7%AB%A0%20%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/">link</a></li>
<li>å’Œ cuda pytorch åŒºåˆ« <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=AtbnRIzpwho&t=273s">link</a><br><img src="https://i.ibb.co/qszbhN4/NYmmor-R0l-P.png" alt="åŒºåˆ«"></li>
<li>ç¼–è¯‘å™¨æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç”Ÿäº§åŠ›å·¥å…·ï¼Œèƒ½å¤Ÿå¸®åŠ©åšå¾ˆå¤šæ‰‹å·¥çš„ä»»åŠ¡</li>
<li>triton æ”¯æŒçš„è¯­è¨€ç‰¹æ€§æ˜¯ Python çš„ä¸€ä¸ªå­é›†<ul>
<li>no dict</li>
<li>no meta-programming</li>
<li>no slicing</li>
<li>no indexing</li>
<li>â€¦</li>
</ul>
</li>
<li>triton v2 <a target="_blank" rel="noopener" href="https://www.jokeren.tech/slides/triton_next.pdf">link</a><ul>
<li>MLIR(Triton dialect, TritonGPU dialect)</li>
<li>clean layout concepts(like cutlass cute)<ul>
<li>low overhead time: Cache and fetch kernels using efficient signatures</li>
</ul>
</li>
<li>debugging: triton.language.print</li>
<li>Profiler interface</li>
</ul>
</li>
<li>æŸ¥çœ‹ grid</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grid = <span class="keyword">lambda</span> meta: (triton.cdiv(n_elements, meta[<span class="string">&#x27;BLOCK_SIZE&#x27;</span>]), )</span><br><span class="line">grid_size = grid(&#123;<span class="string">&#x27;BLOCK_SIZE&#x27;</span>: <span class="number">1024</span>&#125;) <span class="comment"># gridæ˜¯lamdaå‡½æ•°ï¼Œéœ€è¦å…ˆè°ƒç”¨æ‰èƒ½çœ‹ç»“æœ</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Grid size: <span class="subst">&#123;grid_size&#125;</span>&#x27;</span>) <span class="comment"># (97, )</span></span><br></pre></td></tr></table></figure>

<h2 id="è£…é¥°å™¨"><a href="#è£…é¥°å™¨" class="headerlink" title="è£…é¥°å™¨"></a>è£…é¥°å™¨</h2><ol>
<li>triton.jit</li>
<li>triton.autotune</li>
<li>triton.compile</li>
<li>torch.compile</li>
</ol>
<h2 id="debug"><a href="#debug" class="headerlink" title="debug"></a>debug</h2><ol>
<li><a target="_blank" rel="noopener" href="https://mlir.llvm.org/getting_started/Debugging/">MLIR debug</a><ul>
<li>mlir-opt</li>
</ul>
</li>
<li>ä½¿ç”¨<code>llvm::sys::PrintStackTrace(llvm::errs());</code> æ¥æ‰“å°å †æ ˆï¼Œæ³¨æ„éœ€è¦è®¾ç½®llvm-symbolizerè·¯å¾„<ul>
<li>export PATH&#x3D;$PATH:&#x2F;share_data&#x2F;triton&#x2F;llvm_19_dir&#x2F;250925&#x2F;bin</li>
</ul>
</li>
<li>export MLIR_ENABLE_DIAGNOSTICS&#x3D;warnings,remarks;æ¥æ§åˆ¶è¯Šæ–­ä¿¡æ¯<br>op-&gt;emitRemark()<br>mlir::emitRemark</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="keyword">auto</span> enableDiagnostics =</span><br><span class="line">        triton::tools::<span class="built_in">getStrEnv</span>(<span class="string">&quot;MLIR_ENABLE_DIAGNOSTICS&quot;</span>);</span><br><span class="line">    !enableDiagnostics.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">  llvm::SmallVector&lt;std::string, <span class="number">3</span>&gt; storage;</span><br><span class="line">  <span class="built_in">parseCommaSeparatedValues</span>(enableDiagnostics, storage);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;str : storage) &#123;</span><br><span class="line">    <span class="keyword">if</span> (str == <span class="string">&quot;warnings&quot;</span>) &#123;</span><br><span class="line">      showWarnings = <span class="literal">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (str == <span class="string">&quot;remarks&quot;</span>) &#123;</span><br><span class="line">      showRemarks = <span class="literal">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (str == <span class="string">&quot;stacktraces&quot;</span>) &#123;</span><br><span class="line">      showStacktraces = <span class="literal">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (str == <span class="string">&quot;operations&quot;</span>) &#123;</span><br><span class="line">      showOperations = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// we show errors by default, so no need to set it</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>llvm_unreachable(â€œunsupported emitBaseIndexForLayoutâ€);</li>
<li>op-&gt;emitError(â€œExpected at least one tensor input operand.â€);<ul>
<li>è‡ªåŠ¨é™„å¸¦ operation çš„ä½ç½®ä¿¡æ¯ï¼ˆlocationï¼‰ï¼Œæ–¹ä¾¿ç”¨æˆ·æˆ–å¼€å‘è€…å¿«é€Ÿå®šä½ IR ä¸­å‡ºé”™çš„åœ°æ–¹ã€‚</li>
<li>è¿”å›å€¼æ˜¯ä¸€ä¸ª InFlightDiagnostic å¯¹è±¡ï¼Œå¯ä»¥ç”¨äºé“¾å¼è¿½åŠ æ›´è¯¦ç»†çš„ä¿¡æ¯</li>
</ul>
</li>
<li><code>./python/triton/_C/libtriton.so</code> libtrionä½ç½®</li>
<li><a target="_blank" rel="noopener" href="https://triton-lang.org/main/programming-guide/chapter-3/debugging.html">å®˜æ–¹æŒ‡å¯¼</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/triton-lang/triton?tab=readme-ov-file#tips-for-building">æºç  debug</a></li>
<li><code>TRITON_ENABLE_LLVM_DEBUG=1</code> æ‰“å°è¯¦ç»†ä¿¡æ¯</li>
<li><code>TRITON_LLVM_DEBUG_ONLY=&quot;tritongpu-remove-layout-conversions,regalloc&quot;</code> åªæ‰“å°ä¸€äº›pass log, ä½¿ç”¨LDBGå®</li>
<li><code>TRITON_INTERPRET=1</code> ä½¿ç”¨ Triton è§£é‡Šå™¨è€Œä¸æ˜¯åœ¨ GPU ä¸Šè¿è¡Œã€‚æ‚¨å¯ä»¥åœ¨å†…æ ¸ä»£ç ä¸­æ’å…¥ Python æ–­ç‚¹ï¼NOTE:æ³¨æ„çœŸæ­£è¿è¡Œçš„æ—¶å€™ä¸è¦æ‰“å¼€</li>
<li><code>TRITON_HOME=/home/data</code></li>
<li><code>MLIR_ENABLE_DUMP=1</code> åªdump mlir, ä¸dump llvm ir</li>
<li><code>LLVM_IR_ENABLE_DUMP=1</code></li>
<li><code>TRITON_ALWAYS_COMPILE=1</code> æ¯æ¬¡éƒ½é‡æ–°ç¼–è¯‘</li>
<li><code>TRITON_PRINT_AUTOTUNING=1</code>å¯ä»¥æ‰“å° autotune é€‰æ‹©çš„æœ€å¿«é…ç½® prints out the best autotuning config and total time spent for each kernel after autotuning is complete.</li>
</ol>
<h2 id="c-è°ƒç”¨-triton-kernel"><a href="#c-è°ƒç”¨-triton-kernel" class="headerlink" title="c++è°ƒç”¨ triton kernel"></a>c++è°ƒç”¨ triton kernel</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/triton-lang/triton/blob/main/python/test/unit/tools/test_aot.py">test aot</a><ul>
<li>vscode testing ä¸‹çš„ pytest æ¥æµ‹è¯• debug æ¨¡å¼å¯ä»¥çœ‹åˆ°ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„, å³é”®æµ‹è¯•ç¨‹åºè¿›å…¥ debug</li>
<li>èƒ½è‡ªåŠ¨ç”Ÿæˆ kernel.h, kernel.c, libkernel.so, test.c ä¸ç”¨æ‰‹å†™</li>
<li>python3 -m pytest -v python&#x2F;test&#x2F;unit&#x2F;tools è¿è¡Œæµ‹è¯•ç¨‹åº</li>
<li>python3 -m pytest -v -k test_compile_link_matmul python&#x2F;test&#x2F;unit&#x2F;tools&#x2F;test_aot.py</li>
<li>compile.py ç¼–è¯‘</li>
<li>compile_aot_kernels ç¼–è¯‘ kernel</li>
<li><a target="_blank" rel="noopener" href="https://github.com/triton-lang/triton/blob/fd691c67ac20958a67693358186d877790f5f48f/python/triton/tools/link.py#L222">load å‡½æ•°</a></li>
</ul>
</li>
<li>åœ¨ c++ load triton ç”Ÿæˆçš„ ptx æˆ–è€… cubin æ–‡ä»¶</li>
</ol>
<h2 id="links"><a href="#links" class="headerlink" title="links"></a>links</h2><ol>
<li><a target="_blank" rel="noopener" href="http://giantpandacv.com/project/%E9%83%A8%E7%BD%B2%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/OpenAI%20Triton%20MLIR%20%E7%AC%AC%E9%9B%B6%E7%AB%A0%20%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/">éå¸¸å¥½çš„ä¸­æ–‡æ•™ç¨‹</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jokeren.tech/slides/triton_next.pdf">triton next</a><ul>
<li>why triton</li>
<li>triton çš„å®šä½</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/613244988">è°ˆè°ˆå¯¹ OpenAI Triton çš„ä¸€äº›ç†è§£</a></li>
</ol>

    </div>

    
    
    
      

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>æœ¬æ–‡ä½œè€…ï¼š </strong>è´¾å¤•é˜³
  </li>
  <li class="post-copyright-link">
    <strong>æœ¬æ–‡é“¾æ¥ï¼š</strong>
    <a href="https://jiaxiyang.github.io/2024/07/03/triton/" title="triton">https://jiaxiyang.github.io/2024/07/03/triton/</a>
  </li>
  <li class="post-copyright-license">
    <strong>ç‰ˆæƒå£°æ˜ï¼š </strong>æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼
  </li>
</ul>
</div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/07/01/talk-skills/" rel="prev" title="talk_skills">
      <i class="fa fa-chevron-left"></i> talk_skills
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/09/24/qualcomm/" rel="next" title="qualcomm">
      qualcomm <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          æ–‡ç« ç›®å½•
        </li>
        <li class="sidebar-nav-overview">
          ç«™ç‚¹æ¦‚è§ˆ
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#llvm-objdump"><span class="nav-number">1.</span> <span class="nav-text">llvm-objdump</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lit-llvm-integrated-tester"><span class="nav-number">2.</span> <span class="nav-text">lit (llvm integrated tester)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NOTE"><span class="nav-number">3.</span> <span class="nav-text">NOTE</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#value%E6%9E%84%E9%80%A0"><span class="nav-number">4.</span> <span class="nav-text">valueæ„é€ </span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#recompile"><span class="nav-number">5.</span> <span class="nav-text">recompile</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mask"><span class="nav-number">6.</span> <span class="nav-text">mask</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tutorial"><span class="nav-number">7.</span> <span class="nav-text">tutorial</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#06-fused-attention"><span class="nav-number">7.1.</span> <span class="nav-text">06 fused-attention</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#libdevice"><span class="nav-number">8.</span> <span class="nav-text">libdevice</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuda%E5%92%8Ctriton%E5%8C%BA%E5%88%AB"><span class="nav-number">9.</span> <span class="nav-text">cudaå’ŒtritonåŒºåˆ«</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ALU-%E5%92%8C-SFU"><span class="nav-number">10.</span> <span class="nav-text">ALU å’Œ SFU</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E6%95%B0"><span class="nav-number">11.</span> <span class="nav-text">å¯¹æ•°</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#coordinate-%E5%88%B0-index%E7%9A%84%E6%98%A0%E5%B0%84"><span class="nav-number">12.</span> <span class="nav-text">coordinate åˆ° indexçš„æ˜ å°„</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tools"><span class="nav-number">13.</span> <span class="nav-text">Tools</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#triton-tensor-layout"><span class="nav-number">13.1.</span> <span class="nav-text">triton-tensor-layout</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lit"><span class="nav-number">13.2.</span> <span class="nav-text">lit</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%AD%E6%B3%95"><span class="nav-number">14.</span> <span class="nav-text">è¯­æ³•</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%82%E9%85%8D-DSL"><span class="nav-number">15.</span> <span class="nav-text">é€‚é… DSL</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tensor%E5%92%8C%E7%BA%BF%E7%A8%8Blayout"><span class="nav-number">16.</span> <span class="nav-text">tensorå’Œçº¿ç¨‹layout</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#linear-layout"><span class="nav-number">16.1.</span> <span class="nav-text">linear layout</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%8Elinear-layout%E8%8E%B7%E5%8F%96%E6%AF%8F%E4%B8%AAthread%E8%A6%81%E5%A4%84%E7%90%86%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="nav-number">16.1.1.</span> <span class="nav-text">ä»linear layoutè·å–æ¯ä¸ªthreadè¦å¤„ç†çš„æ•°æ®</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#convert-layout"><span class="nav-number">16.2.</span> <span class="nav-text">convert_layout</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#axis-info"><span class="nav-number">17.</span> <span class="nav-text">axis info</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lowering"><span class="nav-number">18.</span> <span class="nav-text">lowering</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#for"><span class="nav-number">18.1.</span> <span class="nav-text">for</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#make-range"><span class="nav-number">18.2.</span> <span class="nav-text">make_range</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#base"><span class="nav-number">19.</span> <span class="nav-text">base</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A3%85%E9%A5%B0%E5%99%A8"><span class="nav-number">20.</span> <span class="nav-text">è£…é¥°å™¨</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#debug"><span class="nav-number">21.</span> <span class="nav-text">debug</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#c-%E8%B0%83%E7%94%A8-triton-kernel"><span class="nav-number">22.</span> <span class="nav-text">c++è°ƒç”¨ triton kernel</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#links"><span class="nav-number">23.</span> <span class="nav-text">links</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="è´¾å¤•é˜³"
      src="/images/coder2.jpg">
  <p class="site-author-name" itemprop="name">è´¾å¤•é˜³</p>
  <div class="site-description" itemprop="description">æ·±åº¦å­¦ä¹ /è‡ªåŠ¨é©¾é©¶/C++/æ€§èƒ½ä¼˜åŒ–</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">195</span>
          <span class="site-state-item-name">æ—¥å¿—</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">åˆ†ç±»</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">æ ‡ç­¾</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/jiaxiyang" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;jiaxiyang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



  <div class="links-of-recent-posts motion-element">
    <div class="links-of-recent-posts-title">
      <i class="fa fa-history fa-fw"></i>
      æœ€è¿‘æ–‡ç« 
    </div>
    <ul class="links-of-recent-posts-list">
        <li class="links-of-recent-posts-item">
          <a href="/2025/08/20/AI-coding/" title="2025&#x2F;08&#x2F;20&#x2F;AI-coding&#x2F;">AI coding</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2025/04/28/Architecture/" title="2025&#x2F;04&#x2F;28&#x2F;Architecture&#x2F;">Computer Architecture</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2025/04/18/pytest/" title="2025&#x2F;04&#x2F;18&#x2F;pytest&#x2F;">pytest</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2025/01/18/cursor/" title="2025&#x2F;01&#x2F;18&#x2F;cursor&#x2F;">cursor</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2024/12/29/LLVM/" title="2024&#x2F;12&#x2F;29&#x2F;LLVM&#x2F;">LLVM</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021 â€“ 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">è´¾å¤•é˜³</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">ç«™ç‚¹æ€»å­—æ•°ï¼š</span>
    <span title="ç«™ç‚¹æ€»å­—æ•°">624k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">ç«™ç‚¹é˜…è¯»æ—¶é•¿ &asymp;</span>
    <span title="ç«™ç‚¹é˜…è¯»æ—¶é•¿">9:27</span>
</div>

<!-- ç½‘ç«™è¿è¡Œæ—¶é—´çš„è®¾ç½® -->
<span id="timeDate">è½½å…¥å¤©æ•°...</span>
<span id="times">è½½å…¥æ—¶åˆ†ç§’...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("06/26/2020 14:52:10");//æ­¤å¤„ä¿®æ”¹ä½ çš„å»ºç«™æ—¶é—´æˆ–è€…ç½‘ç«™ä¸Šçº¿æ—¶é—´
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "æœ¬ç«™å·²å®‰å…¨è¿è¡Œ "+dnum+" å¤© ";
        document.getElementById("times").innerHTML = hnum + " å°æ—¶ " + mnum + " åˆ† " + snum + " ç§’";
    }
setInterval("createtime()",250);
</script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="æ€»è®¿å®¢é‡">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="æ€»è®¿é—®é‡">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_sphere.min.js"></script>


  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : '[object Object]',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://jiaxiyang.github.io/2024/07/03/triton/',]
      });
      });
  </script>


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'g32ipLmEye1u5l6wBGRJt03S-gzGzoHsz',
      appKey     : 'zHgLkAICsZUl9Mf8LfdoVigP',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

  

  <script src="/js/activate-power-mode.min.js"></script>
  <script>
    POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);
  </script>





 
</body>
</html>

