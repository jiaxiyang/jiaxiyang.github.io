<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0-rc2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jiaxiyang.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="great 各种性能分析工具 easyperf VAI profiler perf-book perf-ninja 基于 CPU 性能调优的必要性和方法 topics&#x2F;profiling Linux_Performance_Analysis_and_Tools linuxperf">
<meta property="og:type" content="article">
<meta property="og:title" content="Profiling">
<meta property="og:url" content="https://jiaxiyang.github.io/2021/08/24/Cpp-Profiling/index.html">
<meta property="og:site_name" content="Xiyang">
<meta property="og:description" content="great 各种性能分析工具 easyperf VAI profiler perf-book perf-ninja 基于 CPU 性能调优的必要性和方法 topics&#x2F;profiling Linux_Performance_Analysis_and_Tools linuxperf">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mmbiz.qpic.cn/sz_mmbiz_png/2icOarNW84W7BnJpVvdnUeOgJYHibeWJbd4z0KJu556ykzgnjl7MHm5YWyjWDqR7eMPmXIWSWCFy8KG3dJQD8O8A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">
<meta property="article:published_time" content="2021-08-24T14:30:52.000Z">
<meta property="article:modified_time" content="2023-11-22T04:57:54.195Z">
<meta property="article:author" content="贾夕阳">
<meta property="article:tag" content="Profiling">
<meta property="article:tag" content="Perf">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mmbiz.qpic.cn/sz_mmbiz_png/2icOarNW84W7BnJpVvdnUeOgJYHibeWJbd4z0KJu556ykzgnjl7MHm5YWyjWDqR7eMPmXIWSWCFy8KG3dJQD8O8A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">

<link rel="canonical" href="https://jiaxiyang.github.io/2021/08/24/Cpp-Profiling/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Profiling | Xiyang</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WGS6S6YFJ6"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-WGS6S6YFJ6');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Xiyang</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Think twice, code once!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">158</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">44</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">55</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/jiaxiyang" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiaxiyang.github.io/2021/08/24/Cpp-Profiling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/coder2.jpg">
      <meta itemprop="name" content="贾夕阳">
      <meta itemprop="description" content="深度学习/自动驾驶/C++/性能优化">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiyang">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Profiling
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-24 22:30:52" itemprop="dateCreated datePublished" datetime="2021-08-24T22:30:52+08:00">2021-08-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-22 12:57:54" itemprop="dateModified" datetime="2023-11-22T12:57:54+08:00">2023-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Program/" itemprop="url" rel="index"><span itemprop="name">Program</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Program/Cpp/" itemprop="url" rel="index"><span itemprop="name">Cpp</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/08/24/Cpp-Profiling/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/08/24/Cpp-Profiling/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>38k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>34 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="great"><a href="#great" class="headerlink" title="great"></a>great</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.brendangregg.com/overview.html">各种性能分析工具</a></li>
<li><a target="_blank" rel="noopener" href="https://easyperf.net/">easyperf</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.xilinx.com/r/zh-CN/ug1414-vitis-ai/Vitis-AI-Profiler-%E6%9E%B6%E6%9E%84">VAI profiler</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/dendibakh/perf-book">perf-book</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/dendibakh/perf-ninja">perf-ninja</a></li>
<li><a target="_blank" rel="noopener" href="https://www.eet-china.com/mp/a196988.html">基于 CPU 性能调优的必要性和方法</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/topics/profiling">topics&#x2F;profiling</a></li>
<li><a target="_blank" rel="noopener" href="https://hhb584520.github.io/kvm_blog/files/perf/Linux_Performance_Analysis_and_Tools.pdf">Linux_Performance_Analysis_and_Tools</a></li>
<li><a target="_blank" rel="noopener" href="https://www.brendangregg.com/linuxperf.html">linuxperf</a></li>
</ol>
<span id="more"></span>

<ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/362575905">profiling 与性能优化总结</a><ul>
<li>通常在计算密集型（CPU intensive）的任务中 CPU time 会占据较大的比重，而在 I&#x2F;O 密集型（I&#x2F;O intensive）任务中 off-CPU time 会占据较大的比重。</li>
<li>我们把程序在 CPU 上执行的时间（即 user CPU time + system CPU time）称为 CPU time（或 on-CPU time），程序处于睡眠等状态的时间称为 off-CPU time（or blocked time），程序实际运行的时间称为 wall clock time（字面意思是墙上时钟的时间，也就是真实世界中流逝的时间），对于一个给定的线程：wall clock time &#x3D; CPU time + off-CPU time。</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://arthurchiao.art/blog/linux-tracing-basis-zh/">Linux tracing&#x2F;profiling 基础：符号表、调用栈、perf&#x2F;bpftrace</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/coccoc-engineering-blog/things-you-should-know-to-begin-playing-with-linux-tracing-tools-part-i-x-225aae1aaf13">Practical Linux tracing ( Part 1&#x2F;5) : symbols, debug symbols and stack unwinding</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/385519404">Perf IPC 以及 CPU 性能</a></li>
<li><a target="_blank" rel="noopener" href="https://plantegg.github.io/">plantegg’s blog</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-AI/tree/master/src/vai_runtime/vart/trace">VART trace</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-AI/tree/master/src/vai_runtime/vart/trace/vaitrace/vaitraceTools/mem_perf">vaitraceTools&#x2F;mem_perf</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.xilinx.com/r/en-US/ug1414-vitis-ai/Vitis-AI-Profiler?tocId=LjrELULUsJtA_mgGxWE2lQ">Vitis-AI-Profiler</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/445267642">linux 性能分析工具 perf：十八般武器之 cache</a></li>
<li><a target="_blank" rel="noopener" href="https://static.linaro.org/connect/yvr18/presentations/yvr18-416.pdf">Using perf On Arm platforms</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/gaogaotiantian/viztracer">viztracer</a></li>
<li>谓词替换分支， 谓词函数是一个返回布尔值的函数。</li>
<li>问 chatgpt 如何优化</li>
<li><a target="_blank" rel="noopener" href="https://tvm.hyper.ai/docs/tutorial/tensor_expr#%E7%A4%BA%E4%BE%8B-2%E4%BD%BF%E7%94%A8-te-%E6%89%8B%E5%8A%A8%E4%BC%98%E5%8C%96%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95">TVM 各种优化方法</a><ul>
<li>块操作</li>
<li>循环置换</li>
<li>向量化</li>
<li>数组打包</li>
<li>通过缓存优化块写入</li>
<li>并行化</li>
</ul>
</li>
</ol>
<h2 id="编译器选项"><a href="#编译器选项" class="headerlink" title="编译器选项"></a>编译器选项</h2><ol>
<li><p>gcc 选项顺序很重要，如果两个选项冲突，则以后一个为准。可以用<code>-O3 -fno-inline-functions</code>既使用-O3 的功能又关闭函数内嵌功能。</p>
<ul>
<li><code>-O3 -O0</code> O0 级别</li>
<li><code>-O0 -O3</code> O3 级别</li>
<li><code>-O3 -O</code> O3 级别</li>
<li><code>-O0 -O</code> O0 级别, If you use multiple -O options, with or without level numbers, the last such option is the one that is effective.</li>
</ul>
</li>
<li><p><code>-O3</code> 是编译器的优化级别选项，表示进行高级优化。这个选项告诉编译器进行更多的优化，以提高代码的执行效率。<code>-O3</code> 是最高级别的优化选项，它会启用多种优化技术，包括循环展开、函数内联、向量化等。使用 <code>-O3</code> 可以显著提高代码的执行速度，但可能会增加编译时间和可执行文件的大小。</p>
</li>
<li><p><code>-Ofast</code> enables all -O3 optimizations. It also enables optimizations that are not valid for all standard-compliant programs. It turns on -ffast-math and the Fortran-specific -fstack-arrays, unless -fmax-stack-var-size is specified, and -fno-protect-parens</p>
</li>
<li><p><code>-LNO:simd</code> 是针对 SIMD（Single Instruction Multiple Data）指令集的优化选项。SIMD 是一种并行计算的技术，它允许在同一时间执行多个数据元素的相同操作，以提高程序的并行性和性能。<code>-LNO:simd</code> 告诉编译器使用 SIMD 指令集进行优化，以利用硬件的并行能力。这可以在循环、向量操作和并行计算等方面提高程序的性能。</p>
</li>
<li><p><code>-openmp</code>可以在编译时启用 OpenMP 并行编程的支持，从而实现多线程并行执行，提高程序的性能， 需要注意的是，使用 OpenMP 进行并行编程需要在代码中添加适当的并行指令，如 #pragma omp parallel，来标识需要并行执行的代码块。同时，也需要注意线程间的同步和数据共享，以避免并发冲突和数据竞争的问题。</p>
</li>
<li><p><code>-fopenmp-simd -DSIMDE_ENABLE_OPENMP</code></p>
</li>
<li><p><code>-funroll-loops</code>强制编译器展开循环。这可能会提高某些循环密集型程序的性能，但也可能使代码体积增大。</p>
</li>
<li><p><code>-fprefetch-loop-arrays</code> 如果目标平台支持，这会在循环中为数组引用生成预取指令。</p>
</li>
<li><p><code>-march=native</code> 为当前运行编译命令的机器优化代码。这会使 GCC 产生针对你的特定 CPU 类型的代码，使用所有可用的指令集和优化。</p>
</li>
<li><p><code>-flto</code> 启用链接时间优化。这在链接时进行全程序分析，可能会产生更好的优化代码，但会增加链接时间。</p>
</li>
<li><p><code>-mfpu=neon</code> 此选项告诉编译器要为 NEON 浮点单元生成代码。这适用于较老的 ARM 架构和编译器版本。</p>
</li>
<li><p><code>-march</code> 使用此选项指定目标架构，例如<code>-march=armv8-a</code>。这可以确保编译器针对特定的 ARM 版本生成优化代码。</p>
</li>
<li><p><code>-mfloat-abi</code> 该选项定义了浮点数应该如何在函数调用中传递。有三个选项可以选择：soft、softfp 和 hard。使用 NEON 时，通常建议使用-mfloat-abi&#x3D;hard。</p>
</li>
<li><p><code>-ftree-vectorize</code> 这是一个优化选项，允许编译器自动将循环转换为使用向量指令。虽然这不是直接与 NEON 相关的，但它可以帮助自动利用 NEON 功能。</p>
</li>
<li><p><code>-fprofile-generate / -fprofile-use</code>用于基于真实数据的反馈指导优化（PGO）。首先使用-fprofile-generate 编译和运行程序来收集数据，然后使用-fprofile-use 再次编译以使用该数据进行优化。</p>
</li>
</ol>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rm -rf *<span class="variable">.gcda</span></span><br><span class="line">g++ -Ofast -fprofile-<span class="keyword">generate</span> -o prefetch prefetch<span class="variable">.cpp</span> &amp;&amp; ./prefetch</span><br><span class="line">g++ -Ofast -fprofile-<span class="keyword">use</span> -o prefetch prefetch<span class="variable">.cpp</span> &amp;&amp; ./prefetch</span><br></pre></td></tr></table></figure>

<ol>
<li><code>-DCMAKE_CXX_FLAGS=&quot;-fprofile-generate&quot;</code> 然后运行生成 gcda, 然后 <code>-DCMAKE_CXX_FLAGS=&quot;-fprofile-use&quot;</code></li>
<li><code>-fauto-profile</code> 使用 perf 来优化</li>
<li><code>软件预取技术</code>：预取技术可以减少由于缓存未命中而导致的延迟。<code>__builtin_prefetch</code> 是 GCC 的内置函数，用于预取数据到缓存。其他编译器可能有类似的指令。</li>
<li><code>-ftree-vectorize -funroll-loops</code>可以组合用</li>
</ol>
<h3 id="links"><a href="#links" class="headerlink" title="links"></a>links</h3><ol>
<li><a target="_blank" rel="noopener" href="https://gcc.gnu.org/onlinedocs/">gcc.gnu.org&#x2F;onlinedocs</a></li>
<li><a target="_blank" rel="noopener" href="https://gcc.gnu.org/onlinedocs/gcc-9.5.0/gcc/Optimize-Options.html#Optimize-Options">gcc-9.5.0 Optimize-Options</a></li>
</ol>
<h2 id="程序性能分析步骤"><a href="#程序性能分析步骤" class="headerlink" title="程序性能分析步骤"></a>程序性能分析步骤</h2><ol>
<li><code>cpufreq-set -g performance</code> 保持最大频率(频率固定好分析)</li>
<li><code>taskset -c 0 ./test</code> 固定核</li>
<li><code>perf stat -ddd ./test</code></li>
<li><code>perf top -p</code> 快速的定位热点函数</li>
<li>火焰图看各函数耗时占比</li>
<li>perf report and annotate 查看热点函数的热点代码</li>
<li>profiling table 统计代码具体时间</li>
<li>flamescope 看 hot map</li>
<li>speedscope</li>
</ol>
<h2 id="60s-操作-bpf"><a href="#60s-操作-bpf" class="headerlink" title="60s 操作 bpf"></a>60s 操作 bpf</h2><ol>
<li><p>uptime —–&gt; <code>load averages</code> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/75975041">link</a> <a target="_blank" rel="noopener" href="https://blog.51cto.com/u_15077533/4173309">link1</a></p>
<ul>
<li>Linux load averages 不仅可以用于追踪 runnable 任务，还可以跟踪不间断睡眠状态下的任务（uninterruptible sleep state）。</li>
<li>如果 1min 平均值高于 5min 或 15min 平均值，则负载正在增加, 如果 1min 平均值低于 5min 或 15min 平均值，则负载正在减少</li>
<li>如果它们高于系统 CPU 的数量，那么系统很可能会遇到性能问题（视情况而定）</li>
<li>当 load averages 首次出现在 Linux 中时，就像其他操作系统一样，它们反映了 CPU 的需求。但后来在 Linux 上将它们改为不仅包括 runnable 任务，还包括处于不间断状态的任务（TASK_UNINTERRUPTIBLE 或 nr_uninterruptible）</li>
<li>这证实了故意改变 load averages 以反映对其他系统资源的需求，而不仅仅针对于 CPU 资源。Linux 从 “CPU load averages” 变为 “system load averages”。</li>
</ul>
</li>
<li><p>dmesg -T | tail ——&gt; <code>kernal erros</code></p>
</li>
<li><p>vmstat 1 ——&gt; <code>overall stats by time</code></p>
</li>
<li><p>mpstat -P ALL 1 —–&gt; <code>CPU balance</code></p>
<ul>
<li><code>sudo apt install sysstat</code></li>
<li>可以查看多核心 cpu 中每个计算核心的统计数据；</li>
<li>Report CPU statistics.</li>
</ul>
</li>
<li><p>pidstat 1 —–&gt; <code>process usage</code></p>
<ul>
<li>可以看进程分配在哪一个 cpu 核上</li>
</ul>
</li>
<li><p>iostat -xz 1 —–&gt; <code>iostat -xz 1</code></p>
</li>
<li><p>free -m —–&gt; <code>memory usage</code></p>
<ul>
<li>man free 查看各个字段含义</li>
<li>cat &#x2F;proc&#x2F;meminfo 有更详细内存占用</li>
</ul>
</li>
<li><p>sar -n DEV 1 —–&gt; <code>network I/O</code></p>
</li>
<li><p>sar -n TCP,ETCP 1 —–&gt; <code>TCP stats</code></p>
</li>
<li><p>top —–&gt; <code>check overview</code></p>
</li>
</ol>
<h2 id="roofline"><a href="#roofline" class="headerlink" title="roofline"></a>roofline</h2><ol>
<li><a target="_blank" rel="noopener" href="https://crd.lbl.gov/assets/Uploads/ECP20-Roofline-4-cpu.pdf">roofline 数据收集方法</a></li>
<li>为什么不能达到屋顶上方？因为算出了最大 FLOPS 和最大内存带宽，有比率，假设是线性对应关系，给了算术密度，有了计算性能， 最大带宽就是在线上。不能超过线。</li>
<li>其中 x 轴表示<code>算术密度</code>（每个访问的字节所做的浮点操作数），y 轴表示性能（通常是 FLOP&#x2F;s，即每秒浮点操作数）。如果代码在带宽屋顶下方但接近于它，那么可能会受到内存带宽的限制。相反，如果代码在计算屋顶下方但接近于它，那么它可能受到计算能力的限制。</li>
<li>算术密度(FLOPs&#x2F;Byte), (速率或总量， 知道总操作数和总访问量也可以)</li>
<li>注意 FLOPS 和 Flops 区别。 FLOPS &#x3D; Flops&#x2F;s</li>
<li>转折点为最大性能，最大带宽（可由计算密度算）</li>
<li>程序算术密度点大于转折点所在算术密度就是计算密集型程序。小于则是访存密集型。</li>
<li>和 IPC 有何关联？</li>
<li>Roofline 模型讲的是程序在计算平台的算力和带宽这两个指标限制下，所能达到的理论性能上界，而不是实际达到的性能，因为实际计算过程中还有除算力和带宽之外的其他重要因素，它们也会影响模型的实际性能，这是 Roofline Model 未考虑到的。例如矩阵乘法，会因为 cache 大小的限制、GEMM 实现的优劣等其他限制，导致你几乎无法达到 Roofline 模型所定义的边界（屋顶）。</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/522007924">MegPeak——让你更懂你的处理器</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/accelerating-hpc-applications-with-nsight-compute-roofline-analysis/">Accelerating HPC Applications with NVIDIA Nsight Compute Roofline Analysis</a></li>
<li><a target="_blank" rel="noopener" href="https://crd.lbl.gov/assets/Uploads/ECP20-Roofline-1-intro.pdf">Uploads&#x2F;ECP20-Roofline-1-intro.pdf</a></li>
<li>Roofline 模型是一个可视化工具，用于表示计算系统的性能上限，并帮助识别应用程序的性能瓶颈。它通过绘制两个关键性能指标（算术密集度和峰值性能）来显示应用程序或某一计算部分的性能相对于理论峰值性能的位置。</li>
<li>确定应用程序或代码段的总浮点操作次数和所访问的内存量?</li>
<li><code>likwid-bench</code>可以算 roofline</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34204282">Roofline Model 与深度学习模型的性能分析</a></li>
</ol>
<h2 id="simd-library"><a href="#simd-library" class="headerlink" title="simd library"></a><a target="_blank" rel="noopener" href="https://www.reddit.com/r/cpp/comments/106ivke/simd_intrinsics_and_the_possibility_of_a_standard/">simd library</a></h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/google/highway">highway cpu 向量加速库 SIMD</a><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/google/highway/blob/f86369577e9f884f9156dddbf03ee786493c67f9/hwy/examples/benchmark.cc#LL245C5-L245C31">获取支持的加速硬件</a></li>
<li><code>cat /proc/cpuinfo</code> 看 flags</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://github.com/jfalcou/eve">eve</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/xtensor-stack/xsimd">xsimd</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ermig1979/Simd">图像处理与机器学习 Simd</a></li>
<li><a target="_blank" rel="noopener" href="https://en.cppreference.com/w/cpp/experimental/simd">parallelism TS v2</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/simd-everywhere/simde">simde</a></li>
</ol>
<h2 id="性能基准测试"><a href="#性能基准测试" class="headerlink" title="性能基准测试"></a>性能基准测试</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.spec.org/">spec</a> 需要 ios 文件</li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi-home/p/15981359.html">SpecCPU2017 测试 cpu 性能</a></li>
</ol>
<h2 id="sysstat"><a href="#sysstat" class="headerlink" title="sysstat"></a><a target="_blank" rel="noopener" href="https://github.com/sysstat/sysstat">sysstat</a></h2><h2 id="top"><a href="#top" class="headerlink" title="top"></a><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/af584c5a79f2">top</a></h2><ol>
<li>man top</li>
<li>? help</li>
<li>RES&#x3D;CODE+DATA 进程使用的、未被换出的物理内存大小</li>
<li>内存主要关注物理内存, 虚拟内存表示程序文件及链接库大小，并不是所有的都加载到内存</li>
<li>used mem &#x3D; total - free - buffers - cache （man free 可以看计算公式),</li>
<li>主要看 <code>avaliable</code> &lt; free + buff&#x2F;cache</li>
<li>纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到 free 中去，因此在 linux 上 free 内存会越来越少。</li>
<li>%MEM – Memory Usage (RES) A task’s currently used share of available physical memory. 当前使用的物理内存 &#x2F; 总的物理内存</li>
</ol>
<h2 id="proc-获取信息"><a href="#proc-获取信息" class="headerlink" title="proc 获取信息"></a>proc 获取信息</h2><ol>
<li><code>/proc/[PID]/stat</code></li>
</ol>
<h2 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h2><ol>
<li><p>估计模型运行帧率时需考虑： 内存耗时和计算耗时； 要搬运的内存和内存读写速度可以算出一帧的耗时</p>
</li>
<li><p><code>性能分析</code> 和 <code>性能优化</code> 两大部分。</p>
</li>
<li><p>eigen 矩阵可以向量化，Eigen::Map 问 chatgpt</p>
</li>
<li><p>矩阵乘法是计算密集型运算。为取得良好的 CPU 性能，有两个重要的优化： <a target="_blank" rel="noopener" href="https://tvm.hyper.ai/docs/tutorial/tensor_expr#%E7%A4%BA%E4%BE%8B-2%E4%BD%BF%E7%94%A8-te-%E6%89%8B%E5%8A%A8%E4%BC%98%E5%8C%96%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95">link</a></p>
<ul>
<li><code>提高内存访问的缓存命中率</code>。高缓存命中率可以加速复杂的数值计算和热点内存访问。这需要将原始内存访问模式转换为适合缓存策略的模式。</li>
<li><code>SIMD（单指令多数据）</code>，又称向量处理单元。在每个循环中，SIMD 可以处理一小批数据，而不是处理单个值。这需要将循环体中的数据访问模式转换为统一模式，以便 LLVM 后端可将其降低到 SIMD。</li>
</ul>
</li>
<li><p><code>效率 = 有效量 / 理论量 = 有效量 / (理论峰值量 * 时间) = 有效量 * fps / 理论峰值量</code></p>
</li>
<li><p>op 计算效率：根据 op 算法算出计算量 C（可用 highway 函数统计 cycle)， 测出实际耗时 t, 已知理论峰值算力 O&#x2F;s; <code>计算效率 = 计算量 / 理论计算量(峰值算力 * 实际耗时) = C / (O * t) = C * fps / O</code> ？</p>
</li>
<li><p>op io 效率 <code>io效率 = io量 / 理论io量(峰值IO * 实际耗时)</code></p>
</li>
<li><p>模型算力利用率： <code>利用率 = 模型计算量 / 理论计算量(峰值算力 * 实际耗时) = 模型计算量 * fps / 峰值算力</code></p>
</li>
<li><p>提高 cache 命中率软件方法：</p>
<ul>
<li>连续访存</li>
<li>分块</li>
</ul>
</li>
<li><p>向量处理器可以设置步幅，访问步幅确定的非连续内存也有比较高的性能</p>
</li>
<li><p>在栈上申请内存比堆快, 不是运算快 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/481687008">link</a>;</p>
</li>
<li><p>MIPS: 每秒执行了多少百万条指令。DMIPS：D 是 Dhrystone 的缩写，在 MIPS 前面加上 Dhrystone （整数运算），用于测整数计算能力。进程占用 DMIPS &#x3D; 总的 DMIPS * 进程占用 CPU 百分比</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_21475601/article/details/106564903">ARM 各内核系列整型运算能力对比—DMIPS &#x2F; MHz</a></li>
<li>A55 单核算力： 2.7DMIPS&#x2F;MHz*1.2GHz&#x3D;3.24 KDMIPS</li>
<li>评估算力： 某个平台 top（隔几秒统计一次）看各进程 cpu 占比(max, mean)，根据 cpu 占比计算进程占 DMIPS， 所有进程加起来看是否超过另外一个平台总算力</li>
</ul>
</li>
<li><p>函数计算量评估方法：</p>
<ol>
<li>假设平台的最大计算量是 M，函数运行时的 CPU 占用率是 p%，函数的计算需求 C 可以大致估计为 C &#x3D; M * p%。 然后通过函数的帧率 f 来估计每帧的计算需求：C_frame &#x3D; C &#x2F; f。</li>
</ol>
</li>
<li><p><img src="https://mmbiz.qpic.cn/sz_mmbiz_png/2icOarNW84W7BnJpVvdnUeOgJYHibeWJbd4z0KJu556ykzgnjl7MHm5YWyjWDqR7eMPmXIWSWCFy8KG3dJQD8O8A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="cpu gpu npu算力单位"></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/uTp9DXsG0pzTbyux1JgHMA">抛弃 ARM，高通第五代汽车芯片</a></p>
</li>
<li><p>芯片指令解码位宽对 IPC 有直接影响</p>
</li>
<li><p>提高性能方法： 充分利用并行， 局部性原理</p>
</li>
<li><p>并行加速：</p>
<ul>
<li><p><code>数据级并行（DLP）</code>，它的出现是因为可以同时操作许多数据项。</p>
<ul>
<li><code>指令级并行</code>: 在编译器的帮助下，利用流水线之类的思想适度开发数据级并行，利用推理执行之类的思想以中等水平开发数据级并行。</li>
<li><code>SIMD</code>： 向量体系结构和图形处理器（GPU）将单条指令并行应用于一个数据集，以开发数据级并行。</li>
</ul>
</li>
<li><p><code>任务级并行（TLP）</code>，它的出现是因为创建了一些能够单独处理但大量采用并行方式执行的工作任务。</p>
<ul>
<li><code>线程并行</code>：线程级井行在一种紧耦合硬件模型中开发数据级并行或任务级并行，这种模型允许在并行线程之间进行交互。</li>
<li><code>请求级并行</code>: 在程序员或操作系统指定的大量去耦合任务之间开发并行。</li>
</ul>
</li>
</ul>
</li>
<li><p>局部性原理</p>
<ul>
<li>时间局部性：最近访问过的内容很可能会在短期内被再次访问</li>
<li>空间局部性：地址相互临近的指令或数据很可能会在短时间内被用到</li>
</ul>
</li>
<li><p>加速比(归一化)： 原执行时间 &#x2F; 新执行时间 &#x3D; 1 &#x2F; ( (1 - 升级比例) + (升级比例&#x2F;升级加速比))；新执行时间 &#x3D; 不能加速部分 + 加速后部分 &#x3D; 不能加速部分 + 加速部分&#x2F;加速部分加速比</p>
</li>
<li><p>Amdahl 定律：根据加速比， 可以得到</p>
<ul>
<li>如果仅改进一部分计算的性能，在增加改进是，所获得的加速比增量会逐渐减小</li>
<li>加速比有最大值： 1 &#x2F; ( 1 - 升级比例)</li>
</ul>
</li>
<li><p>感知系统优化方案（从系统上分析)：</p>
<ul>
<li>整体 pipeline 调度优化: 线程优先级， 各模块多线程，异步</li>
<li>整体数据流优化： 合并前处理操作， rgba 在 rgb 转 nchw 时来做， memory_pool, zero copy</li>
<li>模型+后处理联合优化：sigmoid 在后处理做, 反算阈值，sigmoid 之前先过滤， 优化 cpu 热点代码</li>
<li>cuda 算子， neon 加速</li>
</ul>
</li>
<li><p>关注数据流，具体哪一步耗时</p>
</li>
<li><p>data packing:</p>
<ul>
<li>注意 struct 成员变量顺序，尽量减少 padding</li>
</ul>
</li>
<li><p>访存优化：</p>
<ul>
<li>连续访问</li>
<li>不要重复访问（可以先用临时变量存下来)</li>
</ul>
</li>
<li><p>软硬算法联合优化</p>
</li>
<li><p>编译器：</p>
<ul>
<li>打开编译器优化报告</li>
<li>编译器参数：-O3(启动与机器无关的优化功能) -march&#x3D;armv8.2-a(启动针对特定 CPU 系列的优化功能) -flto(启动过程间优化功能)</li>
<li>gcc -fopt-info 输出优化报告</li>
</ul>
</li>
<li><p>技术栈:</p>
<ul>
<li>第一个就是编译器，你可能不需要更深入理解编译器的具体的原理，但是你要了解编译器通用的编译优化手段，以及它有比较通用的一些编译优化的选项。</li>
<li>第二个就是 OS 的一个调度，还有一个可能 CPU 绑核。在手机上的话，绑核还是很明显的，如果是在小核上和大核，要是中核，它们也差距很多。硬件的限制。如果你想你的任务要跑特别快，比如假如一个特别重要的前台功能，你需要把你的主线程一个界面相关的线程可能就要绑定到大核上，让他跑这么快。</li>
<li>第三个在硬点上，我可能我们要比较了解 CPU 的微架构是什么样的， CPU 微架构什么样的，为什么我的代码跑的时候它就慢，慢又拆解为几类，怎么去分析它。第二个你要去可能要去尝试的去学习，怎么去读或者改这些汇编的一些指令。</li>
</ul>
</li>
<li><p>系统级性能优化通常包括两个阶段：性能剖析（performance profiling）和代码优化。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/419859575">性能静态分析（定量）</a></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/a0296d5b91bc">Parallelware Analyzer</a></li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/343408130">性能指标</a></p>
<ul>
<li>latency(延迟或响应时间)</li>
<li>throughput()</li>
<li>资源使用率 (资源：处理器，内存，IO)<ul>
<li>cpu(不大于 75%)</li>
<li>内存(不大于 80%)</li>
<li>IO(磁盘, 网络)</li>
</ul>
</li>
<li>错误率</li>
</ul>
</li>
<li><p>latency 和 throughput (延迟和吞吐量)</p>
<ul>
<li>throughput(速度？)：吞吐量一般指相当一段时间内测量出来的系统单位时间处理的任务数或事务数。如：1s 处理 10 帧图片 (10FPS)</li>
<li>latency: 执行一次任务需要的时间。如：处理一帧图片耗时 10ms</li>
<li>latency 最大值：每个节点最大耗时叠加在一起，就是整体 pipeline 的 latency 最大值，即一帧最大需要多少时间输出结果，这个 latency 值尽量越小越好；</li>
<li>目标：低延迟，高吞吐</li>
<li>提高吞吐：提升 node 处理速度或异步流水线， 异步流水可能会增加延迟（较好提升, 有两种方法)</li>
<li>降低延迟：提升 node 处理速度， 优化关键点，也会增加吞吐(容易遇见瓶颈)</li>
<li>提升 node 处理速度能够同时提高吞吐和降低延迟。</li>
</ul>
</li>
<li><p>流水线深度(硬件执行单元个数)，buffer 数量(处理多少帧)关系</p>
<ul>
<li>如果完全流水起来， buffer size 不小于流水线深度，流水线帧率由耗时最大的 node 决定: 1 &#x2F; max(node time)</li>
<li>(异步处理比较重要 queue size)</li>
<li>node 之间相互不影响，buffer size 大于流水线深度通常作用不大， 同一时刻所有 node 只能处理流水线深度的 buffer，但如果 node 之间相互影响，不好推测 buffer size 大小。</li>
<li>node 之间相互影响：buffer size 不影响其他功能越大越好</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/66933636">流水线深度</a></li>
</ul>
</li>
<li><p>提升 node 处理速度方法：</p>
<ul>
<li>减少运算量(降低算法复杂度)</li>
<li>加速库(如：硬件加速) 或更换更强硬件</li>
<li>多线程</li>
<li>减少资源申请与释放(如 memory pool, thread pool)</li>
<li>减小内存拷贝(如：零拷贝)</li>
<li>内存使用优化：如模型多个输出，申请一次大内存，偏移量来寻址。</li>
<li>空间换时间(如查表法)</li>
<li>语言特性：内联函数</li>
<li>提高 cache 命中率(如：矩阵变数组，连续访问会提高 cache 命中率)</li>
<li>改变运算方法(如 sigmoid 后再做处理，减少指数运算)</li>
</ul>
</li>
<li><p>异步方法(流水线)</p>
<ul>
<li>多线程</li>
<li>增加 buffer 数</li>
<li>调度优化</li>
<li>多流水线(pingpang)</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://bbs.huaweicloud.com/blogs/detail/222032">定位和优化程序 CPU、内存、IO 瓶颈</a></p>
<ul>
<li>两个方向：<code>提⾼运⾏速度 + 减少计算量</code></li>
<li>先建立测试<code>baseline</code></li>
<li>瓶颈点可能有多个，如果不解决最狭窄的瓶颈点</li>
</ul>
</li>
<li><p>调研性能瓶颈，如何对系统性能进行分析。</p>
</li>
<li><p>单例 perf table</p>
</li>
<li><p>计算密集型</p>
<ul>
<li>减少不必要计算</li>
</ul>
</li>
<li><p>访存密集型</p>
<ul>
<li>提高 page 和 cache 命中率</li>
<li>减少不必要访存</li>
</ul>
</li>
<li><p>IO 密集型</p>
</li>
</ol>
<h2 id="理论性能评估"><a href="#理论性能评估" class="headerlink" title="理论性能评估"></a>理论性能评估</h2><ol>
<li>理论 GPU 使用时间计算：各模型的推理耗时是单模型实测值，GPU 时间片按照各自的设计帧率（如 15Hz (fps)）× 推理耗时得到，是个纯理论计算的值。总和为各部分理论值相加，820 为理论值，这个值如果大于 1000 则系统无法达成。</li>
<li>单模型推理时间 * fps &#x3D; 模型占用 gpu 时间, 所有模型时间不能超过 1000ms;</li>
<li>有了各个模型推理时间也可以算理论最大帧率；（未考虑模型对计算资源的抢占，锁）</li>
</ol>
<h2 id="推理优化"><a href="#推理优化" class="headerlink" title="推理优化"></a><a target="_blank" rel="noopener" href="https://www.cnblogs.com/Matrix_Yao/p/13181778.html">推理优化</a></h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.6aiq.com/article/1662281420188">深度模型推理加速的术与道</a></li>
<li>减少 sigmoid 的使用(非常耗时)，可以放到后处理来做，根据 sigmoid 公式， 反算阈值，过滤之后再进行计算</li>
</ol>
<h3 id="算子融合"><a href="#算子融合" class="headerlink" title="算子融合"></a>算子融合</h3><ol>
<li><p>算子融合基于对深度学习拓扑结构模式的观察。深度学习算子按其对资源的需求可以分为两类：</p>
<ul>
<li>计算密集型算子，这些算子的时间绝大部分花在计算上，如卷积、全连接等。</li>
<li>访存密集型算子，这些算子的时间绝大部分花在访存上，他们大部分是 element-wise 算子， ReLU，eltment-wise sum。</li>
</ul>
</li>
</ol>
<h2 id="cpu-time-and-off-cpu-time"><a href="#cpu-time-and-off-cpu-time" class="headerlink" title="cpu time and off-cpu time"></a>cpu time and off-cpu time</h2><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/362575905">profiling 与性能优化总结</a></li>
</ol>
<h2 id="性能调优方法"><a href="#性能调优方法" class="headerlink" title="性能调优方法"></a>性能调优方法</h2><h3 id="PMC-Performance-Monitoring-Counters"><a href="#PMC-Performance-Monitoring-Counters" class="headerlink" title="PMC(Performance Monitoring Counters)"></a>PMC(Performance Monitoring Counters)</h3><h3 id="循环展开"><a href="#循环展开" class="headerlink" title="循环展开"></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/553771789">循环展开</a></h3><ol>
<li>计算能力（GFlops）和访存速度（MB&#x2F;s）的矛盾，在汇编语言中就是取指令（load）和计算（ALU）的矛盾。访存和计算天然是两种独立的资源，两者可以独立运行互不影响。</li>
<li>当循环次数变少，循环体增多的时候，<code>CPU在执行循环体的过程中就有了更大的操作空间进行指令调度(inline也有这个作用)</code>，在计算 a[i]的时候就可以去调度 a[i+1]相关的指令（取数据）和 a[i-1]相关的指令（存数据），因此 CPU 流水线更满载，也就提高了性能。</li>
<li>循环展开可以减少分支预测的次数</li>
<li>一般不需要手动优化，-O2 会自动展开， -O1 不会</li>
<li>perf annotate 可以看出循环有开销(判断，跳转或 index 操作)， cpu 流水线并行性低</li>
</ol>
<h3 id="分支预测"><a href="#分支预测" class="headerlink" title="分支预测"></a>分支预测</h3><ol>
<li>推理：在还不确切知道是否真的需要某一条指令时，就先执行改指令。如果预测错误，就需要清理流水线。</li>
</ol>
<h3 id="预取"><a href="#预取" class="headerlink" title="预取"></a>预取</h3><ol>
<li>数据和指令预取</li>
<li>硬件和软件预取</li>
</ol>
<h3 id="IPC-instruction-per-cycle"><a href="#IPC-instruction-per-cycle" class="headerlink" title="IPC (instruction per cycle)"></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/385519404">IPC (instruction per cycle)</a></h3><ol>
<li><code>tiptop</code></li>
<li><code>perf stat</code> 可以查看</li>
<li>当比较不同的指令集时，与使用相同芯片技术实现更复杂的指令集相比，更简单的指令集可能会导致更高的 IPC 数字。但是，更复杂的指令集可能能够以更少的指令实现更多有用的工作。</li>
<li>确定： <code>计算密集型或访存密集型</code></li>
<li>如果 IPC &lt; 1.0, 很可能是 Memory stall 占主导，可从软件和硬件两个方面考虑这个问题。软件方面：减少不必要的访存操作，提升 cache 命中率，尽量访问本地节点内存；硬件方面：增加 cache 容量，加快访存速度，提升总线带宽。<br>如果 IPC &gt; 1.0, 很可能是计算密集型的程序。可以试图减少执行指令的数量：消除不必要的工作。火焰图 CPU flame graphs，非常适用于分析这类问题。硬件方面：尝试超频、使用更多的 core 或 hyperthread。作者根据 PMU 相关的工作经验，设定了 1.0 这个阈值，用于区分访存密集型(memory-bound)和计算密集型(cpu-bound)程序。读者可以根据自己的实际工作平台，合理调整这个阈值。</li>
<li><a target="_blank" rel="noopener" href="https://www.brendangregg.com/blog/2017-05-09/cpu-utilization-is-wrong.html">cpu-utilization-is-wrong</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/364661188?utm_source=zhihu&utm_medium=social&utm_oi=26748628500480">CPU 最高性能预估之“理论最大 IPC”</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/385519404">IPC 测试，可以预估最大 IPC</a></li>
<li>ipc 是指每个 core 的 IPC</li>
<li><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1517979">用 CPI 火焰图分析 Linux 性能问题</a> 使用 CPI 火焰图，可以很方便地做 CPU 利用率的分析，找到和定位引发 CPU 停顿的函数。一旦找到相关的函数，就可以通过 perf annotate 命令对引起停顿的指令作出进一步确认。</li>
</ol>
<h3 id="CPI-Cycle-Per-Instruction"><a href="#CPI-Cycle-Per-Instruction" class="headerlink" title="CPI(Cycle Per Instruction)"></a>CPI(Cycle Per Instruction)</h3><h3 id="绑核"><a href="#绑核" class="headerlink" title="绑核"></a>绑核</h3><ol>
<li>taskset</li>
<li><code>taskset -c 3,5 firefox</code></li>
<li>taskset 超出核心数程序可能更快， why?</li>
</ol>
<h3 id="memory-bound"><a href="#memory-bound" class="headerlink" title="memory bound"></a>memory bound</h3><h3 id="SSE（Streaming-SIMD-Extensions）"><a href="#SSE（Streaming-SIMD-Extensions）" class="headerlink" title="SSE（Streaming SIMD Extensions）"></a>SSE（Streaming SIMD Extensions）</h3><h3 id="SVE-Scalable-Vector-Extension"><a href="#SVE-Scalable-Vector-Extension" class="headerlink" title="SVE(Scalable Vector Extension)"></a>SVE(Scalable Vector Extension)</h3><ol>
<li>是 arm AArch64 架构下的下一代 SIMD 指令集，旨在加速高性能计算，SVE 引入了很多新的架构特点</li>
</ol>
<h3 id="多发射处理器"><a href="#多发射处理器" class="headerlink" title="多发射处理器"></a>多发射处理器</h3><ol>
<li>多发射处理器相对于向量处理器的潜在优势在于它们能够从结构化程度较低的代码中提取某些并行，以及能够很轻松地缓存所有形式的数据。因为这些原因，<code>多发射方法已经成为利用指令级并行的主要方法</code>，而向量主要作为这些处理器的扩展。</li>
<li>目标就是允许在一个时钟周期中发射多条指令。多发射处理器主要有以下 3 类。</li>
</ol>
<h4 id="静态调度超标量处理器"><a href="#静态调度超标量处理器" class="headerlink" title="静态调度超标量处理器"></a>静态调度超标量处理器</h4><ol>
<li>由于静态调度超标量的收益会随着发射宽度的增长而逐渐减少，所以静态调度超标量主要用于发射宽度较窄的情况，通常仅有两条指令</li>
<li>大多属于嵌入式领域， MiPS 和 ARM ，包括 ARM Cortex-A8</li>
</ol>
<h4 id="VLIW-超长指令字-处理器"><a href="#VLIW-超长指令字-处理器" class="headerlink" title="VLIW( 超长指令字)处理器"></a>VLIW( 超长指令字)处理器</h4><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/337749676">计算机指令集架构 – 超长指令字（VLIW）</a></li>
<li>大多数属于信号处理领域，比如 TI C6x</li>
</ol>
<h4 id="动态调度超标量处理器"><a href="#动态调度超标量处理器" class="headerlink" title="动态调度超标量处理器"></a>动态调度超标量处理器</h4><ol>
<li>Intel Core i3 、i5 ， i7. AMD Phenom, IBM Power7</li>
</ol>
<h3 id="cache"><a href="#cache" class="headerlink" title="cache"></a>cache</h3><ol>
<li>LLC: last level cache 最后一级缓存，比较关键</li>
</ol>
<h3 id="提高-cache-性能"><a href="#提高-cache-性能" class="headerlink" title="提高 cache 性能"></a>提高 cache 性能</h3><p>处理器的缓存（通常是 L1、L2 和 L3）旨在减少从主内存访问数据所需的时间。它们存储了最近或经常访问的数据副本，从而提高了数据访问速度。为了充分利用缓存并提高程序性能，你可以遵循以下一些方法和建议：</p>
<ol>
<li><strong>局部性原理</strong>：<ul>
<li><strong>时间局部性</strong>：如果某个数据项被访问，那么在近期它可能再次被访问。</li>
<li><strong>空间局部性</strong>：如果某个数据项被访问，那么它附近的数据项也可能会很快被访问。<br>为了利用这种局部性，尝试在连续的内存地址上组织和访问数据（例如，使用数组而不是链表）。</li>
</ul>
</li>
<li><strong>避免伪共享</strong>：确保并发运行的线程访问的数据不位于同一缓存行上，因为这可能会导致缓存无效并减慢性能。</li>
<li><strong>数据对齐</strong>：确保数据结构按照缓存行大小进行对齐，这可以减少跨多个缓存行的数据访问。</li>
<li><strong>预取策略</strong>：如果可能，尝试预测下一次需要的数据并预先加载它。一些编译器和硬件支持数据预取指令。</li>
<li><strong>减少缓存失效</strong>：<ul>
<li>将常用的数据放在一起。</li>
<li>避免大的数据结构，它们可能会频繁地导致缓存失效。</li>
<li>在可能的情况下，使用更小的数据类型。</li>
</ul>
</li>
<li><strong>循环分块&#x2F;循环重排</strong>：这是一种技术，可以将大的循环重组为更小的块，从而更好地适应缓存。这尤其适用于多层嵌套的循环。</li>
<li><strong>避免不必要的写回操作</strong>：只在数据确实更改时写入，以减少不必要的写回到主内存。</li>
<li><strong>使用只读和常量数据</strong>：如果数据不需要更改，将其标记为常量可以帮助编译器进行优化。</li>
<li><strong>控制数据的分配和布局</strong>：例如，在 C++中，你可以使用自定义分配器来控制对象在内存中的位置。</li>
<li><strong>利用非统一内存访问 (NUMA) 架构</strong>：在多处理器系统上，确保线程尽可能在与其数据最近的处理器上运行。</li>
<li><strong>监控和剖析</strong>：使用工具（如<code>perf</code>、<code>VTune</code>等）来分析你的程序，找出缓存失效的热点，并对它们进行优化。</li>
</ol>
<h4 id="cache-line"><a href="#cache-line" class="headerlink" title="cache line"></a><a target="_blank" rel="noopener" href="https://plantegg.github.io/2021/05/16/CPU_Cache_Line%E5%92%8C%E6%80%A7%E8%83%BD/">cache line</a></h4><ol>
<li>一般 size 64 byte (512bit)</li>
<li><code>getconf -a | grep CACHE</code> 查看各级 cache line size</li>
<li><code>lscpu -C</code></li>
<li><code>likwid-topology</code>显示有关硬件拓扑的详细信息，例如 CPU、缓存、NUMA 域等。</li>
</ol>
<h4 id="cache-一致性"><a href="#cache-一致性" class="headerlink" title="cache 一致性"></a>cache 一致性</h4><ol>
<li><a target="_blank" rel="noopener" href="https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm">在线体验 MESI 协议状态转换</a></li>
<li><a target="_blank" rel="noopener" href="https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm">cache 相关动画</a></li>
</ol>
<h4 id="cache-miss"><a href="#cache-miss" class="headerlink" title="cache miss"></a>cache miss</h4><ol>
<li>应用程序的读占比越高，对缓存越友好；访问的字长越大对预取越友好；同等数量的指令内存依赖越低，CPI 会越高。</li>
<li><code>sudo perf stat -d -d -d -a -- sleep 10</code></li>
<li><code>sudo perf stat -e cache-misses ls</code></li>
<li><code>sudo cachestat-bpfcc 2</code></li>
<li><code>sudo cachetop-bpfcc</code></li>
</ol>
<h4 id="prefetch"><a href="#prefetch" class="headerlink" title="prefetch"></a>prefetch</h4><ol>
<li>预取是一种优化技术，它允许 CPU 提前加载将要访问的数据到缓存中，以便在实际访问数据时可以更快地获得它。预取可以减少由于缓存未命中引起的等待时间。</li>
<li>硬件预取：现代 CPU 已经有自己的硬件预取策略。在某些情况下，手动的预取可能会与硬件的预取策略发生冲突，导致性能下降。</li>
<li><code> __builtin_prefetch(&amp;data[i + 16], 0, 1);  // 预取下一个将要访问的数据</code></li>
</ol>
<h4 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h4><ol>
<li>伪共享发生在以下情况下：<ul>
<li>两个或多个处理器核心在它们各自的本地缓存中读&#x2F;写不同的变量。</li>
<li>这些变量恰好位于同一缓存行中。</li>
</ul>
</li>
<li>避免：<ul>
<li>数据对齐：确保经常由不同线程访问的数据在不同的缓存行上。许多编译器和平台都提供数据对齐指令或属性。</li>
<li>填充：在数据结构中添加填充，使每个线程访问的数据元素都有一个完整的缓存行。</li>
<li>局部变量：尽量使用线程的局部变量，因为它们通常存储在栈上，并且不太可能与其他线程的变量共享缓存行。</li>
<li>避免细粒度并行：如果任务太小，线程间的同步和伪共享可能会抵消并行处理的好处。</li>
</ul>
</li>
<li>sample, 避免伪共享更快</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;chrono&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> Clock = std::chrono::steady_clock;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __TIC__(tag) auto __##tag##_start_time = Clock::now();</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __TOC__(tag)                                                           \</span></span><br><span class="line"><span class="meta">  auto __##tag##_end_time = Clock::now();                                      \</span></span><br><span class="line"><span class="meta">  std::cout &lt;&lt; #tag &lt;&lt; <span class="string">&quot; : &quot;</span>                                                   \</span></span><br><span class="line"><span class="meta">            <span class="string">&lt;&lt; std::chrono::duration_cast&lt;std::chrono::microseconds&gt;</span>(          \</span></span><br><span class="line"><span class="meta">                   __##tag##_end_time - __##tag##_start_time)                  \</span></span><br><span class="line"><span class="meta">                   .count()                                                    \</span></span><br><span class="line"><span class="meta">            &lt;&lt; <span class="string">&quot;us&quot;</span> &lt;&lt; std::endl;</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ITERATIONS 1000000000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 伪共享情况</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SharedData</span> &#123;</span><br><span class="line">  <span class="type">long</span> value1;</span><br><span class="line">  <span class="type">long</span> value2;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 避免伪共享的情况</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">PaddedData</span> &#123;</span><br><span class="line">  <span class="type">long</span> value1;</span><br><span class="line">  <span class="type">char</span> padding[<span class="number">64</span>]; <span class="comment">// 通常缓存行的大小为64字节</span></span><br><span class="line">  <span class="type">long</span> value2;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">updateValue1</span><span class="params">(SharedData *data)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">long</span> i = <span class="number">0</span>; i &lt; ITERATIONS; i++) &#123;</span><br><span class="line">    data-&gt;value1 += i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">updateValue2</span><span class="params">(SharedData *data)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">long</span> i = <span class="number">0</span>; i &lt; ITERATIONS; i++) &#123;</span><br><span class="line">    data-&gt;value2 += i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  SharedData data;</span><br><span class="line">  __TIC__(TEST)</span><br><span class="line">  <span class="function">std::thread <span class="title">t1</span><span class="params">(updateValue1, &amp;data)</span></span>;</span><br><span class="line">  <span class="function">std::thread <span class="title">t2</span><span class="params">(updateValue2, &amp;data)</span></span>;</span><br><span class="line">  t1.<span class="built_in">join</span>();</span><br><span class="line">  t2.<span class="built_in">join</span>();</span><br><span class="line">  __TOC__(TEST)</span><br><span class="line"></span><br><span class="line">  PaddedData paddedData;</span><br><span class="line">  __TIC__(TEST_WITH_PADDING)</span><br><span class="line">  <span class="function">std::thread <span class="title">t3</span><span class="params">([&amp;paddedData] &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">for</span> (<span class="type">long</span> i = <span class="number">0</span>; i &lt; ITERATIONS; i++) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">      paddedData.value1 += i;</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;)</span></span>;</span><br><span class="line">  <span class="function">std::thread <span class="title">t4</span><span class="params">([&amp;paddedData] &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">for</span> (<span class="type">long</span> i = <span class="number">0</span>; i &lt; ITERATIONS; i++) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">      paddedData.value2 += i;</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;)</span></span>;</span><br><span class="line">  t3.<span class="built_in">join</span>();</span><br><span class="line">  t4.<span class="built_in">join</span>();</span><br><span class="line">  __TOC__(TEST_WITH_PADDING)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><ol>
<li>Release 模式编译</li>
<li>看 cpu 使用率 log 重定向到&#x2F;dev&#x2F;null。 <code>&gt; /dev/null 2&gt;&amp;1</code></li>
<li>log 重定向到文件, 不要打印到 stdout<ul>
<li><code>&gt; output.log 2&gt;&amp;1</code> this will redirect both STDOUT and STDERR to the file.</li>
<li><code>2&gt;&amp;1 &gt; output.log</code> the old STDOUT will be saved (copied) in STDERR and then STDOUT will be redirected to file. So, stdout will go to file and stderr will go to console.</li>
<li><code>2&gt;&amp;1 | tee output.log</code> both streams will be redirected to tee. Tee will duplicate any input to its stdout (the console in your case) and to file (output.log).</li>
</ul>
</li>
<li>GPU 函数耗时统计不能只记录一次的，GPU 可能做一些准备工作，教训： nppiResize_8u_C3R 不管大小第一次运行耗时都很大 The cuda context is lazily initialized</li>
<li>-O3 测试</li>
<li>perf stat .&#x2F;xxx 测试程序运行时间</li>
</ol>
<h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><h3 id="likwid"><a href="#likwid" class="headerlink" title="likwid"></a><a target="_blank" rel="noopener" href="https://github.com/RRZE-HPC/likwid.git">likwid</a></h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/RRZE-HPC/likwid/wiki/AddARMSupport">AddARMSupport</a></li>
<li><code>likwid-topology -V 3</code>打开 debug 信息</li>
<li><a target="_blank" rel="noopener" href="https://github.com/RRZE-HPC/likwid/tree/master/groups">各平台各性能指标计算方法</a> 需要配合<a target="_blank" rel="noopener" href="https://github.com/RRZE-HPC/likwid/wiki/ARM-A57">event</a></li>
<li><code>likwid-perfctr -e</code> 查看 event</li>
<li><code>likwid-perfctr -a</code>查看支持的 group</li>
<li><a target="_blank" rel="noopener" href="https://docs.nersc.gov/tools/performance/likwid/">userguide</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.rwth-aachen.de/hpc_import_20210107/attachments/20056127/24117298.pdf">tutorial1</a></li>
<li><a target="_blank" rel="noopener" href="https://www.vi-hps.org/cms/upload/material/tw09/vi-hps-tw09-VI-HPS_likwid.pdf">tutorial</a></li>
<li><code>sudo apt install likwid</code></li>
<li>源码编译时需要修改 config.mk 的 COMPILER 字段; For ARM builds, the COMPILER flag in config.mk needs to changed to GCCARMv8 or ARMCLANG (experimental).</li>
<li><code>likwid-topology</code>显示有关硬件拓扑的详细信息，例如 CPU、缓存、NUMA 域等。</li>
<li><code>likwid-bench</code>可以算 roofline; likwid-bench: Micro benchmarking platform for CPU architectures</li>
<li><code>likwid-perfscope</code>: Frontend to the timeline mode of likwid-perfctr, plots live graphs of performance metrics using gnuplot</li>
<li><a target="_blank" rel="noopener" href="https://github.com/RRZE-HPC/likwid/wiki/Tutorial%3A-Empirical-Roofline-Model">Tutorial Empirical-Roofline-Model</a><ul>
<li><code>sudo apt intall gnuplot</code></li>
<li><code>gnuplot plotscript.gp</code></li>
</ul>
</li>
<li><code>cat /proc/cpuinfo</code> part 不一定支持， topology.h 中查看</li>
</ol>
<h3 id="gprof"><a href="#gprof" class="headerlink" title="gprof"></a><a target="_blank" rel="noopener" href="http://www.tastones.com/stackoverflow/c++/profiling/profiling_with_gcc_and_gprof/">gprof</a></h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/jrfonseca/gprof2dot">gprof2dot</a></li>
<li><a target="_blank" rel="noopener" href="https://jasonblog.github.io/note/ncku_embededd/tong_xue_li_yong_gprof2dot_gong_ju_ff0c_jiang_zui_.html">link</a></li>
</ol>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">- <span class="keyword">g</span>++ -pg ... -o xxx (<span class="keyword">Note</span>: <span class="keyword">do</span> not <span class="keyword">use</span> -<span class="keyword">g</span>)</span><br><span class="line">- ./xxx</span><br><span class="line">- gprof -b ./xxx gmon.<span class="keyword">out</span> &gt; xxx.<span class="keyword">log</span></span><br><span class="line">-  gprof ./xxx gmon.<span class="keyword">out</span> | less</span><br><span class="line"></span><br><span class="line">sudo pip install gprof2dot</span><br><span class="line">gprof ./xxx | gprof2dot | dot -Tpng -o <span class="keyword">report</span>.png</span><br><span class="line">gprof ./xxx | gprof2dot | dot -Tsvg -o <span class="keyword">report</span>.svg</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span>(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -pg&quot;</span>)</span><br><span class="line"><span class="keyword">SET</span>(CMAKE_EXE_LINKER_FLAGS <span class="string">&quot;$&#123;CMAKE_EXE_LINKER_FLAGS&#125; -pg&quot;</span>)</span><br><span class="line"><span class="keyword">SET</span>(CMAKE_SHARED_LINKER_FLAGS <span class="string">&quot;$&#123;CMAKE_SHARED_LINKER_FLAGS&#125; -pg&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="google-perftools"><a href="#google-perftools" class="headerlink" title="google-perftools"></a>google-perftools</h3><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- <span class="keyword">g</span>++ -O3 -o <span class="keyword">test</span> <span class="keyword">test</span>.<span class="keyword">cc</span> -lprofiler</span><br><span class="line">- LD_PRELOAD=/usr/<span class="keyword">local</span>/lib/libprofiler.<span class="keyword">so</span> CPUPROFILE=<span class="keyword">test</span>.prof ./<span class="keyword">test</span></span><br><span class="line">- google-pprof ./<span class="keyword">test</span> <span class="keyword">test</span>.prof --svg &gt; <span class="keyword">test</span>.svg</span><br></pre></td></tr></table></figure>

<h3 id="valgrind"><a href="#valgrind" class="headerlink" title="valgrind"></a>valgrind</h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/31382177">valgrind + massif-visualizer 看内存占用</a></li>
</ol>
<h4 id="cachegrind"><a href="#cachegrind" class="headerlink" title="cachegrind"></a>cachegrind</h4><ol>
<li>cachegrind：分析 CPU 的 cache 命中率、丢失率，用于进行代码优化。</li>
<li><code>valgrind --tool=cachegrind --branch-sim=yes ls</code></li>
<li><code>cg_annotatel(callgrind_annotate) cachegrind.out.88431</code> 各模块 cache 统计</li>
<li><code>cg_annotatel(callgrind_annotate) cachegrind.out.88431 file</code> 统计 file 每一行 cache 情况, 可以看出 O3 比 O1 cache 优化了</li>
<li><a target="_blank" rel="noopener" href="https://jaist.dl.sourceforge.net/project/qcachegrindwin/0.7.4/">qcachegrindwin 分析生成文件</a></li>
<li>Kcachegrind GUI 显示分析生成的文件</li>
</ol>
<h4 id="callgrind"><a href="#callgrind" class="headerlink" title="callgrind"></a><a target="_blank" rel="noopener" href="https://learnku.com/articles/46663">callgrind</a></h4><ol>
<li>callgrind</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">valgrind –tool=callgrind ./tmp</span><br><span class="line">callgrind_annotate callgrind.out.XXX</span><br><span class="line">gprof2dot.py -f callgrind callgrind.out.XXX |dot -Tpng -o report.png</span><br></pre></td></tr></table></figure>

<h3 id="pmu-tools"><a href="#pmu-tools" class="headerlink" title="pmu-tools"></a><a target="_blank" rel="noopener" href="https://github.com/andikleen/pmu-tools">pmu-tools</a></h3><h3 id="good-pprof"><a href="#good-pprof" class="headerlink" title="(good)pprof"></a><a target="_blank" rel="noopener" href="https://github.com/google/pprof">(good)pprof</a></h3><ol>
<li><code>-g</code>和<code>sudo</code>可能有问题</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo perf record -F 99 -a -g -- ./bandwidth64</span><br><span class="line">pprof -svg perf.data</span><br></pre></td></tr></table></figure>

<ol>
<li>perf 结果可视化</li>
<li><a target="_blank" rel="noopener" href="https://github.com/google/pprof/blob/main/doc/README.md">readme</a></li>
<li>与 google-pprof 不是一个工具</li>
<li><a target="_blank" rel="noopener" href="https://github.com/google/perf_data_converter">需要编译 perf_data_converter</a><ul>
<li><code>cp  bazel-bin/src/perf_to_profile ~/go/bin</code></li>
</ul>
</li>
</ol>
<h3 id="gprof2dot"><a href="#gprof2dot" class="headerlink" title="gprof2dot"></a><a target="_blank" rel="noopener" href="https://github.com/jrfonseca/gprof2dot">gprof2dot</a></h3><ol>
<li>可类似 gprof 将 perf 结果生成调用图</li>
<li><code>perf script | c++filt | gprof2dot.py -f perf | dot -Tpng -o output.png</code></li>
</ol>
<h2 id="perf"><a href="#perf" class="headerlink" title="perf"></a><a target="_blank" rel="noopener" href="https://billtian.github.io/digoal.blog/2016/11/27/01.html">perf</a></h2><ol>
<li><code>-vvv</code>打印调试信息</li>
<li><code>perf stat --all-cpus --no-aggr ls</code>查看每一个 cpu 统计</li>
<li><a target="_blank" rel="noopener" href="https://gaomf.cn/2019/10/30/perf_stack_traceback/">使用 perf 进行性能分析时如何获取准确的调用栈</a></li>
<li><a target="_blank" rel="noopener" href="https://www.brendangregg.com/perf.html">good examples</a></li>
<li>perf 是性能分析的必备工具, 它最核心的能力是能访问硬件上的 Performance Monitor Unit (PMU), 对分析 CPU bound 的问题很有帮助, 当然 perf 也支持各种软件 event.</li>
</ol>
<h3 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a>源码安装</h3><ol>
<li></li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --depth=1 https://github.com/torvalds/linux.git</span><br><span class="line"><span class="built_in">cd</span> tools/perf/</span><br><span class="line">make -j4</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><a target="_blank" rel="noopener" href="https://www.cs.rice.edu/~la5/doc/perf-doc/de/df8/builtin-record_8c.html">docxgen</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/freelancer-leon/notes/blob/master/kernel/profiling/perf.md">原理解析</a></li>
</ol>
<h3 id="perf-event"><a href="#perf-event" class="headerlink" title="perf_event"></a>perf_event</h3><ol>
<li><code>strace perf stat ./test</code>strace 跟踪<code>perf_event_open</code>看 type 和 config</li>
<li>可 c++编程</li>
<li>在 Linux perf events 中，确实存在对同时使用的 raw events 的数量限制。这是因为硬件计数器的数量是有限的。当超过硬件性能计数器的数量时，需要使用复用(multiplexing)来统计所有事件。</li>
<li>raw counter 不管是 bash 还是 c++都有个数限制，需要分时复用，有没有方法计算到利用的时间？</li>
<li><code>perf stat -vvv ./test</code>可以看 perf_event_attr 配置</li>
</ol>
<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><ol>
<li><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/100442/0100/debug-descriptions/pmu/pmu-events?lang=en">arm55 pmu 手册</a></li>
<li>列出 event</li>
<li><code>likwid-perfctr -e</code> 列出所有 PMC</li>
<li><code>likwid-perfctr -e | grep MEM</code>列出所有内存相关 PMC, <code>perf stat -e r013,r066,r067</code> r + mask + eventsel 监控对应事件</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">nvidia@miivii-tegra:~$ likwid-perfctr -e | grep MEM</span><br><span class="line">MEM_ACCESS, 0x13, 0x0, PMC</span><br><span class="line">MEMORY_ERROR, 0x1A, 0x0, PMC</span><br><span class="line">MEM_ACCESS_LD, 0x66, 0x0, PMC</span><br><span class="line">MEM_ACCESS_ST, 0x67, 0x0, PMC</span><br><span class="line"></span><br><span class="line">nvidia@miivii-tegra:~$ perf <span class="built_in">stat</span> -e r013,r066,r067 -- <span class="built_in">ls</span></span><br><span class="line">Desktop  Documents  Downloads  Music  Pictures  Public  Templates  Videos</span><br><span class="line"></span><br><span class="line"> Performance counter stats <span class="keyword">for</span> <span class="string">&#x27;ls&#x27;</span>:</span><br><span class="line"></span><br><span class="line">           156,045      r013:u</span><br><span class="line">           118,079      r066:u</span><br><span class="line">            37,966      r067:u</span><br><span class="line"></span><br><span class="line">       0.003111539 seconds time elapsed</span><br><span class="line"></span><br><span class="line">       0.003294000 seconds user</span><br><span class="line">       0.000000000 seconds sys</span><br></pre></td></tr></table></figure>

<h4 id="record"><a href="#record" class="headerlink" title="record"></a>record</h4><ol>
<li><code>perf record ./test</code></li>
<li><code>perf record -e LLC-load-misses</code> 只记录某个热点，可生成火焰图</li>
<li>perf record 对可以同时记录的事件数量有限制。这个限制由硬件性能监视器计数器（hardware performance monitor counters）决定。</li>
<li>多进程也不行， 开多个实例记录会不准，flopsc, bandwidth 可以用来验证是否准确</li>
<li><code>likwid-perfctr -e</code>可以查看支持的 PMC 个数</li>
</ol>
<h4 id="report"><a href="#report" class="headerlink" title="report"></a>report</h4><h4 id="script"><a href="#script" class="headerlink" title="script"></a>script</h4><ol>
<li><code>perf script -v</code> -v 查看调试信息</li>
</ol>
<h4 id="stat"><a href="#stat" class="headerlink" title="stat"></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/385519404">stat</a></h4><ol>
<li><code>perf stat -I 1000 -a sleep 10</code> -I 1000 每隔 1000ms 输出一次</li>
<li><code>CPUs utilized = task_clock / 总时间</code> task_clock 统计所有核的无意义，肯定是 1; 统计单个程序的才有意义; 可以测量一个程序对 cpu 利用率， sleep 的时间会去掉</li>
<li><code>频率 = cpu_cycles / cpu_clock or task_clock time</code>多核不准</li>
<li><code>perf stat -ddd -- ./test</code> 可以查看 cpu 运行频率，运行 cycle 数，指令数, 程序运行时间</li>
<li>性能有一些损耗，影响不大（-ddd 打开细节越多损失越大）</li>
<li><code>sudo perf stat -a -- sleep 10</code></li>
<li>不计算分布，仅仅进行统计, 可以看总体性能(IPC 等)</li>
<li><code>sudo perf stat -d -d -d -a -- sleep 10</code></li>
<li><code>sudo perf stat -e cache-misses ls</code></li>
<li>可以查看 CPU 真实利用率： CPUs utilized, 不包括等待时间，自旋时间等。真实利用率比 top 查看的利用率要低很多。</li>
<li>top 查看的利用率： 如果 CPU 没有运行在内核的 idle 线程，就认为 CPU 在被使用。当 cpu 阻塞并等待内存访问时，也可能显示较高的利用率。</li>
</ol>
<h4 id="annotate"><a href="#annotate" class="headerlink" title="annotate"></a><a target="_blank" rel="noopener" href="https://developer.ibm.com/tutorials/l-analyzing-performance-perf-annotate-trs/">annotate</a></h4><ol>
<li>将热点函数精确到代码行，用于对问题进行精确定位。</li>
<li>perf report 可以选中 sympol, 按快捷键 a</li>
<li>h 显示快捷键</li>
<li>k 显示行号</li>
<li><tab> Cycle thru hottest instructions</li>
<li>t Circulate percent, total period, samples view</li>
<li>Cross-arch annotate: 需要 vmlinux</li>
<li><a target="_blank" rel="noopener" href="https://ctf-wiki.org/pwn/linux/kernel-mode/environment/build-kernel/">build-kernel</a></li>
<li><a target="_blank" rel="noopener" href="https://phoenixnap.com/kb/build-linux-kernel">build-linux-kernel</a></li>
<li><a target="_blank" rel="noopener" href="https://patchwork.ozlabs.org/project/linuxppc-dev/patch/1474472876-2706-2-git-send-email-ravi.bangoria@linux.vnet.ibm.com/">cross arch</a></li>
</ol>
<h4 id="list-1"><a href="#list-1" class="headerlink" title="list"></a>list</h4><ol>
<li>查看支持的 events</li>
<li><code>perf stat -e</code>查看 events</li>
<li><code>strace perf stat</code>strace 跟踪系统调用</li>
</ol>
<h4 id="top-1"><a href="#top-1" class="headerlink" title="top"></a>top</h4><ol>
<li>我们知道 perf top 是通过读取 PMU 的 PC 寄存器来获取当前执行的指令进而根据汇编的 symbol 信息获得是执行的哪条指令。</li>
<li>能够快速的定位热点函数</li>
<li>(只统计栈顶)可以看到具体函数占用 cpu 比例，与火焰图从上往下看，越宽的函数占比越高，被遮盖的函数占比少</li>
<li>lib 不能被 strip， 否则函数名显示地址</li>
<li>perf top -p xxxx<ul>
<li>perf top -p 23015,32476 &#x2F;&#x2F; 查看这两个进程的 cpu cycles 使用情况</li>
<li>perf top &#x2F;&#x2F; 默认配置</li>
<li>perf top -G &#x2F;&#x2F; 得到调用关系图</li>
<li>perf top -e cycles &#x2F;&#x2F; 指定性能事件</li>
<li>perf top -s comm,pid,symbol &#x2F;&#x2F; 显示调用 symbol 的进程名和进程号</li>
<li>perf top –comms nginx,top &#x2F;&#x2F; 仅显示属于指定进程的符号</li>
<li>perf top –symbols kfree &#x2F;&#x2F; 仅显示指定的符号</li>
</ul>
</li>
</ol>
<h4 id="mem"><a href="#mem" class="headerlink" title="mem"></a>mem</h4><h3 id="hotspot"><a href="#hotspot" class="headerlink" title="hotspot"></a><a target="_blank" rel="noopener" href="https://github.com/KDAB/hotspot">hotspot</a></h3><ol>
<li>the Linux perf GUI for performance analysis</li>
<li><code>sudo apt install hotspot</code></li>
<li><code>sudo strip --remove-section=.note.ABI-tag /usr/lib/x86_64-linux-gnu/libQt5Core.so.5</code></li>
<li><code>sudo perf record -F 99 -p 81163 --call-graph dwarf -- sleep 60</code></li>
</ol>
<h3 id="pyroscope"><a href="#pyroscope" class="headerlink" title="pyroscope"></a><a target="_blank" rel="noopener" href="https://github.com/grafana/pyroscope">pyroscope</a></h3><h3 id="speedscope"><a href="#speedscope" class="headerlink" title="speedscope"></a><a target="_blank" rel="noopener" href="https://github.com/jlfwong/speedscope">speedscope</a></h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.speedscope.app/">在线网页</a></li>
<li>需要 perf script 后的 unfold(可以显示各个线程结果) 或 fold(显示整体结果, 有些信息缺失) 文件， 不是原始文件</li>
<li>页面上边中间可选择具体线程来看占用时间</li>
<li>time order: 时间变化</li>
<li>left heavy: 类似火焰图</li>
<li>Sandwidth: 占用时间比例，及调用栈</li>
<li>点击符号可以看到在哪个动态库中，助于调试</li>
<li>调用堆栈按照它们在输入文件中出现的顺序从左到右排列，这通常是安排它们被记录的时间顺序。这个视图对于理解应用程序随时间变化的行为非常有帮助，比如 “首次从数据库获取到数据，然后为序列化准备数据，数据被序列化为 JSON”。</li>
<li>可以用来看调用关系</li>
<li>调用栈过长可以上下滚动滑轮</li>
</ol>
<h3 id="flamescope"><a href="#flamescope" class="headerlink" title="flamescope"></a><a target="_blank" rel="noopener" href="https://github.com/Netflix/flamescope">flamescope</a></h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.brendangregg.com/blog/2018-11-08/flamescope-pattern-recognition.html">flamescope recognition</a></li>
<li><a target="_blank" rel="noopener" href="https://netflixtechblog.com/netflix-flamescope-a57ca19d47bb">netflix-flamescope</a></li>
<li>heatmap + flamegraph</li>
<li>需要 npm install</li>
<li>将生成的 perf 文件 copy 到 examples 目录下</li>
<li>可以看 pagefault</li>
<li>perf 可以看 all， 也可以看单独进程</li>
<li>斜线可以大概分辨出程序帧率，因为周期性活动</li>
<li>为什么以 49 赫兹采样？因为 50 赫兹可能会与定时活动同步进行采样，并且计数过高或过低。为什么一开始大约是 50 赫兹？它不太慢也不太快。太慢了，我们没有足够的样本来绘制 FlameScope 的 50 行热图（行数可以更改）。太快和采样的开销会减慢应用程序。</li>
<li>注意显示火焰图时 url 会显示时间区间</li>
</ol>
<h3 id="火焰图"><a href="#火焰图" class="headerlink" title="火焰图"></a><a target="_blank" rel="noopener" href="https://github.com/brendangregg/FlameGraph">火焰图</a></h3><ol>
<li><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1517979">用 CPI 火焰图分析 Linux 性能问题</a> 使用 CPI 火焰图，可以很方便地做 CPU 利用率的分析，找到和定位引发 CPU 停顿的函数。一旦找到相关的函数，就可以通过 perf annotate 命令对引起停顿的指令作出进一步确认。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.slideshare.net/brendangregg/usenix-atc-2017-visualizing-performance-with-flame-graphs">作者 slice</a></p>
</li>
<li><p>可以跑多次，看看优化效果</p>
</li>
<li><p>开发板交叉编译 perf，或者找相同 aarch 机器，copy。perf 之后将结果 copy 到开发机生成火焰图</p>
</li>
<li><p>release 模式显示不全，debug 模式更全,可能是 release 符号被保护了？因为 release 模式用到的库被 strip 了</p>
</li>
<li><p>库不能 strip</p>
</li>
<li><p>函数名可能被 mangle，需要 demangle <code>./stackcollapse-perf.pl data.unfold | c++filt &gt; data.folded</code></p>
</li>
<li><p>If you are profiling C++ code, you may want to pipe stacks through c++filt to get readable frames.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/flamegraph-rs/flamegraph">flamegraph-rust</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.infoq.cn/article/a8kmnxdhbwmzxzsytlga">火焰图类型</a></p>
<ul>
<li>on-cpu(默认): 分析 cpu 瓶颈</li>
<li>off-cpu: 阻塞时间</li>
<li>内存火焰图：内存问题</li>
<li>Hot&#x2F;Cold 火焰图： on-cpu and off-cpu 结合</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/162375221">性能分析之 off-cpu</a></p>
</li>
<li><p>Top edge shows who is running on cpu and how much(width)</p>
</li>
<li><p><code>flamegraph.pl --color=java</code> C++和系统调用显示颜色不一样,</p>
</li>
<li><p>平顶山的火苗是瓶颈，perf top 也可以看出来 1. <code>flamegraph.pl --color=java</code> C++, 注意 C++ 普通函数会被认为是其他，比较傻瓜，索引::</p>
</li>
<li><p>第一要想到的是优化平顶</p>
</li>
<li><p>栈上空白处是没有函数调用，栈上没信息，所以不显示，也在计算，比如 for</p>
</li>
<li><p>为什么要叫火焰图，形象的理解：整个图形看起来就像一团跳动的火焰，这也正是其名字的由来。燃烧的火苗尖部就是 CPU 正在执行的操纵，图纵向表示调用栈的深度，横向表示消耗的时间。一个格子的宽度越大越说明其可能是瓶颈。当我们分析火焰图时，主要就是看那些比较宽大的火苗，<code>特别留意那些类似平顶山的火苗</code>。<br>火焰图是基于 stack 信息生成的 SVG 图片，用来展示 CPU 的调用栈。<br>y 轴表示调用栈，每一层都是一个函数，调用栈越深，火焰图的层数就越高，火焰就看起来越高，顶部就是正在执行的函数，下方就是它的父函数。<br>x 轴表示抽样数，表示一个函数在 x 轴占据的宽度越宽，就表示它被抽到的次数多，即执行的时间长，注意，x 轴不代表时间，而是所有的调用栈合并后，按字母顺序排列的。<br>火焰图是 SVG 图片，可以很方便的使用：<br>（1）鼠标悬浮<br>火焰的每一层都会标注函数名，鼠标悬浮时会显示完整的函数名、抽样抽中的次数、<code>占据总抽样次数的百分比</code>；<br>（2）点击放大<br>在某一层点击，火焰图会水平放大，该层会占据所有宽度，显示详细信息；<br>左上角会同时显示“Reset Zoom”，点击该链接，图片就会恢复原样；<br>（3）搜索<br>按下 Ctrl+F 会显示一个搜索框，用户可以输入关键词或正则表达式，所有复合条件的函数名会<code>高亮显示</code>。</p>
</li>
<li><p>火焰图生成<br>生成和创建火焰图需要以下几个步骤：<br>（1）捕获堆栈<br>使用 perf&#x2F;systemtap&#x2F;dtrace 等工具抓取程序的运行堆栈。<br>（2）折叠堆栈<br>trace 工具抓取的系统和程序运行每一时刻的堆栈信息，需要对他们进行分析组合，将重复的堆栈累计在一起，从而体现出负载和关键路径。<br>（3）生成火焰图<br>分析 stackcollapse 输出的堆栈信息生成火焰图。</p>
</li>
<li><p>static 函数可能不显示，会展开</p>
</li>
<li><p>火焰图结合 perf(on-cpu) 实际使用方法</p>
</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sudo apt install -y linux-tools-generic</span></span><br><span class="line"><span class="comment"># sudo rm /usr/bin/perf</span></span><br><span class="line"><span class="comment"># sudo ln -s /usr/lib/linux-tools/4.15.0-162-generic/perf /usr/bin/perf</span></span><br><span class="line"><span class="comment"># git clone https://github.com/brendangregg/FlameGraph.git</span></span><br><span class="line"><span class="comment"># cd FlameGraph</span></span><br><span class="line"><span class="comment"># perf record -F 99 -p $&#123;PID&#125; -a -g -- sleep 60</span></span><br><span class="line"><span class="comment"># perf script &gt; out.perf</span></span><br><span class="line"><span class="comment"># ./stackcollapse-perf.pl out.perf &gt; out.folded</span></span><br><span class="line"><span class="comment"># ./stackcollapse-perf.pl out.perf | c++flit &gt; out.folded</span></span><br><span class="line"><span class="comment"># ./flamegraph.pl out.folded &gt; out.svg</span></span><br></pre></td></tr></table></figure>

<ol>
<li>很轻松的分析出，哪些代码会经常性的触发 pagefault，以及比重。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/lrita/lrita.github.io/blob/master/_posts/2019-09-27-systemtap-profiling-pagefault.md#L29">page-faults</a> flamegraph 作者给的例子有些错误,<br>map, vector clear 会调用 explicit_bzero，容易产生 pagefault</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># perf record -e page-faults -p $1 -g -- sleep 60</span></span><br><span class="line"><span class="comment"># perf script &gt; out.perf</span></span><br><span class="line"><span class="comment"># ./stackcollapse-perf.pl out.perf &gt; out.folded</span></span><br><span class="line"><span class="comment"># ./flamegraph.pl out.folded &gt; out.svg</span></span><br></pre></td></tr></table></figure>

<ol>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/bandaoyu/article/details/108765693">出现 e 大量 unknown</a> 加<code>--call-graph dwarf</code>, 而 -g 就相当于 –call-graph fp. fp 就是 Frame Pointer，即 x86 中的 EBP 寄存器，fp 指向当前栈帧栈底地址，此地址保存着上一栈帧的 EBP 值</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo perf record -F 99 -p 81163 --call-graph dwarf -- <span class="built_in">sleep</span> 60</span><br></pre></td></tr></table></figure>

<ol>
<li>问题：<ul>
<li>perf 还有一个问题是对中断的要求，perf 很多事件都依赖中断，但 Linux 内核是可以关中断的，关中断以后，你就无法击中关中断的点了，你的中断会被延迟到开中断的时候，所以，在这样的平台上，你会看到很多开中断之后的函数被密集击中。但它们是无辜的。但更糟糕的是，如果在关中断的时候，发生了多个事件，由于中断控制器会合并相同的中断，你就会失去多次事件，让你的统计发生错误。现代的 Intel 平台，基本上已经把 PMU 中断都切换为 NMI 中断了（不可屏蔽），所以前面这个问题不存在。但在大部分 ARM&#x2F;ARM64 平台上，这个问题都没有解决，所以看这种平台的报告，都要特别小心，特别是你看到_raw_spin_unlock()一类的函数击中极高，你就要怀疑一下你的测试结果了（注意，这个结果也是能用的，只是看你怎么用）。</li>
<li>你每次看 perf report 的报告，首先要去注意一下总共收集了多少个点，如果你只有几十个点，你这个报告就可能很不可信了。</li>
</ul>
</li>
<li>哪些场景下可以利用火焰图来帮助我们处理问题<br>（1）版本更新时，对比前后两个版本的火焰图差别，有助于我们分析新旧两个版本的异同；<br>（2）CPU 异常占用时（CPU 异常打满或者 CPU 利用率一直上不去），通过火焰图，有助于我们定位异常代码；<br>（3）性能分析时，通过火焰图来了解程序实际执行时各模块对 CPU 资源的占用情况；<br>（4）问题排查，通过分析火焰图的调用栈是否符合预期，排查程序逻辑执行是否符合预期；</li>
</ol>
<h2 id="nsight"><a href="#nsight" class="headerlink" title="nsight"></a>nsight</h2><ol>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html">user guide</a></li>
<li>NsightSystems-2023.2.1.122-3259852.msi 安装包</li>
<li>Nsight_Systems_User_Guide_2023.2.1.122-3259852.pdf 文档</li>
<li>左上角 timeline view 可以选择 analysis summary，有各种总结</li>
<li>左侧右键选<code>show in events view</code>， 可以看具体时间, 可以在 all 上操作，看所有 event 运行时间</li>
<li>右键 reset room 显示全部</li>
<li><code>shift + mouseleftdoubleclick</code> timeline 可以找到对应 event 在 event view 位置</li>
<li><code>ctrl + mouseleftdoubleclick</code> timeline 可以 fit to screen</li>
<li><code>backspace</code> timeline 可以 undo room</li>
<li><code>ctrl + mouseleftdoubleclick</code> 可以找到 event view 对应的 timeline 位置</li>
<li><code>sudo nsys profile &lt;app&gt;</code></li>
<li><code>nsys stats report1.nsys-rep</code> 输出各种 report</li>
<li>可以看 cpu 执行情况， tensort 可以看详细算子耗时，也有对应 cuda 执行情况</li>
<li>analysis summary 中有各个线程的 cpu 利用率总结</li>
<li>可以关注 cpu 空闲的地方，为什么会空闲(同步数据？)</li>
<li>可以缩小看颜色占比，关注占比大的模块</li>
<li>cudaMemcpy 会阻塞 cpu 执行， 可以多注意 cudaMemcpy 影响</li>
<li>cudaStreamSynchronize 是 CUDA API 中的一个函数，用于等待指定的 CUDA 流上的所有 CUDA 核函数执行完毕。当 CUDA 核函数被执行时，它们会被添加到一个 CUDA 流中，这些核函数的执行可能是异步的，也可能是同步的，具体取决于如何在代码中调用它们。当我们调用 cudaStreamSynchronize 时，它将会阻塞当前 CPU 线程，直到指定的流上的所有核函数都执行完毕。</li>
</ol>
<h2 id="总结-搜索-speed-up-C"><a href="#总结-搜索-speed-up-C" class="headerlink" title="总结(搜索 speed up C++)"></a>总结(搜索 speed up C++)</h2><ol>
<li>内存连续读写速度远快于随机读写。(尽可能顺序访问内存)</li>
<li>内存的写入速度比读取慢不少(减少内存写操作)</li>
<li>用连续内存(多线程分配内存？)</li>
<li>少分配内存, 尽量原位操作</li>
<li>函数满足 RVO(return value optimization)</li>
<li>不满足 RVO, 用 move, 例如返回 tuple, 构造时元素要用 move</li>
<li>多维 vector 内存分配比较耗时</li>
<li>尽量用一维 vector 或 array，多维 vector 慢很多</li>
<li>transform 不要用 back_inserter,先分配好，然后用 begin()</li>
<li>lamda 是内联函数，比普通函数快</li>
<li>多用 for, transform, 少用 push_back, emplace_back</li>
<li>transform 应用到连续内存会比较快， 比如 array, 应用到 vector 比 array 慢很多</li>
<li>range 应用到连续内存比较快，array 比 vector 快很多，array 的 range 比 for 快很多，vector 的 range 比 for 慢</li>
<li>range 比 transform 快</li>
<li>矩阵运算用一维矩阵比二维矩阵快很多。</li>
<li>vector: resize 会调用构造函数，reserve 不会调用。reserve 比 resize 快很多。需要 empalce_back 的要先 reserve。初始化为 0 比较慢？</li>
<li>动态内存分配、STL 容器、string 都是一些常容易 cache 不友好的场景，核心代码处尽量不用</li>
</ol>
<h2 id="cpu-mem-实时利用率"><a href="#cpu-mem-实时利用率" class="headerlink" title="cpu mem 实时利用率"></a>cpu mem 实时利用率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ResouceUsageCatch</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;ResouceUsageCatch runing ...&#x27;</span>)</span><br><span class="line">    msg = os.popen(<span class="string">&#x27;ps -aux | grep -v grep | grep  \&#x27;PID\&#x27;&#x27;</span>).read()</span><br><span class="line">    msg_head = msg.split()</span><br><span class="line">    <span class="built_in">print</span>(msg_head)</span><br><span class="line">    <span class="built_in">print</span>(msg_head.index(<span class="string">&#x27;%CPU&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(msg_head.index(<span class="string">&#x27;RSS&#x27;</span>))</span><br><span class="line">    cpu_val_list = []</span><br><span class="line">    mem_val_list = []</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">20</span>) <span class="comment"># wait the demo run stable</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;cpu_mem.csv&#x27;</span>,<span class="string">&#x27;w+&#x27;</span>) <span class="keyword">as</span> file_out:</span><br><span class="line">        run_times = <span class="number">0</span></span><br><span class="line">        cpu_mem_writer = csv.writer(file_out)</span><br><span class="line">        cpu_mem_writer.writerow([<span class="string">&#x27;cpu&#x27;</span>, <span class="string">&#x27;mem&#x27;</span>])</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            msg = os.popen(<span class="string">&#x27;ps -aux | grep -v grep | grep  \&#x27;visual_radar_by_camera_demo\&#x27;&#x27;</span>).read()</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">len</span>(msg) == <span class="number">0</span>):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            msg_list = msg.split()</span><br><span class="line">            <span class="comment"># print(msg_list[msg_head.index(&#x27;%CPU&#x27;)])</span></span><br><span class="line">            <span class="comment"># print(msg_list[msg_head.index(&#x27;RSS&#x27;)])</span></span><br><span class="line"></span><br><span class="line">            cpu_mem_writer.writerow([<span class="built_in">float</span>(msg_list[msg_head.index(<span class="string">&#x27;%CPU&#x27;</span>)]), <span class="built_in">float</span>(msg_list[msg_head.index(<span class="string">&#x27;RSS&#x27;</span>)])])</span><br><span class="line"></span><br><span class="line">            cpu_val_list.append(<span class="built_in">float</span>(msg_list[msg_head.index(<span class="string">&#x27;%CPU&#x27;</span>)]))</span><br><span class="line">            mem_val_list.append(<span class="built_in">float</span>(msg_list[msg_head.index(<span class="string">&#x27;RSS&#x27;</span>)]))</span><br><span class="line"></span><br><span class="line">            run_times = run_times + <span class="number">1</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;run times : &quot;</span>, run_times)</span><br><span class="line">            <span class="keyword">if</span> run_times &gt; <span class="number">3600</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">        os.system(<span class="string">&#x27;killall visual_radar_by_camera_demo&#x27;</span>)</span><br><span class="line">        time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;test_report.csv&#x27;</span>,<span class="string">&#x27;w+&#x27;</span>) <span class="keyword">as</span> file_out:</span><br><span class="line">        csv_writer = csv.writer(file_out)</span><br><span class="line">        csv_writer.writerow([<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;max&#x27;</span>, <span class="string">&#x27;average&#x27;</span>, <span class="string">&#x27;min&#x27;</span>, <span class="string">&#x27;data_unit&#x27;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;=************************= cpu usage =************************=&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(cpu_val_list) &gt; <span class="number">0</span>):</span><br><span class="line">            cpu_max = <span class="built_in">max</span>(cpu_val_list)</span><br><span class="line">            cpu_min = <span class="built_in">min</span>(cpu_val_list)</span><br><span class="line">            cpu_ave = <span class="built_in">sum</span>(cpu_val_list)/<span class="built_in">len</span>(cpu_val_list)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;cpu max : %d&quot;</span>, cpu_max)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;cpu min : %d&quot;</span>, cpu_min)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;cpu ave : %d&quot;</span>, cpu_ave)</span><br><span class="line">            csv_writer.writerow([<span class="string">&#x27;cpu&#x27;</span>, <span class="built_in">round</span>(cpu_max, <span class="number">1</span>), <span class="built_in">round</span>(cpu_ave, <span class="number">1</span>), <span class="built_in">round</span>(cpu_min, <span class="number">1</span>), <span class="string">&#x27;%&#x27;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;---------------------------------------------------------------&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;=************************= mem usage =************************=&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(mem_val_list) &gt; <span class="number">0</span>):</span><br><span class="line">            mem_max = <span class="built_in">max</span>(mem_val_list)/<span class="number">1000.</span></span><br><span class="line">            mem_min = <span class="built_in">min</span>(mem_val_list)/<span class="number">1000.</span></span><br><span class="line">            mem_ave = <span class="built_in">sum</span>(mem_val_list)/<span class="built_in">len</span>(mem_val_list)/<span class="number">1000.</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;mem max : &quot;</span>, mem_max)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;mem min : &quot;</span>, mem_min)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;mem ave : &quot;</span>, mem_ave)</span><br><span class="line">            csv_writer.writerow([<span class="string">&#x27;mem&#x27;</span>, <span class="built_in">round</span>(mem_max, <span class="number">1</span>), <span class="built_in">round</span>(mem_ave, <span class="number">1</span>), <span class="built_in">round</span>(mem_min, <span class="number">1</span>), <span class="string">&#x27;M&#x27;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;---------------------------------------------------------------&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="profiling-result"><a href="#profiling-result" class="headerlink" title="profiling result"></a>profiling result</h2><ol>
<li>多线程分配内存(申请内存足够大，且时间大于线程开销)（或申请内存时可以做其他操作）</li>
</ol>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">TEST : 4955us</span><br><span class="line">TEST_MT : 2786us</span><br><span class="line"></span><br><span class="line">vector&lt;int&gt; test1(<span class="number">1000000</span>, <span class="number">100</span>);</span><br><span class="line">  vector&lt;int&gt; test2(<span class="number">1000000</span>, <span class="number">100</span>);</span><br><span class="line">  vector&lt;int&gt; test11(<span class="number">1000000</span>, <span class="number">100</span>);</span><br><span class="line">  __TOC__(TEST)</span><br><span class="line"></span><br><span class="line">  __TIC__(TEST_MT)</span><br><span class="line">  std::vector&lt;int&gt; test3;</span><br><span class="line">  std::vector&lt;int&gt; test4;</span><br><span class="line">  std::vector&lt;int&gt; test5;</span><br><span class="line">  auto <span class="function"><span class="keyword">fun</span> = []<span class="params">(std::<span class="type">vector</span>&lt;<span class="type">int</span>&gt; &amp;<span class="type">v</span>, int num)</span></span> &#123; v.resize(num); &#125;;</span><br><span class="line">  auto f1 = async(<span class="function"><span class="keyword">fun</span>, <span class="title">ref</span><span class="params">(test3)</span></span>, <span class="number">1000000</span>);</span><br><span class="line">  auto f2 = async(<span class="function"><span class="keyword">fun</span>, <span class="title">ref</span><span class="params">(test4)</span></span>, <span class="number">1000000</span>);</span><br><span class="line">  auto f3 = async(<span class="function"><span class="keyword">fun</span>, <span class="title">ref</span><span class="params">(test5)</span></span>, <span class="number">1000000</span>);</span><br><span class="line">  f1.<span class="keyword">get</span>();</span><br><span class="line">  f2.<span class="keyword">get</span>();</span><br><span class="line">  f3.<span class="keyword">get</span>();</span><br><span class="line">  __TOC__(TEST_MT)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>vector construct, reserve, resize （resize 会调用构造函数，reserve 不会调用。需要 empalce_back 的要先 reserve。初始化为 0 比较慢？）</li>
</ol>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">TEST_RESERVE : <span class="number">6275</span>us</span><br><span class="line">TEST_NOT_RESERVE : <span class="number">10727</span>us</span><br><span class="line">TEST : <span class="number">3740</span>us</span><br><span class="line">TEST_zero : <span class="number">3763</span>us</span><br><span class="line">TEST_one : <span class="number">3292</span>us</span><br><span class="line">TEST_RESIZE : <span class="number">3575</span>us</span><br><span class="line"></span><br><span class="line">  <span class="built_in">__TIC__</span>(TEST_RESERVE)</span><br><span class="line">  vector&lt;int&gt; test0;</span><br><span class="line">  test0<span class="selector-class">.reserve</span>(<span class="number">2000000</span>);</span><br><span class="line">  for (auto i = <span class="number">0</span>u; i &lt; <span class="number">2000000</span>; ++i) &#123;</span><br><span class="line">    test0<span class="selector-class">.emplace_back</span>(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">__TOC__</span>(TEST_RESERVE)</span><br><span class="line"></span><br><span class="line">  <span class="built_in">__TIC__</span>(TEST_NOT_RESERVE)</span><br><span class="line">  vector&lt;int&gt; test1;</span><br><span class="line">  for (auto i = <span class="number">0</span>u; i &lt; <span class="number">2000000</span>; ++i) &#123;</span><br><span class="line">    test1<span class="selector-class">.emplace_back</span>(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">__TOC__</span>(TEST_NOT_RESERVE)</span><br><span class="line"></span><br><span class="line">  <span class="built_in">__TIC__</span>(TEST)</span><br><span class="line">  vector&lt;int&gt; <span class="built_in">test</span>(<span class="number">2000000</span>);</span><br><span class="line">  <span class="built_in">__TOC__</span>(TEST)</span><br><span class="line"></span><br><span class="line">  <span class="built_in">__TIC__</span>(TEST_zero)</span><br><span class="line">  vector&lt;int&gt; <span class="built_in">test2</span>(<span class="number">2000000</span>, <span class="number">0</span>);</span><br><span class="line">  <span class="built_in">__TOC__</span>(TEST_zero)</span><br><span class="line"></span><br><span class="line">  <span class="built_in">__TIC__</span>(TEST_one)</span><br><span class="line">  vector&lt;int&gt; <span class="built_in">test4</span>(<span class="number">2000000</span>, <span class="number">1</span>);</span><br><span class="line">  <span class="built_in">__TOC__</span>(TEST_one)</span><br><span class="line"></span><br><span class="line"> <span class="built_in">__TIC__</span>(TEST_RESIZE)</span><br><span class="line">  vector&lt;int&gt; test3;</span><br><span class="line">  test3<span class="selector-class">.resize</span>(<span class="number">2000000</span>);</span><br><span class="line">  <span class="built_in">__TOC__</span>(TEST_RESIZE)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>range and transform (array 的 transform 比 vector 的快)</li>
</ol>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">ARRAY_RANGE : <span class="number">1084</span>us</span><br><span class="line">VECTOR_RANGE : <span class="number">6421</span>us</span><br><span class="line">ARRAY_TRANSFORM : <span class="number">1603</span>us</span><br><span class="line">VECTOR_TRANSFORM : <span class="number">8252</span>us</span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(ARRAY)</span></span><br><span class="line">  <span class="built_in">array</span>&lt;<span class="built_in">int</span>, <span class="number">1000000</span>&gt; a;</span><br><span class="line">  <span class="keyword">for</span> (auto i = <span class="number">0</span>u; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">    a<span class="literal">[<span class="identifier">i</span>]</span> = i;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="constructor">__TOC__(ARRAY)</span></span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(ARRAY_TRAN)</span></span><br><span class="line">  <span class="built_in">array</span>&lt;<span class="built_in">int</span>, <span class="number">1000000</span>&gt; a1;</span><br><span class="line">  transform(a1.<span class="keyword">begin</span><span class="literal">()</span>, a1.<span class="keyword">end</span><span class="literal">()</span>, a1.<span class="keyword">begin</span><span class="literal">()</span>, <span class="literal">[]</span>(auto &amp;a) &#123; return a + <span class="number">1</span>; &#125;);</span><br><span class="line">  <span class="constructor">__TOC__(ARRAY_TRAN)</span></span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(VECTOR)</span></span><br><span class="line">  vector&lt;<span class="built_in">int</span>&gt; v(<span class="number">1000000</span>);</span><br><span class="line">  <span class="keyword">for</span> (auto i = <span class="number">0</span>u; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">    v<span class="literal">[<span class="identifier">i</span>]</span> = i;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="constructor">__TOC__(VECTOR)</span></span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(VECTOR_TRAN)</span></span><br><span class="line">  vector&lt;<span class="built_in">int</span>&gt; v1(<span class="number">1000000</span>);</span><br><span class="line">  transform(v1.<span class="keyword">begin</span><span class="literal">()</span>, v1.<span class="keyword">end</span><span class="literal">()</span>, v1.<span class="keyword">begin</span><span class="literal">()</span>, <span class="literal">[]</span>(auto &amp;v) &#123; return v + <span class="number">1</span>; &#125;);</span><br><span class="line">  <span class="constructor">__TOC__(VECTOR_TRAN)</span></span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(VECTOR_TRAN2)</span></span><br><span class="line">  vector&lt;<span class="built_in">int</span>&gt; v2(<span class="number">1000000</span>);</span><br><span class="line">  transform(v1.<span class="keyword">begin</span><span class="literal">()</span>, v1.<span class="keyword">end</span><span class="literal">()</span>, v2.<span class="keyword">begin</span><span class="literal">()</span>, <span class="literal">[]</span>(auto &amp;v) &#123; return v + <span class="number">1</span>; &#125;);</span><br><span class="line">  <span class="constructor">__TOC__(VECTOR_TRAN2)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>一维 vector 和二维 vector(一维比多维快很多)</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">VECTOR2 : <span class="number">3770u</span>s</span><br><span class="line">VECTOR1 : <span class="number">554u</span>s</span><br><span class="line">ARRAY : <span class="number">627u</span>s</span><br><span class="line"></span><br><span class="line"> __TIC__(VECTOR2)</span><br><span class="line">  vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">v</span>(<span class="number">10000</span>, <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(<span class="number">5</span>));</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0u</span>; i &lt; v.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> j = <span class="number">0u</span>; j &lt; <span class="number">5</span>; ++j) &#123;</span><br><span class="line">      v[i][j] = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(VECTOR2)</span><br><span class="line"></span><br><span class="line">  __TIC__(VECTOR1)</span><br><span class="line">  <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">v1</span><span class="params">(<span class="number">10000</span> * <span class="number">5</span>)</span></span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0u</span>; i &lt; <span class="number">10000</span> * <span class="number">5</span>; ++i) &#123;</span><br><span class="line">    v1[i] = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(VECTOR1)</span><br><span class="line"></span><br><span class="line">  __TIC__(ARRAY)</span><br><span class="line">  array&lt;<span class="type">int</span>, 10000 * 5&gt; a;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0u</span>; i &lt; <span class="number">10000</span> * <span class="number">5</span>; ++i) &#123;</span><br><span class="line">    a[i] = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(ARRAY)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>array and vector, transform and for(array 配合 transform 比较快， vector 配合 transform 很慢)</li>
</ol>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">ARRAY : <span class="number">1372</span>us</span><br><span class="line">ARRAY_TRAN : <span class="number">1078</span>us</span><br><span class="line">VECTOR : <span class="number">1219</span>us</span><br><span class="line">VECTOR_TRAN : <span class="number">4595</span>us</span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(ARRAY)</span></span><br><span class="line">  <span class="built_in">array</span>&lt;<span class="built_in">int</span>, <span class="number">100000</span>&gt; a;</span><br><span class="line">  <span class="keyword">for</span> (auto i = <span class="number">0</span>u; i &lt; <span class="number">100000</span>; ++i) &#123;</span><br><span class="line">    a<span class="literal">[<span class="identifier">i</span>]</span> = i;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="constructor">__TOC__(ARRAY)</span></span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(ARRAY_TRAN)</span></span><br><span class="line">  <span class="built_in">array</span>&lt;<span class="built_in">int</span>, <span class="number">100000</span>&gt; a1;</span><br><span class="line">  transform(a1.<span class="keyword">begin</span><span class="literal">()</span>, a1.<span class="keyword">end</span><span class="literal">()</span>, a1.<span class="keyword">begin</span><span class="literal">()</span>, <span class="literal">[]</span>(auto a) &#123; return a + <span class="number">1</span>; &#125;);</span><br><span class="line">  <span class="constructor">__TOC__(ARRAY_TRAN)</span></span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(VECTOR)</span></span><br><span class="line">  vector&lt;<span class="built_in">int</span>&gt; v(<span class="number">100000</span>);</span><br><span class="line">  <span class="keyword">for</span> (auto i = <span class="number">0</span>u; i &lt; <span class="number">100000</span>; ++i) &#123;</span><br><span class="line">    v<span class="literal">[<span class="identifier">i</span>]</span> = i;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="constructor">__TOC__(VECTOR)</span></span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(VECTOR_TRAN)</span></span><br><span class="line">  vector&lt;<span class="built_in">int</span>&gt; v1(<span class="number">100000</span>);</span><br><span class="line">  transform(v1.<span class="keyword">begin</span><span class="literal">()</span>, v1.<span class="keyword">end</span><span class="literal">()</span>, v1.<span class="keyword">begin</span><span class="literal">()</span>, <span class="literal">[]</span>(auto v) &#123; return v + <span class="number">1</span>; &#125;);</span><br><span class="line">  <span class="constructor">__TOC__(VECTOR_TRAN)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>function return</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::vector&lt;<span class="type">int</span>&gt; <span class="title">m1</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> std::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(<span class="number">3000000</span>, <span class="number">1</span>); &#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::vector&lt;<span class="type">int</span>&gt; <span class="title">m2</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> std::<span class="built_in">move</span>(std::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(<span class="number">3000000</span>, <span class="number">1</span>)); &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// fastest</span></span><br><span class="line"><span class="function">std::vector&lt;<span class="type">int</span>&gt; <span class="title">m3</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">std::vector&lt;<span class="type">int</span>&gt; <span class="title">result</span><span class="params">(<span class="number">3000000</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::vector&lt;<span class="type">int</span>&gt; <span class="title">m4</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">std::vector&lt;<span class="type">int</span>&gt; <span class="title">result</span><span class="params">(<span class="number">3000000</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">  <span class="keyword">return</span> std::<span class="built_in">move</span>(result);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">M1 : <span class="number">16538117</span>ns</span><br><span class="line">M2 : <span class="number">15113944</span>ns</span><br><span class="line">M3 : <span class="number">14415912</span>ns</span><br><span class="line">M4 : <span class="number">15932611</span>ns</span><br></pre></td></tr></table></figure>

<ol>
<li>range: vector and array(array 的 range 比 for 快很多，vector 的 range 比 for 慢)</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">VECTOR : <span class="number">648u</span>s</span><br><span class="line">VECTOR_RANGE : <span class="number">1784u</span>s</span><br><span class="line">ARRAY : <span class="number">743u</span>s</span><br><span class="line">ARRAY_RANGE : <span class="number">177u</span>s</span><br><span class="line"></span><br><span class="line">__TIC__(VECTOR)</span><br><span class="line">  <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">v1</span><span class="params">(<span class="number">10000</span> * <span class="number">5</span>)</span></span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0u</span>; i &lt; <span class="number">10000</span> * <span class="number">5</span>; ++i) &#123;</span><br><span class="line">    v1[i] = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(VECTOR)</span><br><span class="line"></span><br><span class="line">  __TIC__(VECTOR_RANGE)</span><br><span class="line">  <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">v2</span><span class="params">(<span class="number">10000</span> * <span class="number">5</span>)</span></span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;i : v2) &#123;</span><br><span class="line">    i = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(VECTOR_RANGE)</span><br><span class="line"></span><br><span class="line">  __TIC__(ARRAY)</span><br><span class="line">  array&lt;<span class="type">int</span>, 10000 * 5&gt; a;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0u</span>; i &lt; <span class="number">10000</span> * <span class="number">5</span>; ++i) &#123;</span><br><span class="line">    a[i] = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(ARRAY)</span><br><span class="line"></span><br><span class="line">  __TIC__(ARRAY_RANGE)</span><br><span class="line">  array&lt;<span class="type">int</span>, 10000 * 5&gt; a1;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;i : a) &#123;</span><br><span class="line">    i = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(ARRAY_RANGE)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>range and for</li>
</ol>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> std::vector&lt;int&gt; <span class="built_in">vec</span>(<span class="number">500000</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">__TIC__</span>(M1);</span><br><span class="line">  for (int i = <span class="number">0</span>; i &lt; vec.size(); ++<span class="selector-tag">i</span>) &#123;</span><br><span class="line">    vec<span class="selector-attr">[i]</span>++;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">__TOC__</span>(M1);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">__TIC__</span>(M2);</span><br><span class="line">  for (auto item : vec) &#123;</span><br><span class="line">    item++;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">__TOC__</span>(M2);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">__TIC__</span>(M3);</span><br><span class="line">  for (auto&amp; item : vec) &#123;</span><br><span class="line">    item++;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">__TOC__</span>(M3);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">M1 : <span class="number">5885</span>us</span><br><span class="line">M2 : <span class="number">12406</span>us</span><br><span class="line">M3 : <span class="number">11534</span>us</span><br></pre></td></tr></table></figure>

<ol>
<li>transform and for</li>
</ol>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">vec</span><span class="params">(<span class="number">10000</span>, <span class="number">1.111</span>)</span></span>;</span><br><span class="line"> <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">vec1</span><span class="params">(<span class="number">10000</span>, <span class="number">2.111</span>)</span></span>;</span><br><span class="line"> std::vector&lt;<span class="type">float</span>&gt; result;</span><br><span class="line"> <span class="comment">// 操作一个vector</span></span><br><span class="line"> std::<span class="built_in">transform</span>(vec.<span class="built_in">begin</span>(), vec.<span class="built_in">end</span>(), std::<span class="built_in">back_inserter</span>(result),</span><br><span class="line">                [](<span class="type">const</span> <span class="keyword">auto</span> item) -&gt; <span class="type">float</span> &#123; <span class="keyword">return</span> item + <span class="number">100</span>; &#125;);</span><br><span class="line"> <span class="comment">// for_each(vec.begin(), vec.end(), [](auto &amp;item) &#123; item += 100; &#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 性能好很多，不要用back_inserter</span></span><br><span class="line"> <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">result5</span><span class="params">(vec.size(), <span class="number">0</span>)</span></span>;</span><br><span class="line"> std::<span class="built_in">transform</span>(vec.<span class="built_in">begin</span>(), vec.<span class="built_in">end</span>(), result5.<span class="built_in">begin</span>(),</span><br><span class="line">                [](<span class="type">const</span> <span class="keyword">auto</span> &amp;item) -&gt; <span class="type">float</span> &#123; <span class="keyword">return</span> item + <span class="number">100</span>; &#125;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="comment">// 操作两个vector <span class="doctag">NOTE:</span> 使用前需要检查vec, vec1 size是否匹配。</span></span><br><span class="line"> <span class="comment">// 性能好 797us 13us(-O3)</span></span><br><span class="line"> <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">result1</span><span class="params">(<span class="number">10</span>, <span class="number">0.0</span>)</span></span>;</span><br><span class="line"> std::<span class="built_in">transform</span>(vec.<span class="built_in">begin</span>(), vec.<span class="built_in">end</span>(), vec1.<span class="built_in">begin</span>(), result1.<span class="built_in">begin</span>(),</span><br><span class="line">                [](<span class="type">const</span> <span class="keyword">auto</span> &amp;item1, <span class="type">const</span> <span class="keyword">auto</span> &amp;item2) -&gt; <span class="type">float</span> &#123;</span><br><span class="line">                  <span class="keyword">return</span> item1 + item2;</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line"> <span class="comment">// 性能差 2605us 173us(-O3)</span></span><br><span class="line"> std::vector&lt;<span class="type">float</span>&gt; result2;</span><br><span class="line"> std::<span class="built_in">transform</span>(vec.<span class="built_in">begin</span>(), vec.<span class="built_in">end</span>(), vec1.<span class="built_in">begin</span>(),</span><br><span class="line">                std::<span class="built_in">back_inserter</span>(result2),</span><br><span class="line">                [](<span class="type">const</span> <span class="keyword">auto</span> &amp;item1, <span class="type">const</span> <span class="keyword">auto</span> &amp;item2) -&gt; <span class="type">float</span> &#123;</span><br><span class="line">                  <span class="keyword">return</span> item1 + item2;</span><br><span class="line">                &#125;);</span><br><span class="line"> <span class="comment">// for 463us 70us(-O3)</span></span><br><span class="line"> <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">result3</span><span class="params">(vec.size(), <span class="number">0</span>)</span></span>;</span><br><span class="line"> <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0u</span>; i &lt; result3.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">   result[i] = vec[i] + vec1[i];</span><br><span class="line"> &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>lambda and fun</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 322ns</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">add</span><span class="params">(<span class="type">int</span> &amp;a, <span class="type">int</span> &amp;b)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> result = a + b;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 233ns</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">add_inline</span><span class="params">(<span class="type">int</span> &amp;a, <span class="type">int</span> &amp;b)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> result = a + b;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 233ns</span></span><br><span class="line"><span class="keyword">auto</span> l = [](<span class="type">int</span> &amp;a, <span class="type">int</span> &amp;b) &#123; <span class="keyword">return</span> a + b; &#125;; <span class="comment">// 使用lambda函数的效率与使用函数对象是一样的，都要快于函数指针。他们都能够在编译期将代码内联展开，减少函数调用的时间。</span></span><br><span class="line"><span class="comment">// 编译为类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">__lambda_6_11</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">inline</span> <span class="comment">/*constexpr */</span> <span class="function"><span class="type">int</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> a + b;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">using</span> retType_6_11 = <span class="built_in">int</span> (*)(<span class="type">int</span>, <span class="type">int</span>);</span><br><span class="line">    <span class="keyword">inline</span> <span class="comment">/*constexpr */</span> <span class="function"><span class="keyword">operator</span> <span class="title">retType_6_11</span> <span class="params">()</span> <span class="type">const</span> <span class="keyword">noexcept</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> __invoke;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">    <span class="type">static</span> <span class="keyword">inline</span> <span class="type">int</span> __invoke(<span class="type">int</span> a, <span class="type">int</span> b)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">return</span> a + b;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>4 for and memset</p>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">  <span class="built_in">int</span> a<span class="literal">[<span class="number">800000</span>]</span>;</span><br><span class="line">  <span class="constructor">__TIC__(M1)</span>;</span><br><span class="line">  memset(a, <span class="number">0</span>, <span class="number">800000</span><span class="operator"> * </span>sizeof(<span class="built_in">int</span>)); <span class="comment">// memset 只能用于连续内存，不能用于vector</span></span><br><span class="line">  <span class="constructor">__TOC__(M1)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(M2)</span>;</span><br><span class="line">  <span class="keyword">for</span> (auto i = <span class="number">0</span>u; i &lt; <span class="number">800000</span>; ++i) &#123;</span><br><span class="line">    a<span class="literal">[<span class="identifier">i</span>]</span> = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="constructor">__TOC__(M2)</span>;</span><br><span class="line"></span><br><span class="line">M1 : <span class="number">1401</span>us</span><br><span class="line">M2 : <span class="number">1908</span>us</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>for, transform, push_back, emplace_back(少用 push_back, emplace_back)</li>
</ol>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;float&gt; vec(<span class="number">1000000</span>, <span class="number">-1235.23</span>)<span class="comment">;</span></span><br><span class="line"></span><br><span class="line">  __TIC__(<span class="name">FOR</span>)</span><br><span class="line">  vector&lt;float&gt; result_for(<span class="number">1000000</span>, <span class="number">0</span>)<span class="comment">;</span></span><br><span class="line">  for (<span class="name">auto</span> i = <span class="number">0</span>u<span class="comment">; i &lt; result_for.size(); ++i) &#123;</span></span><br><span class="line">    result_for[i] = vec[i]<span class="comment">;</span></span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(<span class="name">FOR</span>)</span><br><span class="line"></span><br><span class="line">  __TIC__(<span class="name">TRANSFORM</span>)</span><br><span class="line">  vector&lt;float&gt; result_trans(<span class="number">1000000</span>, <span class="number">0</span>)<span class="comment">;</span></span><br><span class="line">  std:<span class="symbol">:transform</span>(<span class="name">vec</span>.begin(), vec.end(), result_trans.begin(),</span><br><span class="line">                 [](<span class="name">auto</span> i) -&gt; float &#123; return i<span class="comment">; &#125;);</span></span><br><span class="line">  __TOC__(<span class="name">TRANSFORM</span>)</span><br><span class="line"></span><br><span class="line">  __TIC__(<span class="name">PUSH_BACK</span>)</span><br><span class="line">  vector&lt;float&gt; result0<span class="comment">;</span></span><br><span class="line">  for (<span class="name">auto</span> i : vec) &#123;</span><br><span class="line">    result0.push_back(<span class="name">i</span>)<span class="comment">;</span></span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(<span class="name">PUSH_BACK</span>)</span><br><span class="line"></span><br><span class="line">  __TIC__(<span class="name">PUSH_BACK1</span>)</span><br><span class="line">  vector&lt;float&gt; result<span class="comment">;</span></span><br><span class="line">  for (<span class="name">auto</span> i : vec) &#123;</span><br><span class="line">    result.push_back(<span class="name">std</span>:<span class="symbol">:move</span>(<span class="name">i</span>))<span class="comment">;</span></span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(<span class="name">PUSH_BACK1</span>)</span><br><span class="line"></span><br><span class="line">  __TIC__(<span class="name">EMPLACE_BACK</span>)</span><br><span class="line">  vector&lt;float&gt; result1<span class="comment">;</span></span><br><span class="line">  for (<span class="name">auto</span> i : vec) &#123;</span><br><span class="line">    result1.emplace_back(<span class="name">i</span>)<span class="comment">;</span></span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(<span class="name">EMPLACE_BACK</span>)</span><br><span class="line"></span><br><span class="line">  __TIC__(<span class="name">EMPLACE_BACK2</span>)</span><br><span class="line">  vector&lt;float&gt; result2<span class="comment">;</span></span><br><span class="line">  for (<span class="name">auto</span> <span class="symbol">&amp;i</span> : vec) &#123;</span><br><span class="line">    result2.emplace_back(<span class="name">i</span>)<span class="comment">;</span></span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(<span class="name">EMPLACE_BACK2</span>)</span><br><span class="line"></span><br><span class="line">  __TIC__(<span class="name">EMPLACE_BACK3</span>)</span><br><span class="line">  vector&lt;float&gt; result3<span class="comment">;</span></span><br><span class="line">  for (<span class="name">auto</span> <span class="symbol">&amp;i</span> : vec) &#123;</span><br><span class="line">    result3.emplace_back(<span class="name">std</span>:<span class="symbol">:move</span>(<span class="name">i</span>))<span class="comment">;</span></span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(<span class="name">EMPLACE_BACK3</span>)</span><br><span class="line"></span><br><span class="line">  cout &lt;&lt; vec[<span class="number">0</span>] &lt;&lt; endl<span class="comment">;</span></span><br><span class="line"></span><br><span class="line">  for (<span class="name">auto</span> <span class="symbol">&amp;i</span> : vec) &#123;</span><br><span class="line">    // cout &lt;&lt; i &lt;&lt; <span class="string">&quot; &quot;</span><span class="comment">;</span></span><br><span class="line">  &#125;</span><br><span class="line">  return <span class="number">0</span><span class="comment">;</span></span><br><span class="line"></span><br><span class="line">FOR : <span class="number">2042</span>us</span><br><span class="line">TRANSFORM : <span class="number">2161</span>us</span><br><span class="line">PUSH_BACK : <span class="number">4369</span>us</span><br><span class="line">PUSH_BACK1 : <span class="number">5835</span>us</span><br><span class="line">EMPLACE_BACK : <span class="number">5175</span>us</span><br><span class="line">EMPLACE_BACK2 : <span class="number">5075</span>us</span><br><span class="line">EMPLACE_BACK3 : <span class="number">5364</span>us</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>struct bindings(多用引用)</li>
</ol>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">  vector&lt;<span class="built_in">float</span>&gt; vec(<span class="number">1000000</span>, -<span class="number">1235.23</span>);</span><br><span class="line">  auto tup = std::make<span class="constructor">_tuple(<span class="params">vec</span>, <span class="params">vec</span>, <span class="params">vec</span>)</span>;</span><br><span class="line">  <span class="constructor">__TIC__(TUP1)</span></span><br><span class="line">  auto <span class="literal">[<span class="identifier">x</span>, <span class="identifier">y</span>, <span class="identifier">z</span>]</span> = tup;</span><br><span class="line">  <span class="constructor">__TOC__(TUP1)</span></span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(TUP2)</span></span><br><span class="line">  auto &amp;<span class="literal">[<span class="identifier">l</span>, <span class="identifier">m</span>, <span class="identifier">n</span>]</span> = tup;</span><br><span class="line">  <span class="constructor">__TOC__(TUP2)</span></span><br><span class="line"></span><br><span class="line">TUP1 : <span class="number">6940</span>us</span><br><span class="line">TUP2 : <span class="number">0</span>us</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 三种方式等价</span></span><br><span class="line">  vector&lt;<span class="built_in">float</span>&gt; vec(<span class="number">1000000</span>, -<span class="number">1235.23</span>);</span><br><span class="line">  <span class="constructor">__TIC__(TUP1)</span></span><br><span class="line">  auto tup = std::make<span class="constructor">_tuple(<span class="params">vec</span>, <span class="params">vec</span>, <span class="params">vec</span>)</span>;</span><br><span class="line">  auto <span class="literal">[<span class="identifier">x</span>, <span class="identifier">y</span>, <span class="identifier">z</span>]</span> = std::move(tup);</span><br><span class="line">  <span class="constructor">__TOC__(TUP1)</span></span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(TUP2)</span></span><br><span class="line">  auto tup2 = std::make<span class="constructor">_tuple(<span class="params">vec</span>, <span class="params">vec</span>, <span class="params">vec</span>)</span>;</span><br><span class="line">  auto &amp;<span class="literal">[<span class="identifier">x2</span>, <span class="identifier">y2</span>, <span class="identifier">z2</span>]</span> = tup;</span><br><span class="line">  <span class="constructor">__TOC__(TUP2)</span></span><br><span class="line"></span><br><span class="line">  <span class="constructor">__TIC__(TUP3)</span></span><br><span class="line">  auto <span class="literal">[<span class="identifier">x1</span>, <span class="identifier">y1</span>, <span class="identifier">z1</span>]</span> = std::make<span class="constructor">_tuple(<span class="params">vec</span>, <span class="params">vec</span>, <span class="params">vec</span>)</span>;</span><br><span class="line">  <span class="constructor">__TOC__(TUP3)</span></span><br><span class="line"></span><br><span class="line">TUP1 : <span class="number">10087</span>us</span><br><span class="line">TUP2 : <span class="number">10126</span>us</span><br><span class="line">TUP3 : <span class="number">10127</span>us</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 构造时能用Move用move</span></span><br><span class="line">tuple&lt;vector&lt;<span class="type">float</span>&gt;, vector&lt;<span class="type">float</span>&gt;, vector&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">get_tup</span>() &#123;</span><br><span class="line">  <span class="function">vector&lt;<span class="type">float</span>&gt; <span class="title">vec1</span><span class="params">(<span class="number">1000000</span>, <span class="number">-1235.23</span>)</span></span>;</span><br><span class="line">  <span class="function">vector&lt;<span class="type">float</span>&gt; <span class="title">vec2</span><span class="params">(<span class="number">1000000</span>, <span class="number">-1235.23</span>)</span></span>;</span><br><span class="line">  <span class="function">vector&lt;<span class="type">float</span>&gt; <span class="title">vec3</span><span class="params">(<span class="number">1000000</span>, <span class="number">-1235.23</span>)</span></span>;</span><br><span class="line">  <span class="keyword">return</span> &#123;vec1, vec2, vec3&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tuple&lt;vector&lt;<span class="type">float</span>&gt;, vector&lt;<span class="type">float</span>&gt;, vector&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">get_tup1</span>() &#123;</span><br><span class="line">  <span class="function">vector&lt;<span class="type">float</span>&gt; <span class="title">vec1</span><span class="params">(<span class="number">1000000</span>, <span class="number">-1235.23</span>)</span></span>;</span><br><span class="line">  <span class="function">vector&lt;<span class="type">float</span>&gt; <span class="title">vec2</span><span class="params">(<span class="number">1000000</span>, <span class="number">-1235.23</span>)</span></span>;</span><br><span class="line">  <span class="function">vector&lt;<span class="type">float</span>&gt; <span class="title">vec3</span><span class="params">(<span class="number">1000000</span>, <span class="number">-1235.23</span>)</span></span>;</span><br><span class="line">  <span class="keyword">return</span> &#123;std::<span class="built_in">move</span>(vec1), std::<span class="built_in">move</span>(vec2), std::<span class="built_in">move</span>(vec3)&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  __TIC__(TUP3)</span><br><span class="line">  <span class="keyword">auto</span> [x1, y1, z1] = <span class="built_in">get_tup</span>();</span><br><span class="line">  __TOC__(TUP3)</span><br><span class="line"></span><br><span class="line">  __TIC__(TUP4)</span><br><span class="line">  <span class="keyword">auto</span> [x4, y4, z4] = <span class="built_in">get_tup1</span>();</span><br><span class="line">  __TOC__(TUP4)</span><br><span class="line"></span><br><span class="line">TUP3 : <span class="number">18522u</span>s</span><br><span class="line">TUP4 : <span class="number">6687u</span>s</span><br></pre></td></tr></table></figure>

<ol>
<li>if and std::max (简单比较用 if，无函数调用)</li>
</ol>
<figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;<span class="keyword">int</span>&gt; <span class="keyword">test</span>(<span class="number">100000</span>, <span class="number">0</span>)<span class="comment">;</span></span><br><span class="line">  for (auto i = 0u<span class="comment">; i &lt; 100000; i++) &#123;</span></span><br><span class="line">    <span class="keyword">test</span>[i] = rand()<span class="comment">;</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  __TIC__(<span class="keyword">TEST</span>)</span><br><span class="line">  <span class="keyword">int</span> max_value = <span class="number">0</span><span class="comment">;</span></span><br><span class="line">  for (auto i = 0u<span class="comment">; i &lt; 100000; ++i) &#123;</span></span><br><span class="line">    if (<span class="keyword">test</span>[i] &gt; max_value) &#123;</span><br><span class="line">      max_value = <span class="keyword">test</span>[i]<span class="comment">;</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(<span class="keyword">TEST</span>)</span><br><span class="line"></span><br><span class="line">  __TIC__(TEST2)</span><br><span class="line">  <span class="keyword">int</span> max_value2 = <span class="number">0</span><span class="comment">;</span></span><br><span class="line">  for (auto i = 0u<span class="comment">; i &lt; 100000; ++i) &#123;</span></span><br><span class="line">    max_value2 = <span class="keyword">std</span>::max(max_value2, <span class="keyword">test</span>[i])<span class="comment">;</span></span><br><span class="line">  &#125;</span><br><span class="line">  __TOC__(TEST2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">TEST</span> : 570us</span><br><span class="line">TEST2 : 994us</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Links"><a href="#Links" class="headerlink" title="Links"></a>Links</h2><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33638344">C++性能优化</a></li>
<li><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000040755126">C++性能调优</a></li>
</ol>
<h2 id="优化的问题"><a href="#优化的问题" class="headerlink" title="优化的问题"></a>优化的问题</h2><ol>
<li>j5 模型定点对齐输出， 后处理在需要的地方进行定浮点转换与取有效数据</li>
<li>模型输出 chw， 按 c 取最大值，形成 h*w mask；如果按 for i j k 来取，不连续。解决方法：设置第一层为最大值，后续 k-1 层没一层和第 k-1 层做对比，最大值保存在第一层，max 对应的 index 存起来</li>
</ol>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">//</span> net_output: NCHW; net_output_shape: NHWC</span><br><span class="line">auto frame_w = net_output_shape[<span class="number">0</span>][<span class="number">2</span>];</span><br><span class="line">auto frame_h = net_output_shape[<span class="number">0</span>][<span class="number">1</span>];</span><br><span class="line">auto channel_num = net_output_shape[<span class="number">0</span>][<span class="number">3</span>];</span><br><span class="line"><span class="regexp">//</span> cv::Mat mask_mat(frame_h,frame_w, CV_8UC1);</span><br><span class="line">cv::Mat mask_mat = cv::Mat::zeros(frame_h, frame_w, CV_8UC1);</span><br><span class="line">unsigned char *maskdata = mask_mat.data;</span><br><span class="line"><span class="regexp">//</span> <span class="keyword">for</span>(int i=<span class="number">0</span>; i&lt;frame_h; i++)&#123;</span><br><span class="line"><span class="regexp">//</span>   <span class="keyword">for</span>(int j=<span class="number">0</span>; j&lt;frame_w; j++)&#123;</span><br><span class="line"><span class="regexp">//</span>     int index = i*frame_w+j;</span><br><span class="line"><span class="regexp">//</span>     float tmp = net_output[index];</span><br><span class="line"><span class="regexp">//</span>     int maxk = <span class="number">0</span>;</span><br><span class="line"><span class="regexp">//</span>     <span class="keyword">for</span>(int k=<span class="number">1</span>; k&lt;channel_num; k++)&#123;</span><br><span class="line"><span class="regexp">//</span>       int index1 = k*frame_h*frame_w+index;</span><br><span class="line"><span class="regexp">//</span>       <span class="keyword">if</span> (tmp &lt; net_output[index1]) &#123;</span><br><span class="line"><span class="regexp">//</span>         tmp = net_output[index1];</span><br><span class="line"><span class="regexp">//</span>         maxk = k;</span><br><span class="line"><span class="regexp">//</span>       &#125;</span><br><span class="line"><span class="regexp">//</span>     &#125;</span><br><span class="line"><span class="regexp">//</span>     maskdata[index] = maxk;</span><br><span class="line"><span class="regexp">//</span>   &#125;</span><br><span class="line"><span class="regexp">//</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="regexp">//</span> net_output 和 maskdata 都连续访存, 提高cache命中率</span><br><span class="line">int wxh = frame_h *frame_w;</span><br><span class="line"><span class="regexp">//</span> set layer <span class="number">0</span> to max_value;</span><br><span class="line">std::vector&lt;float&gt; max_value(wxh, <span class="number">0</span>);</span><br><span class="line">memcpy(&amp;max_value[<span class="number">0</span>], net_output, wxh * sizeof(float));</span><br><span class="line"><span class="regexp">//</span> get max index from layer <span class="number">1</span></span><br><span class="line">int index = wxh;</span><br><span class="line"><span class="keyword">for</span> (auto k = <span class="number">1</span>u; k &lt; channel_num; ++k) &#123;</span><br><span class="line">  <span class="keyword">for</span> (auto offset = <span class="number">0</span>u; offset &lt; wxh; ++offset) &#123;</span><br><span class="line">    <span class="keyword">if</span> (net_output[index] &gt; max_value[offset]) &#123;</span><br><span class="line">      max_value[offset] = net_output[index];</span><br><span class="line">      maskdata[offset] = k;</span><br><span class="line">    &#125;</span><br><span class="line">    index++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="regexp">//</span> <span class="regexp">//</span> not copy: <span class="number">7</span>ms</span><br><span class="line"><span class="regexp">//</span> int index = wxh;</span><br><span class="line"><span class="regexp">//</span> <span class="keyword">for</span> (auto k = <span class="number">1</span>u; k &lt; channel_num; ++k) &#123;</span><br><span class="line"><span class="regexp">//</span>   <span class="keyword">for</span> (auto offset = <span class="number">0</span>u; offset &lt; wxh; ++offset) &#123;</span><br><span class="line"><span class="regexp">//</span>     <span class="keyword">if</span> (net_output[index] &gt; net_output[offset]) &#123;</span><br><span class="line"><span class="regexp">//</span>       net_output[offset] = net_output[index];</span><br><span class="line"><span class="regexp">//</span>       maskdata[offset] = k;</span><br><span class="line"><span class="regexp">//</span>     &#125;</span><br><span class="line"><span class="regexp">//</span>     index++;</span><br><span class="line"><span class="regexp">//</span>   &#125;</span><br><span class="line"><span class="regexp">//</span> &#125;</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
      

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>贾夕阳
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://jiaxiyang.github.io/2021/08/24/Cpp-Profiling/" title="Profiling">https://jiaxiyang.github.io/2021/08/24/Cpp-Profiling/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Profiling/" rel="tag"><i class="fa fa-tag"></i> Profiling</a>
              <a href="/tags/Perf/" rel="tag"><i class="fa fa-tag"></i> Perf</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/08/22/Programming-Paradigm/" rel="prev" title="Programming-Paradigm">
      <i class="fa fa-chevron-left"></i> Programming-Paradigm
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/09/13/Plugin-System/" rel="next" title="plugins">
      plugins <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#great"><span class="nav-number">1.</span> <span class="nav-text">great</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%E5%99%A8%E9%80%89%E9%A1%B9"><span class="nav-number">2.</span> <span class="nav-text">编译器选项</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#links"><span class="nav-number">2.1.</span> <span class="nav-text">links</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A8%8B%E5%BA%8F%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%AD%A5%E9%AA%A4"><span class="nav-number">3.</span> <span class="nav-text">程序性能分析步骤</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#60s-%E6%93%8D%E4%BD%9C-bpf"><span class="nav-number">4.</span> <span class="nav-text">60s 操作 bpf</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#roofline"><span class="nav-number">5.</span> <span class="nav-text">roofline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#simd-library"><span class="nav-number">6.</span> <span class="nav-text">simd library</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="nav-number">7.</span> <span class="nav-text">性能基准测试</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sysstat"><span class="nav-number">8.</span> <span class="nav-text">sysstat</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#top"><span class="nav-number">9.</span> <span class="nav-text">top</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#proc-%E8%8E%B7%E5%8F%96%E4%BF%A1%E6%81%AF"><span class="nav-number">10.</span> <span class="nav-text">proc 获取信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic"><span class="nav-number">11.</span> <span class="nav-text">Basic</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%90%86%E8%AE%BA%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0"><span class="nav-number">12.</span> <span class="nav-text">理论性能评估</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96"><span class="nav-number">13.</span> <span class="nav-text">推理优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%97%E5%AD%90%E8%9E%8D%E5%90%88"><span class="nav-number">13.1.</span> <span class="nav-text">算子融合</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cpu-time-and-off-cpu-time"><span class="nav-number">14.</span> <span class="nav-text">cpu time and off-cpu time</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%96%B9%E6%B3%95"><span class="nav-number">15.</span> <span class="nav-text">性能调优方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#PMC-Performance-Monitoring-Counters"><span class="nav-number">15.1.</span> <span class="nav-text">PMC(Performance Monitoring Counters)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80"><span class="nav-number">15.2.</span> <span class="nav-text">循环展开</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B"><span class="nav-number">15.3.</span> <span class="nav-text">分支预测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E5%8F%96"><span class="nav-number">15.4.</span> <span class="nav-text">预取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IPC-instruction-per-cycle"><span class="nav-number">15.5.</span> <span class="nav-text">IPC (instruction per cycle)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPI-Cycle-Per-Instruction"><span class="nav-number">15.6.</span> <span class="nav-text">CPI(Cycle Per Instruction)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%91%E6%A0%B8"><span class="nav-number">15.7.</span> <span class="nav-text">绑核</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#memory-bound"><span class="nav-number">15.8.</span> <span class="nav-text">memory bound</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SSE%EF%BC%88Streaming-SIMD-Extensions%EF%BC%89"><span class="nav-number">15.9.</span> <span class="nav-text">SSE（Streaming SIMD Extensions）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SVE-Scalable-Vector-Extension"><span class="nav-number">15.10.</span> <span class="nav-text">SVE(Scalable Vector Extension)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%8F%91%E5%B0%84%E5%A4%84%E7%90%86%E5%99%A8"><span class="nav-number">15.11.</span> <span class="nav-text">多发射处理器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9D%99%E6%80%81%E8%B0%83%E5%BA%A6%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8"><span class="nav-number">15.11.1.</span> <span class="nav-text">静态调度超标量处理器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#VLIW-%E8%B6%85%E9%95%BF%E6%8C%87%E4%BB%A4%E5%AD%97-%E5%A4%84%E7%90%86%E5%99%A8"><span class="nav-number">15.11.2.</span> <span class="nav-text">VLIW( 超长指令字)处理器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E8%B0%83%E5%BA%A6%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8"><span class="nav-number">15.11.3.</span> <span class="nav-text">动态调度超标量处理器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cache"><span class="nav-number">15.12.</span> <span class="nav-text">cache</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%90%E9%AB%98-cache-%E6%80%A7%E8%83%BD"><span class="nav-number">15.13.</span> <span class="nav-text">提高 cache 性能</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#cache-line"><span class="nav-number">15.13.1.</span> <span class="nav-text">cache line</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#cache-%E4%B8%80%E8%87%B4%E6%80%A7"><span class="nav-number">15.13.2.</span> <span class="nav-text">cache 一致性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#cache-miss"><span class="nav-number">15.13.3.</span> <span class="nav-text">cache miss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#prefetch"><span class="nav-number">15.13.4.</span> <span class="nav-text">prefetch</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%AA%E5%85%B1%E4%BA%AB"><span class="nav-number">15.13.5.</span> <span class="nav-text">伪共享</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Notes"><span class="nav-number">16.</span> <span class="nav-text">Notes</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tools"><span class="nav-number">17.</span> <span class="nav-text">Tools</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#likwid"><span class="nav-number">17.1.</span> <span class="nav-text">likwid</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gprof"><span class="nav-number">17.2.</span> <span class="nav-text">gprof</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#google-perftools"><span class="nav-number">17.3.</span> <span class="nav-text">google-perftools</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#valgrind"><span class="nav-number">17.4.</span> <span class="nav-text">valgrind</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#cachegrind"><span class="nav-number">17.4.1.</span> <span class="nav-text">cachegrind</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#callgrind"><span class="nav-number">17.4.2.</span> <span class="nav-text">callgrind</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pmu-tools"><span class="nav-number">17.5.</span> <span class="nav-text">pmu-tools</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#good-pprof"><span class="nav-number">17.6.</span> <span class="nav-text">(good)pprof</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gprof2dot"><span class="nav-number">17.7.</span> <span class="nav-text">gprof2dot</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#perf"><span class="nav-number">18.</span> <span class="nav-text">perf</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85"><span class="nav-number">18.1.</span> <span class="nav-text">源码安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#perf-event"><span class="nav-number">18.2.</span> <span class="nav-text">perf_event</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#list"><span class="nav-number">18.3.</span> <span class="nav-text">list</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#record"><span class="nav-number">18.3.1.</span> <span class="nav-text">record</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#report"><span class="nav-number">18.3.2.</span> <span class="nav-text">report</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#script"><span class="nav-number">18.3.3.</span> <span class="nav-text">script</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#stat"><span class="nav-number">18.3.4.</span> <span class="nav-text">stat</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#annotate"><span class="nav-number">18.3.5.</span> <span class="nav-text">annotate</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#list-1"><span class="nav-number">18.3.6.</span> <span class="nav-text">list</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#top-1"><span class="nav-number">18.3.7.</span> <span class="nav-text">top</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mem"><span class="nav-number">18.3.8.</span> <span class="nav-text">mem</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hotspot"><span class="nav-number">18.4.</span> <span class="nav-text">hotspot</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pyroscope"><span class="nav-number">18.5.</span> <span class="nav-text">pyroscope</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#speedscope"><span class="nav-number">18.6.</span> <span class="nav-text">speedscope</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#flamescope"><span class="nav-number">18.7.</span> <span class="nav-text">flamescope</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%81%AB%E7%84%B0%E5%9B%BE"><span class="nav-number">18.8.</span> <span class="nav-text">火焰图</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#nsight"><span class="nav-number">19.</span> <span class="nav-text">nsight</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-%E6%90%9C%E7%B4%A2-speed-up-C"><span class="nav-number">20.</span> <span class="nav-text">总结(搜索 speed up C++)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cpu-mem-%E5%AE%9E%E6%97%B6%E5%88%A9%E7%94%A8%E7%8E%87"><span class="nav-number">21.</span> <span class="nav-text">cpu mem 实时利用率</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#profiling-result"><span class="nav-number">22.</span> <span class="nav-text">profiling result</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Links"><span class="nav-number">23.</span> <span class="nav-text">Links</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">24.</span> <span class="nav-text">优化的问题</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="贾夕阳"
      src="/images/coder2.jpg">
  <p class="site-author-name" itemprop="name">贾夕阳</p>
  <div class="site-description" itemprop="description">深度学习/自动驾驶/C++/性能优化</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">158</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/jiaxiyang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jiaxiyang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



  <div class="links-of-recent-posts motion-element">
    <div class="links-of-recent-posts-title">
      <i class="fa fa-history fa-fw"></i>
      最近文章
    </div>
    <ul class="links-of-recent-posts-list">
        <li class="links-of-recent-posts-item">
          <a href="/2023/11/21/transformer/" title="2023&#x2F;11&#x2F;21&#x2F;transformer&#x2F;">transformer</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/11/21/LLM/" title="2023&#x2F;11&#x2F;21&#x2F;LLM&#x2F;">LLM</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/11/15/shareX/" title="2023&#x2F;11&#x2F;15&#x2F;shareX&#x2F;">shareX</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/11/10/nvidia/" title="2023&#x2F;11&#x2F;10&#x2F;nvidia&#x2F;">nvidia</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/11/05/package-manager/" title="2023&#x2F;11&#x2F;05&#x2F;package-manager&#x2F;">package manager</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">贾夕阳</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">374k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">5:40</span>
</div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("06/26/2020 14:52:10");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_sphere.min.js"></script>


  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : '[object Object]',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://jiaxiyang.github.io/2021/08/24/Cpp-Profiling/',]
      });
      });
  </script>


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'g32ipLmEye1u5l6wBGRJt03S-gzGzoHsz',
      appKey     : 'zHgLkAICsZUl9Mf8LfdoVigP',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

  

  <script src="/js/activate-power-mode.min.js"></script>
  <script>
    POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);
  </script>





 
</body>
</html>

